{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SZmBDUcPggiK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch \n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "from transformers import DistilBertTokenizer,DistilBertModel,AdamW, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04SRG3MOYHe"
      },
      "source": [
        "#Data Imports, Cleaning, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "2W09yXnJggiN",
        "outputId": "eadfe22c-777e-4b25-bf95-1a74a1e5395e"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"data/jigsaw-toxic-comment-train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UMozNq5KggiP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94e9521f28329dd1</td>\n",
              "      <td>:Awesome! Thank you so much!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19f3078ecbccebeb</td>\n",
              "      <td>Ok but can u at leas block User: Gibraltarian ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2dc194f8771b71dc</td>\n",
              "      <td>::Seems prudent. Thanks!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5daf3e5ba6db326e</td>\n",
              "      <td>\"Also: you seem completely unclear on the conc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99f2381ed941124b</td>\n",
              "      <td>There are several definitions of Kinneret - wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic\n",
              "0  94e9521f28329dd1                       :Awesome! Thank you so much!      0\n",
              "1  19f3078ecbccebeb  Ok but can u at leas block User: Gibraltarian ...      0\n",
              "2  2dc194f8771b71dc                           ::Seems prudent. Thanks!      0\n",
              "3  5daf3e5ba6db326e  \"Also: you seem completely unclear on the conc...      0\n",
              "4  99f2381ed941124b  There are several definitions of Kinneret - wh...      0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LABEL_COLUMNS = [\"toxic\"]\n",
        "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
        "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
        "train_toxic = train_toxic.drop(columns = ['severe_toxic','obscene', 'threat', 'insult', 'identity_hate'])\n",
        "train_clean = train_clean.drop(columns = ['severe_toxic','obscene', 'threat', 'insult', 'identity_hate'])\n",
        "concat_df = pd.concat([train_toxic, train_clean])\n",
        "train_data = concat_df.sample(frac=1).reset_index(drop=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "956xSTycggiS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text  toxic\n",
              "0   0  Doctor Who adlı viki başlığına 12. doctor olar...      0\n",
              "1   1   Вполне возможно, но я пока не вижу необходимо...      0\n",
              "2   2  Quindi tu sei uno di quelli   conservativi  , ...      1\n",
              "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...      0\n",
              "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...      0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels_df = pd.read_csv('data/test_labels.csv')\n",
        "test_df = pd.read_csv('data/test.csv')\n",
        "test_df=test_df.drop(columns='id')\n",
        "test_concat_df = pd.concat([test_labels_df,test_df], axis=1,join=\"inner\")\n",
        "test_concat_df = test_concat_df.drop(columns = ['lang'])\n",
        "test_concat_df['comment_text'] = test_concat_df['content']\n",
        "test_data = test_concat_df[['id','comment_text','toxic']].copy()\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7T0HzSVHggiT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Este usuario ni siquiera llega al rango de    ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Il testo di questa voce pare esser scopiazzato...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text  toxic\n",
              "0   0  Este usuario ni siquiera llega al rango de    ...      0\n",
              "1   1  Il testo di questa voce pare esser scopiazzato...      0\n",
              "2   2  Vale. Sólo expongo mi pasado. Todo tiempo pasa...      1\n",
              "3   3  Bu maddenin alt başlığı olarak  uluslararası i...      0\n",
              "4   4  Belçika nın şehirlerinin yanında ilçe ve belde...      0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df = pd.read_csv('data/validation.csv')\n",
        "val_data = val_df.drop(columns = ['lang'])\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "00PJE9OEggiU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 3)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data = val_data[:2000]\n",
        "val_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "P4FR54lWggiU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8000, 3)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = train_data[:8000]\n",
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "t6YyxetpggiU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3000, 3)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = test_data[:3000]\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "F561aH7BggiU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text  toxic\n",
              "0   0  Doctor Who adlı viki başlığına 12. doctor olar...      0\n",
              "1   1   Вполне возможно, но я пока не вижу необходимо...      0\n",
              "2   2  Quindi tu sei uno di quelli   conservativi  , ...      1\n",
              "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...      0\n",
              "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...      0"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "mS0vmym4ggiV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Este usuario ni siquiera llega al rango de    ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Il testo di questa voce pare esser scopiazzato...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text  toxic\n",
              "0   0  Este usuario ni siquiera llega al rango de    ...      0\n",
              "1   1  Il testo di questa voce pare esser scopiazzato...      0\n",
              "2   2  Vale. Sólo expongo mi pasado. Todo tiempo pasa...      1\n",
              "3   3  Bu maddenin alt başlığı olarak  uluslararası i...      0\n",
              "4   4  Belçika nın şehirlerinin yanında ilçe ve belde...      0"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "c3KE3T3qggiV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148052a1f780a1e7</td>\n",
              "      <td>::That doesn't make even the slightest bit of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d1ebc8b7169bb282</td>\n",
              "      <td>You know, if you don't tell me what I did wron...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ef63757759cfa1aa</td>\n",
              "      <td>Belief? \\n\\nIs RadioKirk the onlyone who beliv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2c38f650668e090a</td>\n",
              "      <td>\"\\n\\n I suggest that you search the article fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e15f2f0010f19e5d</td>\n",
              "      <td>oh lol eleanor is a pure and utter gimp she li...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic\n",
              "0  148052a1f780a1e7  ::That doesn't make even the slightest bit of ...      0\n",
              "1  d1ebc8b7169bb282  You know, if you don't tell me what I did wron...      0\n",
              "2  ef63757759cfa1aa  Belief? \\n\\nIs RadioKirk the onlyone who beliv...      0\n",
              "3  2c38f650668e090a  \"\\n\\n I suggest that you search the article fo...      0\n",
              "4  e15f2f0010f19e5d  oh lol eleanor is a pure and utter gimp she li...      0"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yFT3mwu4N7Lv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id               int64\n",
              "comment_text    object\n",
              "toxic            int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "K8N0MEMXPlK-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3000, 3) (8000, 3) (2000, 3)\n"
          ]
        }
      ],
      "source": [
        "print(test_data.shape,\n",
        "train_data.shape,\n",
        "val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"::That doesn't make even the slightest bit of sense. That you think it looks shitty is not a justification for ignoring rules, so of course I wouldn't prefer it. You are flat wrong on this. It is more important the the text of quotations not be misleading than that Hell in a Bucket like the way something looks. It's weird enough that you refuse to understand the rather obvious reason why the brackets were there, but that you edit warred over it is incomprehensible. It's understandable when someone edit wars to try to enforce a guideline, but to consciously do so for no more reason than you don't like the guideline is hard to understand. -\"\n",
            " \"You know, if you don't tell me what I did wrong, I don't see what I can learn from it.76.10.75.168\"\n",
            " 'Belief? \\n\\nIs RadioKirk the onlyone who belives me???' ...\n",
            " '\"\\n\\nLifespan\\nPossibly this entry at the SSDI - born August 6, 1899, died January 1983.  Paul \"'\n",
            " \"Why bother with signing my name when you temporarily blocked me from articles on which I had provided good references. What's the point?\"\n",
            " \"IT IS UNNATURAL FOR A MAN TO TAKE ANOTHER MAN'S COCK UP HIS ASS. FIND GOD! 131.247.244.191\"]\n",
            "[0 0 0 ... 0 0 1]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = train_data\n",
        "comments = df1.comment_text.values\n",
        "labels = df1.toxic.values\n",
        "\n",
        "print(comments), print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Este usuario ni siquiera llega al rango de    hereje   . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    Skipe linkin 22px   Honor, valor, leltad.      17:48 13 mar 2008 (UTC)'\n",
            " 'Il testo di questa voce pare esser scopiazzato direttamente da qui. Immagino possano esserci problemi di copyright, nel fare cio .'\n",
            " 'Vale. Sólo expongo mi pasado. Todo tiempo pasado fue mejor, ni mucho menos, yo no quisiera retroceder 31 años a nivel particular. Las volveria a pasar putas.Fernando '\n",
            " ...\n",
            " 'Supongo que eso de que eres un adicto al porno, es un vandalismo hecho por otro. '\n",
            " 'Que caciqueros, mesetarios, incultos y prepotentes...a mi me parecéis todos una banda de bastardos...Lo importante es joder, da igual la razón...porque tenéis los tanques, que si no. Ya lo dejaís bien clarito en muchas ocasiones que aunque imbéciles ( y lo de imbéciles queda reflejado dia tras dia en su mierda de Pais, dónde aun tienen un presidente borderline que no sabe hablar ni inglés)...siguen mandando ustedes...Nos queda claro bastardos que aquí somos una colonia, que nunca nos van a dejar ir porque somos la gallina de los huevos de oro de los caciques. Un dia se os va a acabar el chollo o nos tendrési que matar a todos...antes me llevaré algunos bastardos caciqueros mesetarios e incultos por delante...que abundan mucho por la zona...Ara, los mesetarios bastardos de por aquí lo llaman Baix Llobregat'\n",
            " 'Merhaba, Cobija, Nargin Adası adasında eklediğiniz BS şablonunu kaldırabilir misiniz? Sayfayı güncelliyorum. Şu an için kısa bir mola vermekle birlikte çalışmayı kısa (birkaç saat) içinde tamamlayacağım. Kolay gelsin. thecatcherintherye   mesaj    ']\n",
            "[0 0 1 ... 1 1 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = val_data\n",
        "comments2 = df2.comment_text.values\n",
        "labels2 = df2.toxic.values\n",
        "\n",
        "print(comments2), print(labels2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Doctor Who adlı viki başlığına 12. doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital '\n",
            " ' Вполне возможно, но я пока не вижу необходимости выделять материал в отдельную статью. Если про правосудие в СССР будет написано хотя бы килобайт 20-30 — тогда да, следует разделить. Пока же мы в итоге получим одну куцую статью Правосудие и другую не менее куцую статью Правосудие в СССР. Мне кажется, что этот вопрос вполне разумно решать на основе правил ВП:Размер статей? которые не предписывают разделения, пока размер статьи не достигнет хотя бы 50 тыс. знаков. '\n",
            " 'Quindi tu sei uno di quelli   conservativi  , che preferiscono non cancellare. Ok. Avresti lasciato anche   sfaccimma  ? Si? Ok. Contento te... io non approvo per nulla, ma non conto nemmeno nulla... Allora lo sai che faccio? Me ne frego! (Aborro il fascismo, ma quando ce vo , ce vo !) Elborgo (sms) '\n",
            " ...\n",
            " 'Polluer? ça fait des semaines que j ai bossé sur l article, le débat est clos pour toi, car y a que toi qui fait chier (soyons clairs) sur cet article avec ton francisé à la con qui n existe nulle part sauf sur francefootball.fr, les français beaufs de ton genre me cassent les burnes (tu m agresses, je fais de même), tant que tu écriras des conneries et qu en plus, tu effaceras des sources et le travail des autres (ici moi), je ferais comme toi et j effacerais tes conneries. Arrête de te prendre pour un dieu d internet en écrivant de la merde sur un jour qui ne s est jamais appelé comme tu l entends!Loic182 (d) '\n",
            " ' Вы параноик? Если согласны с фальшивкой, почему я должен, просто обязан подтверждать, что это фальшивка? Чобиток Василий '\n",
            " ':Doğanoğlu sayfasında yaptığınız deneme için teşekkür ederiz. Denemeniz çalıştı, fakat ya geri alındı ya da silindi. Lütfen diğer testleriniz için deneme tahtasını kullanın. Eğer nasıl katkı yapabileceğiniz konusunda daha fazla bilgi edinmek istiyorsanız, lütfen Vikipedi`ye hoş geldiniz sayfasına bir göz atın. Teşekkürler.M. Yalçın Yalhı ']\n",
            "[0 0 1 ... 1 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3 = test_data\n",
        "test_comments = df3.comment_text.values\n",
        "test_labels = df3.toxic.values\n",
        "\n",
        "print(test_comments), print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "7AnnSo08ggiO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#MAX_LEN = 512\n",
        "#TRAIN_BATCH_SIZE = 1\n",
        "#VALID_BATCH_SIZE = 2\n",
        "#EPOCHS = 1\n",
        "#LEARNING_RATE = 1e-05\n",
        "bert_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  ::That doesn't make even the slightest bit of sense. That you think it looks shitty is not a justification for ignoring rules, so of course I wouldn't prefer it. You are flat wrong on this. It is more important the the text of quotations not be misleading than that Hell in a Bucket like the way something looks. It's weird enough that you refuse to understand the rather obvious reason why the brackets were there, but that you edit warred over it is incomprehensible. It's understandable when someone edit wars to try to enforce a guideline, but to consciously do so for no more reason than you don't like the guideline is hard to understand. -\n",
            "Tokenized:  [':', ':', 'That', 'doesn', \"'\", 't', 'make', 'even', 'the', 'sl', '##ight', '##est', 'bit', 'of', 'sense', '.', 'That', 'you', 'think', 'it', 'looks', 'shi', '##tty', 'is', 'not', 'a', 'just', '##ification', 'for', 'ig', '##nor', '##ing', 'rules', ',', 'so', 'of', 'course', 'I', 'would', '##n', \"'\", 't', 'pre', '##fer', 'it', '.', 'You', 'are', 'flat', 'wrong', 'on', 'this', '.', 'It', 'is', 'more', 'important', 'the', 'the', 'text', 'of', 'quota', '##tions', 'not', 'be', 'mis', '##lea', '##ding', 'than', 'that', 'Hell', 'in', 'a', 'Buck', '##et', 'like', 'the', 'way', 'something', 'looks', '.', 'It', \"'\", 's', 'wei', '##rd', 'enough', 'that', 'you', 'refuse', 'to', 'understand', 'the', 'rather', 'obvious', 'reason', 'why', 'the', 'bra', '##ckets', 'were', 'there', ',', 'but', 'that', 'you', 'edit', 'war', '##red', 'over', 'it', 'is', 'in', '##com', '##pre', '##hen', '##sible', '.', 'It', \"'\", 's', 'understand', '##able', 'when', 'someone', 'edit', 'wars', 'to', 'try', 'to', 'en', '##force', 'a', 'guide', '##line', ',', 'but', 'to', 'con', '##sci', '##ously', 'do', 'so', 'for', 'no', 'more', 'reason', 'than', 'you', 'don', \"'\", 't', 'like', 'the', 'guide', '##line', 'is', 'hard', 'to', 'understand', '.', '-']\n",
            "Token IDs:  [131, 131, 13646, 47798, 112, 188, 13086, 13246, 10105, 38523, 27521, 13051, 17684, 10108, 15495, 119, 13646, 13028, 27874, 10271, 59148, 57667, 30921, 10124, 10472, 169, 12820, 29748, 10142, 23602, 36064, 10230, 23123, 117, 10380, 10108, 15348, 146, 10894, 10115, 112, 188, 12229, 14854, 10271, 119, 11065, 10301, 31307, 56126, 10135, 10531, 119, 10377, 10124, 10798, 12452, 10105, 10105, 15541, 10108, 59027, 15024, 10472, 10347, 12606, 25277, 13971, 11084, 10189, 22167, 10106, 169, 40477, 10308, 11850, 10105, 13170, 26133, 59148, 119, 10377, 112, 187, 86981, 12023, 21408, 10189, 13028, 48787, 10114, 49151, 10105, 16863, 94452, 27949, 31237, 10105, 67603, 81143, 10309, 11155, 117, 10473, 10189, 13028, 70971, 10338, 15711, 10491, 10271, 10124, 10106, 22530, 30619, 14786, 55864, 119, 10377, 112, 187, 49151, 13096, 10841, 30455, 70971, 68756, 10114, 31638, 10114, 10110, 39910, 169, 25083, 12953, 117, 10473, 10114, 10173, 89270, 47173, 10149, 10380, 10142, 10192, 10798, 27949, 11084, 13028, 16938, 112, 188, 11850, 10105, 25083, 12953, 10124, 19118, 10114, 49151, 119, 118]\n"
          ]
        }
      ],
      "source": [
        "print('Original: ',  comments[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(comments[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(comments[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "eu-Td0nVggiV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ninput_ids = []\\nattention_masks = []\\n\\nclass ToxicCommentsDataset(Dataset):\\n    def __init__(self, data, tokenizer, max_len): #: DistilBertTokenizer\\n        self.data = data\\n        self.tokenizer = tokenizer\\n        self.max_len = max_len\\n        self.len=len(data)\\n\\n    def __len__(self):\\n        return len(self.data)\\n        \\n    def __getitem__(self, comments):#, item):\\n        #comment_text = str(self.data.comment_text[item])\\n        print(comments)\\n        encoding = self.tokenizer.encode_plus(\\n        comments, \\n        None,\\n        add_special_tokens=True,\\n        max_length=self.max_len, \\n        return_token_type_ids=True,\\n        padding=\"max_length\",\\n        truncation=True,\\n        return_attention_mask=True,\\n        return_tensors=\\'pt\\',\\n    )\\n        #ids = encoding[\\'input_ids\\']\\n        #mask = encoding[\\'attention_mask\\']\\n\\n        input_ids.append(encoding[\\'input_ids\\']) \\n        attention_masks.append(encoding[\\'attention_mask\\'])\\n    '"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "class ToxicCommentsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len): #: DistilBertTokenizer\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.len=len(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self, comments):#, item):\n",
        "        #comment_text = str(self.data.comment_text[item])\n",
        "        print(comments)\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "        comments, \n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len, \n",
        "        return_token_type_ids=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "        #ids = encoding['input_ids']\n",
        "        #mask = encoding['attention_mask']\n",
        "\n",
        "        input_ids.append(encoding['input_ids']) \n",
        "        attention_masks.append(encoding['attention_mask'])\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "IwblmTj3ggiW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ntraining_set = ToxicCommentsDataset(train_data,tokenizer,MAX_LEN)\\nvalidation_set = ToxicCommentsDataset(val_data,tokenizer,MAX_LEN)\\ntesting_set = ToxicCommentsDataset(test_data,tokenizer,MAX_LEN)\\n\\n\\nprint(\"TRAIN Dataset: {}\".format(train_data.shape))\\nprint(\"TEST Dataset: {}\".format(test_data.shape))\\nprint(\"VAL Dataset: {}\".format(val_data.shape))\\n'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_size = 0.8\n",
        "# train_dataset = train_data.sample(frac=train_size, random_state=123)\n",
        "# test_dataset = test_data.drop(test_data.index).reset_index(drop=True)\n",
        "# train_dataset = train_dataset.reset_index(drop=True)\n",
        "\"\"\"\n",
        "training_set = ToxicCommentsDataset(train_data,tokenizer,MAX_LEN)\n",
        "validation_set = ToxicCommentsDataset(val_data,tokenizer,MAX_LEN)\n",
        "testing_set = ToxicCommentsDataset(test_data,tokenizer,MAX_LEN)\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "print(\"VAL Dataset: {}\".format(val_data.shape))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "def maketensors(dataset,input_ids_list,attention_masks_list):\n",
        "    \n",
        "    for data in dataset:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "C:\\Users\\Saeed\\Anaconda3\\envs\\env_pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  ::That doesn't make even the slightest bit of sense. That you think it looks shitty is not a justification for ignoring rules, so of course I wouldn't prefer it. You are flat wrong on this. It is more important the the text of quotations not be misleading than that Hell in a Bucket like the way something looks. It's weird enough that you refuse to understand the rather obvious reason why the brackets were there, but that you edit warred over it is incomprehensible. It's understandable when someone edit wars to try to enforce a guideline, but to consciously do so for no more reason than you don't like the guideline is hard to understand. -\n",
            "Token IDs: tensor([  101,   131,   131, 13646, 47798,   112,   188, 13086, 13246, 10105,\n",
            "        38523, 27521, 13051, 17684, 10108, 15495,   119, 13646, 13028, 27874,\n",
            "        10271, 59148, 57667, 30921, 10124, 10472,   169, 12820, 29748, 10142,\n",
            "        23602, 36064, 10230, 23123,   117, 10380, 10108, 15348,   146, 10894,\n",
            "        10115,   112,   188, 12229, 14854, 10271,   119, 11065, 10301, 31307,\n",
            "        56126, 10135, 10531,   119, 10377, 10124, 10798, 12452, 10105, 10105,\n",
            "        15541, 10108, 59027,   102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for comment in comments:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', comments[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8000, 64])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8000, 64])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8000])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Este usuario ni siquiera llega al rango de    hereje   . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    Skipe linkin 22px   Honor, valor, leltad.      17:48 13 mar 2008 (UTC)\n",
            "Token IDs: tensor([  101, 12515, 82849, 10414, 10294, 39190, 10113, 39492, 10164, 39715,\n",
            "        10104, 19353, 10381,   119, 12399, 10406, 12921, 96621, 10493, 29826,\n",
            "        11272, 10110, 10109, 18121, 10537, 83592, 10220, 32385, 66240, 10198,\n",
            "        39215,   193, 75036, 32500, 18010, 80592, 32413, 11244, 18229, 10198,\n",
            "        11600, 32413, 11482,   119, 51874, 11355, 26192, 10245, 10306, 10410,\n",
            "        10686, 26354,   117, 18094,   117, 10141, 92608,   119, 10273,   131,\n",
            "        11300, 10249, 12318,   102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for comment in comments2:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded sentence to the list.    \n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "val_labels = torch.tensor(labels2)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', comments2[0])\n",
        "print('Token IDs:', val_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000, 64])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_attention_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000, 64])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Doctor Who adlı viki başlığına 12. doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital \n",
            "Token IDs: tensor([   101,  17376,  14516,  19165,  56324,  10116,  24542,  91727,  10186,\n",
            "           119,  26937,  11772,  10561,  56324,  10116,  82867,  10713,  32720,\n",
            "         42702,  16334,  19343,  61716,  18330,    119, 102884,  10917,    172,\n",
            "         78653,  12683,  10147,    119,  44798,  82350,  14434,  30471,  10126,\n",
            "         60906,  23760,    119,    152,  28217,  55743,    102,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0])\n"
          ]
        }
      ],
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for comment in test_comments:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "print('Original: ', test_comments[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "M0NlZza7ggiW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ntrain_params = {'batch_size': TRAIN_BATCH_SIZE,\\n                'shuffle': True,\\n                'num_workers': 0\\n                }\\n\\n\\nval_params = {'batch_size': VALID_BATCH_SIZE,\\n                'shuffle': True,\\n                'num_workers': 0\\n                }\\n\\n\\ntest_params = {'batch_size': VALID_BATCH_SIZE,\\n                'shuffle': True,\\n                'num_workers': 0\\n                }\\n\\ntraining_loader = DataLoader(training_set, **train_params)\\nvalidation_loader = DataLoader(validation_set, **val_params)\\ntesting_loader = DataLoader(testing_set, **test_params)\\n\\n# Set the batch size.  \\nbatch_size = 32  \\n\\n# Create the DataLoader.\\nprediction_data = TensorDataset(input_ids, attention_masks, labels)\\nprediction_sampler = SequentialSampler(prediction_data)\\nprediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\\n\""
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "validation_loader = DataLoader(validation_set, **val_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "test_dataset = TensorDataset(test_input_ids,test_attention_masks,test_labels)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = 16 # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(val_dataset), # Select batches randomly\n",
        "            batch_size = 16 # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = 32 # Trains with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(input_ids),type(attention_masks),type(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(val_input_ids),type(val_attention_masks),type(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101, 42272, 42998,  ..., 10310, 84572,   102],\n",
            "        [  101, 11045, 61197,  ..., 64424, 28581,   102],\n",
            "        [  101, 33127, 10123,  ..., 10143, 10549,   102],\n",
            "        ...,\n",
            "        [  101, 64831, 11244,  ...,   114, 69579,   102],\n",
            "        [  101, 11045, 10428,  ...,     0,     0,     0],\n",
            "        [  101, 31301, 48985,  ..., 10305,   117,   102]])\n",
            "tensor([[  101, 13740, 22037,  ..., 12216, 10369,   102],\n",
            "        [  101,   246,   151,  ..., 59879, 11273,   102],\n",
            "        [  101, 11045, 11381,  ..., 24446, 10343,   102],\n",
            "        ...,\n",
            "        [  101, 75294, 10133,  ...,     0,     0,     0],\n",
            "        [  101, 11916, 13785,  ..., 10104, 81695,   102],\n",
            "        [  101, 30247, 29392,  ...,   119,   102,     0]])\n",
            "tensor([[   101,  11045,  10228,  ..., 107054,  10125,    102],\n",
            "        [   101,  10734, 100025,  ...,  18938,  79118,    102],\n",
            "        [   101,  10734, 100025,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  42272,  42998,  ...,    119,  12845,    102],\n",
            "        [   101,    138,  48798,  ...,  32448,  85948,    102],\n",
            "        [   101,  18082,  10637,  ...,  10435,  10110,    102]])\n",
            "tensor([[  101, 20220, 10330,  ..., 41249, 10104,   102],\n",
            "        [  101, 10445, 52977,  ...,     0,     0,     0],\n",
            "        [  101, 13672,   171,  ..., 16719, 10125,   102],\n",
            "        ...,\n",
            "        [  101, 10657,   119,  ..., 10119, 15189,   102],\n",
            "        [  101,   169, 43216,  ..., 17339, 20589,   102],\n",
            "        [  101, 51457, 14875,  ..., 10178, 10830,   102]])\n",
            "tensor([[  101,   142, 10109,  ..., 37749, 10342,   102],\n",
            "        [  101, 37313, 16114,  ..., 77089, 11015,   102],\n",
            "        [  101, 51457, 14875,  ..., 19972,   113,   102],\n",
            "        ...,\n",
            "        [  101, 10912, 79381,  ...,     0,     0,     0],\n",
            "        [  101, 10777,   184,  ...,     0,     0,     0],\n",
            "        [  101, 35555, 10403,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  19561,  10133,  ...,      0,      0,      0],\n",
            "        [   101,  77311,  10321,  ...,  13063, 100625,    102],\n",
            "        [   101,  35290,  10561,  ...,    119,  52678,    102],\n",
            "        ...,\n",
            "        [   101,  10469,  10713,  ...,  10824,  71339,    102],\n",
            "        [   101,  10192,  18077,  ...,    119,    119,    102],\n",
            "        [   101,  12271,  27119,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 51806, 99027,  ..., 10305, 15554,   102],\n",
            "        [  101, 12399, 38188,  ...,     0,     0,     0],\n",
            "        [  101, 16336, 73613,  ..., 13055, 82427,   102],\n",
            "        ...,\n",
            "        [  101, 25822, 10323,  ...,     0,     0,     0],\n",
            "        [  101, 38523, 10147,  ..., 10308, 20267,   102],\n",
            "        [  101,   224, 21452,  ...,     0,     0,     0]])\n",
            "tensor([[  101,   246, 18369,  ..., 10115, 53953,   102],\n",
            "        [  101, 20220, 29956,  ...,     0,     0,     0],\n",
            "        [  101, 30087, 19130,  ..., 87039,   123,   102],\n",
            "        ...,\n",
            "        [  101, 58060, 10178,  ...,     0,     0,     0],\n",
            "        [  101, 10224, 75980,  ..., 52338, 11259,   102],\n",
            "        [  101,   144, 36133,  ..., 10323, 10294,   102]])\n",
            "tensor([[   101,  10533,  10410,  ...,  10835,  10561,    102],\n",
            "        [   101, 101546,  11826,  ...,    119,  43506,    102],\n",
            "        [   101,  48691,  26635,  ...,    119,    187,    102],\n",
            "        ...,\n",
            "        [   101,  10153,  97705,  ...,  24806,  10183,    102],\n",
            "        [   101,  20220,  10330,  ...,  10406,  27122,    102],\n",
            "        [   101,  11045,  10228,  ..., 107054,  10125,    102]])\n",
            "tensor([[   101,  11741,  10285,  ...,      0,      0,      0],\n",
            "        [   101,    122,    118,  ...,  10110,  10125,    102],\n",
            "        [   101,    152,  44962,  ...,  27421,  87264,    102],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  32212,  11802,    102],\n",
            "        [   101,  10912,  10121,  ...,      0,      0,      0],\n",
            "        [   101,  13229,  30222,  ...,  10126,  23440,    102]])\n",
            "tensor([[  101, 90792, 10112,  ..., 40431,   193,   102],\n",
            "        [  101,   224, 38500,  ...,   113, 31078,   102],\n",
            "        [  101, 58060,   106,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 20220, 10330,  ..., 45075,   169,   102],\n",
            "        [  101,   142, 52963,  ..., 20861, 40773,   102],\n",
            "        [  101,   233, 24995,  ..., 13636, 10262,   102]])\n",
            "tensor([[  101, 21452, 10196,  ...,     0,     0,     0],\n",
            "        [  101, 51457, 14875,  ...,     0,     0,     0],\n",
            "        [  101,   118, 40840,  ..., 32228, 62511,   102],\n",
            "        ...,\n",
            "        [  101, 58901, 13055,  ..., 13114, 41449,   102],\n",
            "        [  101, 10406, 10380,  ..., 14875, 30960,   102],\n",
            "        [  101, 52143, 13273,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 11045, 21114,  ..., 17720, 10576,   102],\n",
            "        [  101, 11916, 16818,  ..., 11783, 74158,   102],\n",
            "        [  101, 10141, 26978,  ..., 27447, 43950,   102],\n",
            "        ...,\n",
            "        [  101, 29846, 10446,  ...,     0,     0,     0],\n",
            "        [  101, 87892, 85111,  ...,   102,     0,     0],\n",
            "        [  101, 58060,   117,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 10159, 20079,  ...,     0,     0,     0],\n",
            "        [  101, 38571, 10483,  ...,   106,   106,   102],\n",
            "        [  101, 29079, 27364,  ..., 24707, 39061,   102],\n",
            "        ...,\n",
            "        [  101, 19561, 10133,  ..., 16430, 14250,   102],\n",
            "        [  101,   246, 18369,  ...,     0,     0,     0],\n",
            "        [  101, 10446, 37416,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  19561,  32448,  ...,  30479,  10125,    102],\n",
            "        [   101,  81687,  23420,  ...,      0,      0,      0],\n",
            "        [   101,    126,  25890,  ..., 105861,  26101,    102],\n",
            "        ...,\n",
            "        [   101,  20220,  10330,  ...,      0,      0,      0],\n",
            "        [   101,  51457,  14875,  ...,  18894,  21187,    102],\n",
            "        [   101,  14723,  70384,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        [  101, 12515, 41249,  ...,     0,     0,     0],\n",
            "        [  101,   141, 89757,  ..., 84995, 30672,   102],\n",
            "        ...,\n",
            "        [  101, 11499, 10549,  ..., 26101, 12361,   102],\n",
            "        [  101,   262, 10106,  ..., 52700, 10343,   102],\n",
            "        [  101, 54074, 13259,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 34182, 10330,  ...,     0,     0,     0],\n",
            "        [  101, 78749, 65374,  ..., 10840, 77204,   102],\n",
            "        [  101, 20220, 10330,  ..., 10827, 10208,   102],\n",
            "        ...,\n",
            "        [  101, 85989, 25460,  ...,     0,     0,     0],\n",
            "        [  101, 51457, 14875,  ..., 10715, 39709,   102],\n",
            "        [  101, 10657, 18611,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 23358, 10151,  ..., 70995, 10317,   102],\n",
            "        [  101, 24948, 19402,  ...,     0,     0,     0],\n",
            "        [  101, 11045, 21114,  ..., 74788, 20024,   102],\n",
            "        ...,\n",
            "        [  101, 27158, 15792,  ...,     0,     0,     0],\n",
            "        [  101, 20220, 10330,  ...,   117,   102,     0],\n",
            "        [  101, 32286,   119,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  22800,  22659,  ...,  10915,  52580,    102],\n",
            "        [   101,  98759,  57152,  ...,  22243,    282,    102],\n",
            "        [   101,  53953,  10418,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  48024,  10213,  ...,      0,      0,      0],\n",
            "        [   101,  29005,  96462,  ...,  10899,  12229,    102],\n",
            "        [   101, 104513,  10425,  ...,  11008,    169,    102]])\n",
            "tensor([[   101,  10377,  10458,  ...,  10325,    177,    102],\n",
            "        [   101,  10282,  17982,  ...,  39077,  10401,    102],\n",
            "        [   101,    157, 110923,  ...,  14703,  11274,    102],\n",
            "        ...,\n",
            "        [   101,  20220,  10330,  ..., 106734,  10836,    102],\n",
            "        [   101,  10159,  86945,  ...,  17421,  41068,    102],\n",
            "        [   101,    145,  72679,  ...,  10817,  28167,    102]])\n",
            "tensor([[  101, 32105, 18422,  ...,     0,     0,     0],\n",
            "        [  101, 33127, 10123,  ..., 10117, 11919,   102],\n",
            "        [  101, 29095, 47617,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 20220, 10330,  ..., 34987, 61153,   102],\n",
            "        [  101, 29033, 21550,  ...,     0,     0,     0],\n",
            "        [  101, 10159, 27218,  ...,     0,     0,     0]])\n",
            "tensor([[  101,   141, 48277,  ..., 15922, 10126,   102],\n",
            "        [  101, 11045, 21114,  ..., 10406, 24345,   102],\n",
            "        [  101, 10533, 10410,  ..., 10113, 18910,   102],\n",
            "        ...,\n",
            "        [  101, 10224, 37030,  ..., 13621, 47116,   102],\n",
            "        [  101, 10912, 48929,  ..., 34522, 53189,   102],\n",
            "        [  101, 20220, 10330,  ...,   193, 30664,   102]])\n",
            "tensor([[  101, 51457, 14875,  ..., 17049, 10406,   102],\n",
            "        [  101,   171,   262,  ...,     0,     0,     0],\n",
            "        [  101, 10827, 10686,  ..., 40773, 10323,   102],\n",
            "        ...,\n",
            "        [  101, 20108, 12132,  ...,     0,     0,     0],\n",
            "        [  101, 11045, 21114,  ..., 40929, 10240,   102],\n",
            "        [  101, 25148, 10261,  ..., 10153, 32056,   102]])\n",
            "tensor([[   101,  10159,  19696,  ...,  13227,  11498,    102],\n",
            "        [   101,  11518, 100745,  ...,  23827,  26219,    102],\n",
            "        [   101,  11916,  18370,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,    156,  10162,  ...,  11381,  10120,    102],\n",
            "        [   101,    149,  10266,  ...,  26046,  10153,    102],\n",
            "        [   101,  10159,  24400,  ...,  28050,  64741,    102]])\n",
            "tensor([[   101,  23138,  79080,  ...,  79080,    119,    102],\n",
            "        [   101,  10734, 100025,  ...,  23763,  57291,    102],\n",
            "        [   101,  77710,  18887,  ...,  11281,  49000,    102],\n",
            "        ...,\n",
            "        [   101,  70843,  10115,  ...,  11759,    114,    102],\n",
            "        [   101,  11045,  21114,  ...,  98881,  11604,    102],\n",
            "        [   101,  14200,  10126,  ...,  49378,  32002,    102]])\n",
            "tensor([[  101, 10159, 16430,  ..., 18345, 10112,   102],\n",
            "        [  101, 11741, 65214,  ..., 10185,   102,     0],\n",
            "        [  101, 32200,   232,  ..., 12352, 10730,   102],\n",
            "        ...,\n",
            "        [  101, 13026, 18497,  ...,     0,     0,     0],\n",
            "        [  101, 51457, 14875,  ...,     0,     0,     0],\n",
            "        [  101, 20220, 10330,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  84591,    119,  ...,  45858,  10113,    102],\n",
            "        [   101,  56695,  14336,  ...,  10109, 104303,    102],\n",
            "        [   101,  19803,  32650,  ...,  10262,  10446,    102],\n",
            "        ...,\n",
            "        [   101,    183,  31644,  ...,      0,      0,      0],\n",
            "        [   101,  13497,  24132,  ...,      0,      0,      0],\n",
            "        [   101,  20220,  10330,  ...,  37495,  10127,    102]])\n",
            "tensor([[  101, 18484, 37838,  ...,     0,     0,     0],\n",
            "        [  101, 26037, 26417,  ...,     0,     0,     0],\n",
            "        [  101, 11589, 75980,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 31301, 48985,  ..., 10305,   117,   102],\n",
            "        [  101, 35649, 42622,  ...,     0,     0,     0],\n",
            "        [  101,   162, 10294,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 49004, 69765,  ..., 20569, 11127,   102],\n",
            "        [  101, 11982, 58562,  ...,     0,     0,     0],\n",
            "        [  101, 35562, 17353,  ..., 30471,   181,   102],\n",
            "        ...,\n",
            "        [  101, 46800, 10406,  ..., 14773, 79118,   102],\n",
            "        [  101, 51935, 10147,  ..., 12783, 10713,   102],\n",
            "        [  101, 19644, 11802,  ..., 14680, 23763,   102]])\n",
            "tensor([[  101, 94901, 10738,  ..., 11281, 59879,   102],\n",
            "        [  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        [  101, 13448,   196,  ..., 68701, 10824,   102],\n",
            "        ...,\n",
            "        [  101,   134,   134,  ...,   123,   119,   102],\n",
            "        [  101, 11045, 10477,  ..., 36544, 10305,   102],\n",
            "        [  101, 11766, 10410,  ..., 35101, 10129,   102]])\n",
            "tensor([[   101,  13697, 100025,  ...,      0,      0,      0],\n",
            "        [   101,  58803,  28489,  ...,  38356,  19636,    102],\n",
            "        [   101,  51457,  14875,  ...,    119,    119,    102],\n",
            "        ...,\n",
            "        [   101,  11045,  21114,  ...,  25506,  10305,    102],\n",
            "        [   101,  49869,  73884,  ...,  15688,  22394,    102],\n",
            "        [   101,  10824,    117,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 25141, 10154,  ..., 10262, 10685,   102],\n",
            "        [  101,   157, 21722,  ..., 94701, 17736,   102],\n",
            "        [  101, 97126, 12396,  ...,   114, 10120,   102],\n",
            "        ...,\n",
            "        [  101, 10407, 10410,  ..., 13641, 68012,   102],\n",
            "        [  101,   171, 33472,  ..., 10192, 33452,   102],\n",
            "        [  101, 10159, 28416,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  47243,  23232,  ...,    262,  10153,    102],\n",
            "        [   101,  49869,  73884,  ...,      0,      0,      0],\n",
            "        [   101,  10469,  17145,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  10912,  10109,  ...,      0,      0,      0],\n",
            "        [   101,    122,    114,  ...,  34465,  47300,    102],\n",
            "        [   101,  23513,  88799,  ...,  11639, 105658,    102]])\n",
            "tensor([[   101,    113,    156,  ...,  10549,  10143,    102],\n",
            "        [   101,  13744,  41449,  ...,  36121,  11396,    102],\n",
            "        [   101,  10734, 100025,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  10281,  99269,  ...,  20324,  74156,    102],\n",
            "        [   101,  13069,  21292,  ...,      0,      0,      0],\n",
            "        [   101,  97978,  16334,  ...,  48261,  18342,    102]])\n",
            "tensor([[  101, 29005, 10506,  ..., 38941, 48261,   102],\n",
            "        [  101, 32916,   172,  ...,     0,     0,     0],\n",
            "        [  101,   153, 30546,  ..., 44131, 10104,   102],\n",
            "        ...,\n",
            "        [  101, 13026, 17039,  ..., 15494, 10262,   102],\n",
            "        [  101, 35248, 10605,  ...,     0,     0,     0],\n",
            "        [  101,   152, 10911,  ..., 10126, 11559,   102]])\n",
            "tensor([[  101, 10111, 10661,  ...,   102,     0,     0],\n",
            "        [  101, 55260, 18679,  ..., 12098, 10120,   102],\n",
            "        [  101,   142, 12843,  ...,   173, 12843,   102],\n",
            "        ...,\n",
            "        [  101, 63142, 10807,  ..., 84278, 10113,   102],\n",
            "        [  101, 10657, 12758,  ...,     0,     0,     0],\n",
            "        [  101,   156, 13306,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 12153,   196,  ...,   119, 13740,   102],\n",
            "        [  101, 31826, 51484,  ..., 45094, 19181,   102],\n",
            "        [  101, 78558, 13859,  ..., 22243,   113,   102],\n",
            "        ...,\n",
            "        [  101, 12017,   119,  ..., 12519,   119,   102],\n",
            "        [  101, 11982, 64316,  ...,   119, 73784,   102],\n",
            "        [  101, 11589, 67622,  ..., 10107, 10119,   102]])\n",
            "tensor([[  101, 16680, 62932,  ...,     0,     0,     0],\n",
            "        [  101,   169, 77937,  ..., 16334, 11608,   102],\n",
            "        [  101, 31301, 48985,  ..., 10305,   117,   102],\n",
            "        ...,\n",
            "        [  101, 11045, 21114,  ...,     0,     0,     0],\n",
            "        [  101, 10282, 25951,  ..., 32002, 11281,   102],\n",
            "        [  101, 11045, 21114,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 10224, 10121,  ..., 21753, 30967,   102],\n",
            "        [  101, 11982, 58562,  ..., 82849, 10121,   102],\n",
            "        [  101, 10190, 10402,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 49092, 10129,  ..., 10561,   172,   102],\n",
            "        [  101, 51457, 14875,  ..., 17049, 10406,   102],\n",
            "        [  101, 55260, 18679,  ...,   187, 71933,   102]])\n",
            "tensor([[   101,  20220,  10330,  ...,      0,      0,      0],\n",
            "        [   101,  10281,  11322,  ...,      0,      0,      0],\n",
            "        [   101,  84591,  13998,  ...,  10157,    113,    102],\n",
            "        ...,\n",
            "        [   101,  31826,  51484,  ...,      0,      0,      0],\n",
            "        [   101,  54394,  10323,  ...,    117,  23218,    102],\n",
            "        [   101, 101390,  10120,  ...,      0,      0,      0]])\n",
            "tensor([[   101,  23357,  10446,  ...,    187,  14319,    102],\n",
            "        [   101,  58901,  12229,  ...,  10120,  25313,    102],\n",
            "        [   101,  29968,  10147,  ...,  58735,  36903,    102],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,    175,  12369,    102],\n",
            "        [   101,  11357,  10116,  ...,    119,    119,    102],\n",
            "        [   101,  19561,  10133,  ...,  23005,  10115,    102]])\n",
            "tensor([[   101,  11982,    180,  ...,  20730,  10262,    102],\n",
            "        [   101,  68295,  10113,  ...,      0,      0,      0],\n",
            "        [   101,  93939,  10183,  ...,    113,  31078,    102],\n",
            "        ...,\n",
            "        [   101,  42096,  10229,  ...,  28581,  36544,    102],\n",
            "        [   101,  10734, 100025,  ...,      0,      0,      0],\n",
            "        [   101,  15595,  10921,  ...,      0,      0,      0]])\n",
            "tensor([[   101,    148,  44376,  ...,  11403,  11281,    102],\n",
            "        [   101,  37312,  10707,  ...,  98881,  18624,    102],\n",
            "        [   101,  93726,  10225,  ...,  25103,  41786,    102],\n",
            "        ...,\n",
            "        [   101,  11741,  74243,  ...,  10446,    173,    102],\n",
            "        [   101,  32916,  10173,  ...,  24159,  15393,    102],\n",
            "        [   101,    140, 110685,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 10258, 10410,  ..., 48610, 11499,   102],\n",
            "        [  101, 11543, 13778,  ..., 10118, 25506,   102],\n",
            "        [  101, 10657,   117,  ..., 11322, 40012,   102],\n",
            "        ...,\n",
            "        [  101, 56695, 10824,  ...,     0,     0,     0],\n",
            "        [  101, 61569, 10136,  ..., 81299, 36953,   102],\n",
            "        [  101, 10159, 25460,  ..., 17938, 15719,   102]])\n",
            "tensor([[  101, 58395, 10107,  ..., 10104, 21166,   102],\n",
            "        [  101, 11741, 10192,  ...,     0,     0,     0],\n",
            "        [  101, 87104, 12322,  ...,   175, 87179,   102],\n",
            "        ...,\n",
            "        [  101, 10224, 10911,  ...,   193, 10294,   102],\n",
            "        [  101, 32070, 11249,  ..., 11382,   136,   102],\n",
            "        [  101,   183, 10112,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  11045,  21114,  ...,  44798,  19613,    102],\n",
            "        [   101,    138,  49341,  ...,  10213,    193,    102],\n",
            "        [   101,    142,  10119,  ...,  30791,    136,    102],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  10305,    119,    102],\n",
            "        [   101,  10734, 100025,  ...,  36217,  16054,    102],\n",
            "        [   101,  11916,  16818,  ...,  10104, 109995,    102]])\n",
            "tensor([[   101,  10282,  29346,  ...,      0,      0,      0],\n",
            "        [   101,    138,  10425,  ...,      0,      0,      0],\n",
            "        [   101,  63816,  10112,  ...,  10815,  10657,    102],\n",
            "        ...,\n",
            "        [   101,  10294,  10305,  ...,  10147,  15851,    102],\n",
            "        [   101,  10912,  10133,  ...,      0,      0,      0],\n",
            "        [   101,  10734, 100025,  ...,  19468,  10147,    102]])\n",
            "tensor([[   101,  10119,  85996,  ...,      0,      0,      0],\n",
            "        [   101,  31178,    117,  ...,  10944,  21964,    102],\n",
            "        [   101,  10167,  53174,  ...,  10143,  26588,    102],\n",
            "        ...,\n",
            "        [   101,  28248,  10201,  ...,    117,  16938,    102],\n",
            "        [   101,    180,  41559,  ...,      0,      0,      0],\n",
            "        [   101,  10734, 100025,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 23357, 19696,  ...,     0,     0,     0],\n",
            "        [  101, 10630, 41148,  ...,     0,     0,     0],\n",
            "        [  101, 18022, 10410,  ..., 10604, 21340,   102],\n",
            "        ...,\n",
            "        [  101, 51243, 16212,  ...,   114,   102,     0],\n",
            "        [  101, 23139, 10211,  ...,     0,     0,     0],\n",
            "        [  101, 97764,   118,  ..., 15091,   117,   102]])\n",
            "tensor([[  101, 39294, 24213,  ...,     0,     0,     0],\n",
            "        [  101, 10178, 12904,  ...,   102,     0,     0],\n",
            "        [  101, 12832, 10107,  ..., 10119, 13113,   102],\n",
            "        ...,\n",
            "        [  101, 45031, 14415,  ...,     0,     0,     0],\n",
            "        [  101,   142, 10525,  ..., 35265, 10342,   102],\n",
            "        [  101, 13744, 52952,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  10734, 100025,  ...,  33526,  10112,    102],\n",
            "        [   101,  12515,  48458,  ...,  56237,    114,    102],\n",
            "        [   101,  51457,  14875,  ...,  24044,  10419,    102],\n",
            "        ...,\n",
            "        [   101,  12882,  10157,  ...,  10543,  10104,    102],\n",
            "        [   101,    262,  92016,  ...,  10154,  76547,    102],\n",
            "        [   101,  78558,  13859,  ...,      0,      0,      0]])\n",
            "tensor([[   101,    142,  10119,  ...,  10840,  61937,    102],\n",
            "        [   101,  20220,  10330,  ...,  10183, 100745,    102],\n",
            "        [   101,  10734, 100025,  ...,  13483,  89350,    102],\n",
            "        ...,\n",
            "        [   101,  13304,    138,  ...,    119,    142,    102],\n",
            "        [   101,  10883,  16719,  ...,    131,  11524,    102],\n",
            "        [   101,  12399,  10406,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 95469, 11127,  ..., 18687, 10104,   102],\n",
            "        [  101, 21452, 10198,  ...,   117, 10186,   102],\n",
            "        [  101, 10109, 29095,  ...,   117, 10119,   102],\n",
            "        ...,\n",
            "        [  101,   120,   115,  ...,     0,     0,     0],\n",
            "        [  101, 40630, 48672,  ...,   169, 10192,   102],\n",
            "        [  101,   156, 10545,  ..., 15492, 38188,   102]])\n",
            "tensor([[   101,  64831,  10612,  ...,  10294,  20313,    102],\n",
            "        [   101,  20834,  47461,  ...,      0,      0,      0],\n",
            "        [   101,    142,  53543,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  11396,  11373,    102],\n",
            "        [   101,  12882,  10262,  ...,      0,      0,      0],\n",
            "        [   101,  26329,  14932,  ...,  10262,  11875,    102]])\n",
            "tensor([[   101,  10734, 100025,  ...,  10174,  31687,    102],\n",
            "        [   101,  21452,  61047,  ...,  14084,    119,    102],\n",
            "        [   101,  33763,    117,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  11982,  10269,  ...,  11211,    113,    102],\n",
            "        [   101,  13730,  28941,  ...,    119,    119,    102],\n",
            "        [   101,  10192,  17736,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 30186, 10775,  ..., 28780, 26127,   102],\n",
            "        [  101, 72251, 10451,  ..., 12583, 44773,   102],\n",
            "        [  101, 77014, 34522,  ..., 32650, 33498,   102],\n",
            "        ...,\n",
            "        [  101, 10243, 15289,  ..., 10183, 12921,   102],\n",
            "        [  101, 10282, 29346,  ..., 10164, 10328,   102],\n",
            "        [  101, 10462, 10410,  ..., 47461, 25506,   102]])\n",
            "tensor([[   101,  19372,  10171,  ..., 110767,  10173,    102],\n",
            "        [   101,  10109,  14045,  ...,    193,  10104,    102],\n",
            "        [   101,  11982,  77880,  ...,  12921,  10120,    102],\n",
            "        ...,\n",
            "        [   101,  10462,  10686,  ...,  15688,  32467,    102],\n",
            "        [   101,  20220,  10330,  ...,  10104,  10182,    102],\n",
            "        [   101,  10159,  19696,  ...,  17147,    129,    102]])\n",
            "tensor([[   101,  10734, 100025,  ...,  10713,  79118,    102],\n",
            "        [   101,  26037,  11044,  ...,  10493,  15176,    102],\n",
            "        [   101,  10657,  62621,  ...,    117,  10549,    102],\n",
            "        ...,\n",
            "        [   101,   1735,  16232,  ...,  44872,  12132,    102],\n",
            "        [   101,  24165,  10157,  ...,      0,      0,      0],\n",
            "        [   101,    122,    118,  ...,  26101,  20498,    102]])\n",
            "tensor([[   101,    153,  30546,  ...,  13687,    117,    102],\n",
            "        [   101,  69342,  82678,  ..., 110014,  93252,    102],\n",
            "        [   101,  50264,  10120,  ...,    153,  58060,    102],\n",
            "        ...,\n",
            "        [   101,  31826,  51484,  ...,      0,      0,      0],\n",
            "        [   101,    119,    119,  ...,      0,      0,      0],\n",
            "        [   101,  10827,  10686,  ...,  49152,  31644,    102]])\n",
            "tensor([[   101,  34987,  12680,  ...,    173,    118,    102],\n",
            "        [   101,  10734, 100025,  ...,  15546,  20227,    102],\n",
            "        [   101,  23357,  19696,  ...,  10340,  10154,    102],\n",
            "        ...,\n",
            "        [   101,  25148,  26941,  ...,      0,      0,      0],\n",
            "        [   101,    146,  26192,  ...,    136,  39412,    102],\n",
            "        [   101,  34387,  96327,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 84591,   117,  ...,   119,   118,   102],\n",
            "        [  101, 11045, 21114,  ...,   136, 38217,   102],\n",
            "        [  101, 25148, 44047,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 27158, 10543,  ...,     0,     0,     0],\n",
            "        [  101, 67302, 10347,  ..., 13078, 20357,   102],\n",
            "        [  101, 37294, 10323,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  11045,  21114,  ...,  33219,  64543,    102],\n",
            "        [   101,  11045,  10109,  ...,  63067,    119,    102],\n",
            "        [   101,  10462,  10686,  ...,  23763,  57797,    102],\n",
            "        ...,\n",
            "        [   101,  10446,  13080,  ...,  11627, 107040,    102],\n",
            "        [   101,    141,  10549,  ...,      0,      0,      0],\n",
            "        [   101,  14890,  13337,  ...,  54497,    119,    102]])\n",
            "tensor([[  101, 23886, 27012,  ..., 10153, 24960,   102],\n",
            "        [  101, 51946, 11741,  ...,     0,     0,     0],\n",
            "        [  101, 13338, 36396,  ..., 16312, 66114,   102],\n",
            "        ...,\n",
            "        [  101,   138, 13406,  ...,     0,     0,     0],\n",
            "        [  101, 14890, 10173,  ...,   113, 10106,   102],\n",
            "        [  101, 29005, 10506,  ..., 10368, 31687,   102]])\n",
            "tensor([[   101,  51457,  14875,  ...,      0,      0,      0],\n",
            "        [   101,    349,  10138,  ...,      0,      0,      0],\n",
            "        [   101,  10734, 100025,  ...,  36621,  71246,    102],\n",
            "        ...,\n",
            "        [   101,  23886,  27012,  ...,    196,  12186,    102],\n",
            "        [   101,    224,  13666,  ...,  11445,    114,    102],\n",
            "        [   101,  10882,  12407,  ...,  52065,  83728,    102]])\n",
            "tensor([[   101,  35555,  10403,  ...,    119,  25148,    102],\n",
            "        [   101,  39999,  59879,  ...,    119,  17935,    102],\n",
            "        [   101,  93939,  10183,  ..., 106734,    169,    102],\n",
            "        ...,\n",
            "        [   101,  10730,  25616,  ...,    179,  10713,    102],\n",
            "        [   101,  60786,  18985,  ...,  10113,    189,    102],\n",
            "        [   101,  11045,  21114,  ...,  23218,  14302,    102]])\n",
            "tensor([[  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        [  101, 31301, 48985,  ..., 10305,   117,   102],\n",
            "        [  101, 37312, 10707,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 91075, 11517,  ...,   138, 86643,   102],\n",
            "        [  101, 55260, 18679,  ...,     0,     0,     0],\n",
            "        [  101, 52271, 31282,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 30665, 16819,  ...,     0,     0,     0],\n",
            "        [  101, 13069, 13410,  ..., 12132, 23882,   102],\n",
            "        [  101, 13304, 10419,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 58145, 32022,  ...,   102,     0,     0],\n",
            "        [  101, 19642, 10891,  ..., 89512, 10466,   102],\n",
            "        [  101,   157, 11281,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 11045, 15632,  ...,     0,     0,     0],\n",
            "        [  101,   131, 32070,  ..., 31230,   119,   102],\n",
            "        [  101, 14723, 14496,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 21469,   177,  ...,     0,     0,     0],\n",
            "        [  101, 49092, 41249,  ..., 10638, 10164,   102],\n",
            "        [  101, 20220, 10330,  ..., 19180, 11282,   102]])\n",
            "tensor([[  101, 20220, 10330,  ..., 10104, 18094,   102],\n",
            "        [  101, 25148, 62764,  ...,   119,   168,   102],\n",
            "        [  101, 51457, 14875,  ..., 15003,   119,   102],\n",
            "        ...,\n",
            "        [  101,   116, 11916,  ...,   114, 14261,   102],\n",
            "        [  101, 10159, 44555,  ..., 14638, 29121,   102],\n",
            "        [  101,   156, 13306,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 11916, 12783,  ...,     0,     0,     0],\n",
            "        [  101, 10282, 16966,  ..., 12211, 80808,   102],\n",
            "        [  101,   162, 17053,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 13605, 10294,  ...,     0,     0,     0],\n",
            "        [  101, 14200, 10317,  ...,     0,     0,     0],\n",
            "        [  101, 30186, 11147,  ..., 22942, 25896,   102]])\n",
            "tensor([[   101,    162, 102770,  ...,      0,      0,      0],\n",
            "        [   101,  20108,  12832,  ...,      0,      0,      0],\n",
            "        [   101,  43129,  10774,  ...,  11538,  28270,    102],\n",
            "        ...,\n",
            "        [   101,    119,    119,  ...,  16952,  10127,    102],\n",
            "        [   101,  11045,  48961,  ...,    119,    102,      0],\n",
            "        [   101,  10407,  10410,  ...,  52065,  13153,    102]])\n",
            "tensor([[  101, 13744, 10678,  ...,     0,     0,     0],\n",
            "        [  101, 90834,   117,  ..., 13364, 54877,   102],\n",
            "        [  101,   119,   119,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 25148, 13723,  ..., 29101, 10549,   102],\n",
            "        [  101, 51457, 14875,  ...,   173, 52952,   102],\n",
            "        [  101, 27729, 11639,  ..., 10124, 15976,   102]])\n",
            "tensor([[   101,  20220,  10330,  ...,  10165,    169,    102],\n",
            "        [   101,    157,  23229,  ...,  10678,  10143,    102],\n",
            "        [   101,  51935,  10147,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  75850,  11744,  ...,  82394,  10835,    102],\n",
            "        [   101,    224,  27582,  ...,    190, 101439,    102],\n",
            "        [   101,  89506,  10133,  ...,      0,      0,      0]])\n",
            "tensor([[  101,   140, 33472,  ...,   117, 10225,   102],\n",
            "        [  101, 10104, 10109,  ...,     0,     0,     0],\n",
            "        [  101, 70627, 10262,  ..., 86321, 12246,   102],\n",
            "        ...,\n",
            "        [  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        [  101, 15595, 14345,  ...,     0,     0,     0],\n",
            "        [  101, 35555, 10403,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  10734, 100025,  ...,  10115,  29392,    102],\n",
            "        [   101,  20220,  10330,  ...,  93939,    119,    102],\n",
            "        [   101,  20220,  10330,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  34589,  10115,    102],\n",
            "        [   101,  20220,  10330,  ...,  10302,    113,    102],\n",
            "        [   101,  12399,  11189,  ...,  21793,  96905,    102]])\n",
            "tensor([[  101, 13069, 82427,  ..., 45045, 10129,   102],\n",
            "        [  101, 14890, 11190,  ...,     0,     0,     0],\n",
            "        [  101,   118, 19496,  ..., 14323, 16490,   102],\n",
            "        ...,\n",
            "        [  101, 10159, 44287,  ...,     0,     0,     0],\n",
            "        [  101, 47197, 20267,  ..., 66570, 26146,   102],\n",
            "        [  101, 20220, 29956,  ..., 10106, 33687,   102]])\n",
            "tensor([[   101,  90233,  96955,  ...,  46503,  11282,    102],\n",
            "        [   101,  10666,  50192,  ...,  15176,  61356,    102],\n",
            "        [   101,  31301,  10633,  ...,  10116,  18190,    102],\n",
            "        ...,\n",
            "        [   101,  14321,  10237,  ...,  10512,  29095,    102],\n",
            "        [   101,  13697, 100025,  ...,  12538,    172,    102],\n",
            "        [   101,  32992,  94954,  ...,      0,      0,      0]])\n",
            "tensor([[   101,    137,  61080,  ...,  13936,    136,    102],\n",
            "        [   101,  11045,  10446,  ...,  82427,  31510,    102],\n",
            "        [   101,  10657,  12994,  ...,  95682, 100891,    102],\n",
            "        ...,\n",
            "        [   101,  51457,  14875,  ...,  31804,  73662,    102],\n",
            "        [   101,  10357,  19614,  ...,  85198,  10310,    102],\n",
            "        [   101,  10106,  10262,  ...,  45726,  10113,    102]])\n",
            "tensor([[  101, 58901, 10153,  ..., 57243, 15561,   102],\n",
            "        [  101, 11982, 64741,  ...,     0,     0,     0],\n",
            "        [  101, 10201, 10320,  ..., 10361, 48961,   102],\n",
            "        ...,\n",
            "        [  101, 35888, 36929,  ...,     0,     0,     0],\n",
            "        [  101, 10824, 13868,  ..., 14332,   169,   102],\n",
            "        [  101, 10657, 10312,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 20153, 10120,  ...,     0,     0,     0],\n",
            "        [  101, 11499, 10824,  ..., 25896, 10104,   102],\n",
            "        [  101, 10838, 49158,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 71968, 94918,  ...,     0,     0,     0],\n",
            "        [  101, 53412,   117,  ..., 12841, 10129,   102],\n",
            "        [  101, 10883, 13782,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 13056, 12436,  ..., 13559, 12177,   102],\n",
            "        [  101, 86462, 76486,  ...,     0,     0,     0],\n",
            "        [  101, 11045, 10228,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 13810, 10216,  ...,     0,     0,     0],\n",
            "        [  101, 24625, 12216,  ..., 10136, 36088,   102],\n",
            "        [  101, 16336, 14382,  ..., 27244, 62355,   102]])\n",
            "tensor([[   101,  10243,  10630,  ...,    119,  10709,    102],\n",
            "        [   101,    224,  39759,  ...,  10171,  10104,    102],\n",
            "        [   101,  51457,  14875,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  30909,  66014,  ...,  10121,  13605,    102],\n",
            "        [   101,  10824,  15004,  ...,      0,      0,      0],\n",
            "        [   101,  24466, 104840,  ...,  89957,  46123,    102]])\n",
            "tensor([[  101, 10243, 39898,  ...,     0,     0,     0],\n",
            "        [  101, 10657, 10355,  ..., 10121, 11395,   102],\n",
            "        [  101, 14890, 10228,  ..., 10119, 13621,   102],\n",
            "        ...,\n",
            "        [  101, 27746, 98974,  ...,     0,     0,     0],\n",
            "        [  101, 20220, 10330,  ..., 17623, 10192,   102],\n",
            "        [  101, 10258, 10410,  ..., 10824, 71339,   102]])\n",
            "tensor([[   101,  10734, 100025,  ...,  33987,  34677,    102],\n",
            "        [   101,  11818,  32467,  ...,    119,  12786,    102],\n",
            "        [   101,    142,  84732,  ...,  10110,  10153,    102],\n",
            "        ...,\n",
            "        [   101,  10159,  61101,  ...,  89900,  10286,    102],\n",
            "        [   101,  10462,  10686,  ...,  57797,  18932,    102],\n",
            "        [   101,  13929,  18012,  ...,  10341,  71959,    102]])\n",
            "tensor([[   101,    199,  43209,  ...,  11703,  21744,    102],\n",
            "        [   101,  10159,  13418,  ...,      0,      0,      0],\n",
            "        [   101,  71020,  11369,  ...,  89696,  52980,    102],\n",
            "        ...,\n",
            "        [   101,  13697, 100025,  ...,  34589,  10115,    102],\n",
            "        [   101,  11045,  21114,  ...,  10390,  92287,    102],\n",
            "        [   101,  10657,  10824,  ...,      0,      0,      0]])\n",
            "tensor([[   101,  19803,  43092,  ...,    117,  15606,    102],\n",
            "        [   101,  10734, 100025,  ...,  86132,  10305,    102],\n",
            "        [   101,  51457,  14875,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  13069,  10121,  ...,    102,      0,      0],\n",
            "        [   101,  15838,  39584,  ...,  22567,    102,      0],\n",
            "        [   101, 106306,  51295,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 60120, 49540,  ..., 10815, 19026,   102],\n",
            "        [  101,   142, 10262,  ...,   114,   102,     0],\n",
            "        [  101,   198, 20065,  ..., 82867, 14434,   102],\n",
            "        ...,\n",
            "        [  101, 29033, 14325,  ...,     0,     0,     0],\n",
            "        [  101, 49056, 19180,  ..., 36544, 12583,   102],\n",
            "        [  101, 20220, 25472,  ..., 79423, 10162,   102]])\n",
            "tensor([[   101,  74909,    117,  ...,  10133,    119,    102],\n",
            "        [   101,  10556,    131,  ...,  10116,  10120,    102],\n",
            "        [   101,  56215, 101699,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,    131,  70182,  ...,      0,      0,      0],\n",
            "        [   101,  13069,  10261,  ...,    117, 109436,    102],\n",
            "        [   101,    119,    119,  ...,  28531,  11726,    102]])\n",
            "tensor([[   101,  13956,  65314,  ...,      0,      0,      0],\n",
            "        [   101,  79015,  11030,  ...,      0,      0,      0],\n",
            "        [   101,  57667,  10123,  ...,  10126,  55946,    102],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  28959,  53452,    102],\n",
            "        [   101,  66039,  40773,  ...,  25326,  47033,    102],\n",
            "        [   101,  11916,  13891,  ...,  28099,  31510,    102]])\n",
            "tensor([[  101, 20220, 10330,  ..., 10119, 43358,   102],\n",
            "        [  101, 10262, 14508,  ...,     0,     0,     0],\n",
            "        [  101,   144, 47854,  ..., 19733, 43425,   102],\n",
            "        ...,\n",
            "        [  101,   146, 13641,  ..., 10815,   119,   102],\n",
            "        [  101, 11045, 21114,  ...,     0,     0,     0],\n",
            "        [  101,   179, 38356,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  11045,  10477,  ...,    320,  25446,    102],\n",
            "        [   101,  11916, 101699,  ...,  11778,  10129,    102],\n",
            "        [   101,    156,  34871,  ...,  16285,  78183,    102],\n",
            "        ...,\n",
            "        [   101,  33461,  31282,  ...,  91118,  10129,    102],\n",
            "        [   101,  45423,  10229,  ...,  26101,  10774,    102],\n",
            "        [   101,  59482,  10157,  ...,      0,      0,      0]])\n",
            "tensor([[   101,  14302,  22076,  ...,      0,      0,      0],\n",
            "        [   101,  10734, 100025,  ...,  19733,  19385,    102],\n",
            "        [   101,  87295,  10104,  ...,  10320,  10320,    102],\n",
            "        ...,\n",
            "        [   101,  56695,  51427,  ...,  10854,  22849,    102],\n",
            "        [   101,  12954,    175,  ...,      0,      0,      0],\n",
            "        [   101,  58060,  10178,  ...,  55421,  10317,    102]])\n",
            "tensor([[  101,   146, 13641,  ..., 53953, 10418,   102],\n",
            "        [  101, 51457, 14875,  ..., 66956, 11355,   102],\n",
            "        [  101, 19803, 14541,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 19803, 32650,  ..., 12132, 12211,   102],\n",
            "        [  101, 46624, 10104,  ...,     0,     0,     0],\n",
            "        [  101, 30186, 21125,  ..., 98881, 21125,   102]])\n",
            "tensor([[  101, 29033, 27452,  ...,     0,     0,     0],\n",
            "        [  101, 25444, 10161,  ..., 96684, 18257,   102],\n",
            "        [  101, 11499, 18812,  ..., 64428, 22934,   102],\n",
            "        ...,\n",
            "        [  101, 10282, 26192,  ..., 11403,   142,   102],\n",
            "        [  101, 28941, 33219,  ..., 19385, 43871,   102],\n",
            "        [  101, 25148, 22444,  ...,   114,   193,   102]])\n",
            "tensor([[   101,  11101,  14945,  ...,  10120,  15696,    102],\n",
            "        [   101,  10734, 100025,  ...,      0,      0,      0],\n",
            "        [   101,  32992,  67292,  ...,  71033,  86001,    102],\n",
            "        ...,\n",
            "        [   101,    120,  10911,  ...,  31408,  18849,    102],\n",
            "        [   101,  10915, 110344,  ...,    118,    144,    102],\n",
            "        [   101,  14248,  10976,  ...,  46503,  13406,    102]])\n",
            "tensor([[  101, 11589, 30395,  ..., 10109, 10261,   102],\n",
            "        [  101, 10224, 82683,  ..., 12525, 10121,   102],\n",
            "        [  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 53453, 10129,  ..., 10165, 10390,   102],\n",
            "        [  101, 18082, 36612,  ...,   172, 48261,   102],\n",
            "        [  101, 64831, 10612,  ...,     0,     0,     0]])\n",
            "tensor([[  101,   118, 24165,  ...,     0,     0,     0],\n",
            "        [  101, 25148, 10285,  ...,     0,     0,     0],\n",
            "        [  101, 20220, 10330,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 55260, 18679,  ...,     0,     0,     0],\n",
            "        [  101,   162, 99903,  ...,   141, 75859,   102],\n",
            "        [  101, 25067, 46876,  ..., 56455, 10245,   102]])\n",
            "tensor([[  101,   232, 11140,  ..., 19093, 10815,   102],\n",
            "        [  101, 20220, 10330,  ...,   119, 35207,   102],\n",
            "        [  101, 21557, 29948,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 19610, 30668,  ...,     0,     0,     0],\n",
            "        [  101, 22076, 10262,  ..., 63565, 10120,   102],\n",
            "        [  101, 11741, 10824,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 82608, 10245,  ...,   102,     0,     0],\n",
            "        [  101,   158, 29389,  ..., 10216, 50339,   102],\n",
            "        [  101,   195,   195,  ..., 56738, 14021,   102],\n",
            "        ...,\n",
            "        [  101, 31301, 48985,  ..., 10305,   117,   102],\n",
            "        [  101, 15189,   181,  ..., 15612,   119,   102],\n",
            "        [  101, 11641, 83722,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  34387,  18068,  ...,  45332,  85381,    102],\n",
            "        [   101,  19319, 102946,  ...,  27283,  12538,    102],\n",
            "        [   101,  31826,  51484,  ...,  70124,  15090,    102],\n",
            "        ...,\n",
            "        [   101, 106250,  10119,  ...,      0,      0,      0],\n",
            "        [   101,  44131,  10109,  ...,  12866,    131,    102],\n",
            "        [   101,  19319,  72274,  ...,  10147,  12369,    102]])\n",
            "tensor([[   101, 103960,  65600,  ...,  10703,  46503,    102],\n",
            "        [   101,  27158,  23683,  ..., 101439,  22219,    102],\n",
            "        [   101,  11045,  21114,  ..., 100035,  13998,    102],\n",
            "        ...,\n",
            "        [   101,    155,  10291,  ...,    136,    136,    102],\n",
            "        [   101,  13666,  10537,  ...,  10552,  10104,    102],\n",
            "        [   101,  11054,  10133,  ...,  10154,  34860,    102]])\n",
            "tensor([[  101, 24471,   193,  ..., 45513,   119,   102],\n",
            "        [  101, 19803, 10959,  ..., 22831, 10178,   102],\n",
            "        [  101, 10709, 10410,  ..., 13167, 10713,   102],\n",
            "        ...,\n",
            "        [  101, 49283, 11166,  ..., 84995, 30672,   102],\n",
            "        [  101, 20220, 77061,  ..., 63067,   173,   102],\n",
            "        [  101, 15068, 10119,  ...,   113, 92287,   102]])\n",
            "tensor([[  101, 53466, 18422,  ...,     0,     0,     0],\n",
            "        [  101, 10882, 12407,  ..., 37203, 10113,   102],\n",
            "        [  101, 51243, 62606,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 78558, 13859,  ...,     0,     0,     0],\n",
            "        [  101, 10190, 23208,  ..., 27582, 62944,   102],\n",
            "        [  101, 11045, 21114,  ...,   136, 19319,   102]])\n",
            "tensor([[  101, 20220, 10330,  ...,   114,   102,     0],\n",
            "        [  101, 10159, 12957,  ..., 16259, 10127,   102],\n",
            "        [  101, 25148, 10121,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 87104, 35840,  ...,     0,     0,     0],\n",
            "        [  101, 64831, 10612,  ..., 99528, 31408,   102],\n",
            "        [  101, 13304, 15851,  ..., 10104, 16054,   102]])\n",
            "tensor([[   101,  30247,  67871,  ...,  10369,  16453,    102],\n",
            "        [   101,  50858,  26506,  ...,  10815,  10104,    102],\n",
            "        [   101,  51457,  10340,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  10734, 100025,  ...,  15694,  12280,    102],\n",
            "        [   101,  44271,  60880,  ...,      0,      0,      0],\n",
            "        [   101,  27158,  11231,  ...,  83046,  36074,    102]])\n",
            "tensor([[  101, 20304, 18330,  ...,     0,     0,     0],\n",
            "        [  101, 49056, 10157,  ...,     0,     0,     0],\n",
            "        [  101, 10154, 17055,  ..., 44219,   177,   102],\n",
            "        ...,\n",
            "        [  101, 14890,   262,  ..., 10109, 76884,   102],\n",
            "        [  101, 19372, 23611,  ...,     0,     0,     0],\n",
            "        [  101, 11699, 10681,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 19655, 13439,  ...,     0,     0,     0],\n",
            "        [  101, 31826, 51484,  ..., 10112, 16054,   102],\n",
            "        [  101, 13098, 70995,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 12845, 84149,  ...,     0,     0,     0],\n",
            "        [  101, 11045, 21114,  ..., 33987, 19385,   102],\n",
            "        [  101, 23011, 11465,  ..., 56324, 57133,   102]])\n",
            "tensor([[   101,  11982,  58562,  ...,      0,      0,      0],\n",
            "        [   101,  11916,  13785,  ...,  37924,  26988,    102],\n",
            "        [   101,  19803,  31745,  ...,    169,  65399,    102],\n",
            "        ...,\n",
            "        [   101,  51457,  14875,  ...,  10446,    262,    102],\n",
            "        [   101,  18856,  10104,  ...,  18422,  44946,    102],\n",
            "        [   101, 103401,  15487,  ...,    119,  11303,    102]])\n",
            "tensor([[   101,  28031,  41449,  ...,      0,      0,      0],\n",
            "        [   101, 108755,  10116,  ...,  10262,  11395,    102],\n",
            "        [   101,  30665,    171,  ...,  10109,  38938,    102],\n",
            "        ...,\n",
            "        [   101,  20220,  10330,  ...,    119,  15531,    102],\n",
            "        [   101,    145,  39272,  ...,      0,      0,      0],\n",
            "        [   101,  20220,  30351,  ...,      0,      0,      0]])\n",
            "tensor([[   101,  40060,  10707,  ...,  55011,  45659,    102],\n",
            "        [   101,  11518,  24423,  ...,  96172, 109372,    102],\n",
            "        [   101,  19319,    148,  ...,  19130,  42020,    102],\n",
            "        ...,\n",
            "        [   101,    131,  70182,  ...,  64965,    113,    102],\n",
            "        [   101,  10190,  16054,  ...,  10549,  10143,    102],\n",
            "        [   101,  12515,  41249,  ...,      0,      0,      0]])\n",
            "tensor([[  101, 11741, 10106,  ...,   136, 49004,   102],\n",
            "        [  101, 10912, 63706,  ..., 10469, 93726,   102],\n",
            "        [  101, 10106, 42159,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 11045, 21114,  ..., 20227, 10143,   102],\n",
            "        [  101, 66977,   117,  ...,     0,     0,     0],\n",
            "        [  101, 37313, 12728,  ..., 15688, 32467,   102]])\n",
            "tensor([[  101,   141, 18913,  ..., 16239, 88357,   102],\n",
            "        [  101, 30186, 12805,  ..., 57817, 97349,   102],\n",
            "        [  101, 59170, 16822,  ..., 68701, 10561,   102],\n",
            "        ...,\n",
            "        [  101, 10282, 45598,  ..., 10106, 55858,   102],\n",
            "        [  101, 10282,   143,  ..., 13173, 16130,   102],\n",
            "        [  101, 23642, 10330,  ..., 10243,   179,   102]])\n",
            "tensor([[   101,  10282,  20710,  ...,  10390,  10740,    102],\n",
            "        [   101,  13672,  34969,  ...,      0,      0,      0],\n",
            "        [   101,  66558,  11669,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  45457, 109865,  ...,  10104,  10121,    102],\n",
            "        [   101,  11589,  30395,  ...,  10104, 110076,    102],\n",
            "        [   101,  51457,  10133,  ...,  10678,  39122,    102]])\n",
            "tensor([[  101, 10533, 10410,  ..., 24948, 19385,   102],\n",
            "        [  101, 51457, 14875,  ..., 10401,   119,   102],\n",
            "        [  101, 20220, 12843,  ..., 25896,   261,   102],\n",
            "        ...,\n",
            "        [  101, 12944, 10797,  ..., 25220, 10882,   102],\n",
            "        [  101,   320, 12843,  ..., 20024, 19093,   102],\n",
            "        [  101, 11238,   177,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  10734, 100025,  ...,  10245,  36621,    102],\n",
            "        [   101,  33884,  24140,  ...,  10262,  12132,    102],\n",
            "        [   101,  11589,  30395,  ...,  18874,  10119,    102],\n",
            "        ...,\n",
            "        [   101,  10243,  12655,  ...,  10406,  10261,    102],\n",
            "        [   101,  11322,  14875,  ...,      0,      0,      0],\n",
            "        [   101, 107249,  15628,  ...,  10330,  10794,    102]])\n",
            "tensor([[   101,  20220,  10330,  ...,  11266,  10543,    102],\n",
            "        [   101,  20220,  34016,  ...,    122,    117,    102],\n",
            "        [   101,  12384,  10611,  ...,  10410,  10175,    102],\n",
            "        ...,\n",
            "        [   101,  31282,  13005,  ..., 110744,  24491,    102],\n",
            "        [   101,  58060,  19501,  ...,  11924,  10237,    102],\n",
            "        [   101,  27113,  11382,  ...,  11779,  58521,    102]])\n",
            "tensor([[   101,  43882,  29291,  ...,    183,  10192,    102],\n",
            "        [   101,  47698,  10891,  ...,      0,      0,      0],\n",
            "        [   101,    138,  83426,  ...,  44287,  66558,    102],\n",
            "        ...,\n",
            "        [   101,  69765, 110014,  ...,  42622,  52338,    102],\n",
            "        [   101,  42096,  10229,  ...,  13672,  12659,    102],\n",
            "        [   101,  39327,  11669,  ..., 105775,    117,    102]])\n",
            "tensor([[  101, 12132, 10148,  ...,   136, 10446,   102],\n",
            "        [  101, 51457, 14875,  ..., 35052, 41640,   102],\n",
            "        [  101, 10190, 10320,  ..., 11769, 10797,   102],\n",
            "        ...,\n",
            "        [  101, 66039, 40773,  ..., 58895, 10707,   102],\n",
            "        [  101, 56215, 19468,  ...,     0,     0,     0],\n",
            "        [  101, 16680, 11540,  ...,     0,     0,     0]])\n",
            "tensor([[  101, 51457, 14875,  ..., 36237, 11014,   102],\n",
            "        [  101, 26329, 87264,  ...,     0,     0,     0],\n",
            "        [  101,   138, 10911,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,   153, 19031,  ...,     0,     0,     0],\n",
            "        [  101, 11122, 13227,  ..., 33694, 32524,   102],\n",
            "        [  101,   153, 19031,  ...,   117,   183,   102]])\n",
            "tensor([[   101,    146,  27285,  ...,  11259,    159,    102],\n",
            "        [   101,  10347,  10237,  ...,      0,      0,      0],\n",
            "        [   101,  80468,  11273,  ...,  58719,  29833,    102],\n",
            "        ...,\n",
            "        [   101,  36584,  10196,  ...,    102,      0,      0],\n",
            "        [   101,  10225,  10355,  ...,      0,      0,      0],\n",
            "        [   101,  78558,  13859,  ..., 105282,  21423,    102]])\n",
            "tensor([[   101,  10734, 100025,  ...,    175,  12369,    102],\n",
            "        [   101,  10224,  18434,  ...,      0,      0,      0],\n",
            "        [   101,  26363,  10121,  ...,  12900,  10133,    102],\n",
            "        ...,\n",
            "        [   101,  13744,  23859,  ...,  43548,  15091,    102],\n",
            "        [   101,  38508,  15181,  ...,      0,      0,      0],\n",
            "        [   101,  20220,  10330,  ...,  35314,  10115,    102]])\n",
            "tensor([[   101,  51457,  14875,  ...,  10715,    114,    102],\n",
            "        [   101,  84591,    117,  ...,    106,    113,    102],\n",
            "        [   101,  29033, 107159,  ...,  12132,  29956,    102],\n",
            "        ...,\n",
            "        [   101,  68918,  11147,  ...,  90238,  10120,    102],\n",
            "        [   101,  22800,  10181,  ...,  53696,  48590,    102],\n",
            "        [   101,  25444,  13369,  ...,    136,  19745,    102]])\n",
            "tensor([[  101,   224, 27158,  ..., 57369, 19263,   102],\n",
            "        [  101, 10657,   117,  ...,   113, 31078,   102],\n",
            "        [  101, 19803, 26391,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 34607, 25898,  ...,     0,     0,     0],\n",
            "        [  101, 61354,   169,  ..., 10354, 18196,   102],\n",
            "        [  101,   140, 66058,  ...,     0,     0,     0]])\n",
            "tensor([[   101,  11916,  11015,  ...,      0,      0,      0],\n",
            "        [   101,  11916,  10824,  ...,  81843,  14212,    102],\n",
            "        [   101,  85198,  10310,  ...,  12944,  10797,    102],\n",
            "        ...,\n",
            "        [   101,    156,  19901,  ...,  10174,  10143,    102],\n",
            "        [   101,  10734, 100025,  ...,  91445,  11604,    102],\n",
            "        [   101,  60160,  85292,  ...,  13904,  10125,    102]])\n",
            "tensor([[  101, 10915, 10171,  ..., 10104, 10680,   102],\n",
            "        [  101, 13589, 10911,  ...,     0,     0,     0],\n",
            "        [  101, 27582, 11912,  ..., 10129, 10795,   102],\n",
            "        ...,\n",
            "        [  101, 20220, 29956,  ...,   119, 10282,   102],\n",
            "        [  101,   122,   118,  ...,     0,     0,     0],\n",
            "        [  101, 10357, 22076,  ...,   119, 10468,   102]])\n"
          ]
        }
      ],
      "source": [
        "for batch in validation_dataloader:\n",
        "    print(batch[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125\n"
          ]
        }
      ],
      "source": [
        "print(len(validation_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataset.TensorDataset object at 0x000001592A9452E0>\n"
          ]
        }
      ],
      "source": [
        "print(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "orwq6YqqggiW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nclass DistillBERTClass(torch.nn.Module):\\n    def __init__(self):\\n        super(DistillBERTClass, self).__init__()\\n        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\\n        self.pre_classifier = torch.nn.Linear(768, 768)\\n        self.dropout = torch.nn.Dropout(0.3)\\n        self.classifier = torch.nn.Linear(768, 2)\\n\\n    def forward(self, input_ids, attention_mask):\\n        print(\"A\")\\n        inp = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\\n        output_1 = self.l1(**inp)#(input_ids, attention_mask)\\n        print(\"B\")\\n        hidden_state = output_1[0]\\n        print(\"C\")\\n        pooler = hidden_state[:, 0]\\n        print(\"D\")\\n        pooler = self.pre_classifier(pooler)\\n        print(\"E\")\\n        pooler = torch.nn.ReLU()(pooler)\\n        print(\"F\")\\n        pooler = self.dropout(pooler)\\n        print(\"G\")\\n        output = self.classifier(pooler)\\n        print(\"H\")\\n        print(\"down\")\\n        print(\"output: \", output)\\n        return output\\n    '"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        print(\"A\")\n",
        "        inp = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "        output_1 = self.l1(**inp)#(input_ids, attention_mask)\n",
        "        print(\"B\")\n",
        "        hidden_state = output_1[0]\n",
        "        print(\"C\")\n",
        "        pooler = hidden_state[:, 0]\n",
        "        print(\"D\")\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        print(\"E\")\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        print(\"F\")\n",
        "        pooler = self.dropout(pooler)\n",
        "        print(\"G\")\n",
        "        output = self.classifier(pooler)\n",
        "        print(\"H\")\n",
        "        print(\"down\")\n",
        "        print(\"output: \", output)\n",
        "        return output\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.set_device(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "aGh-7askggiW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'vocab_transform.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'classifier.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'classifier.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "#model = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "5KC7eZf_ggiX"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "2C7tAnwGggiX"
      },
      "outputs": [],
      "source": [
        "#def calcuate_accu(big_idx, targets): #calculate accuracy of the model\n",
        "    #n_correct = (big_idx==targets).sum().item()\n",
        "    #return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "luzqxzLaggiX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#def train(epoch):\\n    tr_loss = 0\\n    n_correct = 0\\n    nb_tr_steps = 0\\n    nb_tr_examples = 0\\n    model.train()\\n    for _,data in enumerate(training_loader, 0):\\n        print(list(data.keys()))\\n        ids = data[\\'ids\\'].to(device, dtype = torch.long)\\n        mask = data[\\'mask\\'].to(device, dtype = torch.long)\\n        targets = data[\\'targets\\'].to(device, dtype = torch.long)\\n        # ids = data[\\'ids\\'].cuda().long()\\n        # mask = data[\\'mask\\'].cuda().long()\\n        # targets = data[\\'targets\\'].cuda().long()\\n        outputs = model(ids, mask)\\n        loss = loss_function(outputs,targets)\\n        tr_loss += loss.item()\\n        big_val, big_idx = torch.max(outputs.data, dim=1)\\n        n_correct += calcuate_accu(big_idx, targets)\\n\\n        #nb_tr_steps += 1\\n        #nb_tr_examples+=targets.size(0)\\n        \\n        #if _%5000==0:\\n            loss_step = tr_loss/nb_tr_steps\\n            accu_step = (n_correct*100)/nb_tr_examples \\n            print(f\"Training Loss per 5000 steps: {loss_step}\")\\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        \\n\\n    print(f\\'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}\\')\\n    epoch_loss = tr_loss/nb_tr_steps\\n    epoch_accu = (n_correct*100)/nb_tr_examples\\n    print(f\"Training Loss Epoch: {epoch_loss}\")\\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\\n\\n    return \\n'"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "#def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        print(list(data.keys()))\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "        # ids = data['ids'].cuda().long()\n",
        "        # mask = data['mask'].cuda().long()\n",
        "        # targets = data['targets'].cuda().long()\n",
        "        outputs = model(ids, mask)\n",
        "        loss = loss_function(outputs,targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "        #nb_tr_steps += 1\n",
        "        #nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        #if _%5000==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "AIA5WZXMggiY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfor epoch in range(3):\\n    epoch_loss = 0.0\\n    for (b_ix, batch) in enumerate(train_dataloader):\\n      print(batch)\\n      optimizer.zero_grad()\\n      ids = batch[\\'input_ids\\']        # tensor\\n      mask = batch[1]  # tensor\\n      lbls = batch[2]               # tensor\\n      outputs = model(ids,attention_mask=mask, targets=lbls)\\n      loss = outputs[0]\\n      epoch_loss += loss.item()  # accumulate batch loss\\n      loss.backward()\\n      optimizer.step()\\n      if b_ix % 5 == 0:  # 200 items is 20 batches of 10\\n        print(\" batch = %5d curr batch loss = %0.4f \" %         (b_ix, loss.item()))\\n      # if b_ix >= xx: break  # to save time for demo\\n    print(\"end epoch = %4d  epoch loss = %0.4f \" %       (epoch, epoch_loss))\\n    print(\"Training complete \")\\n'"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "for epoch in range(3):\n",
        "    epoch_loss = 0.0\n",
        "    for (b_ix, batch) in enumerate(train_dataloader):\n",
        "      print(batch)\n",
        "      optimizer.zero_grad()\n",
        "      ids = batch['input_ids']        # tensor\n",
        "      mask = batch[1]  # tensor\n",
        "      lbls = batch[2]               # tensor\n",
        "      outputs = model(ids,attention_mask=mask, targets=lbls)\n",
        "      loss = outputs[0]\n",
        "      epoch_loss += loss.item()  # accumulate batch loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if b_ix % 5 == 0:  # 200 items is 20 batches of 10\n",
        "        print(\" batch = %5d curr batch loss = %0.4f \" % \\\n",
        "        (b_ix, loss.item()))\n",
        "      # if b_ix >= xx: break  # to save time for demo\n",
        "    print(\"end epoch = %4d  epoch loss = %0.4f \" % \\\n",
        "      (epoch, epoch_loss))\n",
        "    print(\"Training complete \")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    500.    Elapsed: 0:03:58.\n",
            "  Batch    80  of    500.    Elapsed: 0:07:41.\n",
            "  Batch   120  of    500.    Elapsed: 0:11:22.\n",
            "  Batch   160  of    500.    Elapsed: 0:15:02.\n",
            "  Batch   200  of    500.    Elapsed: 0:18:42.\n",
            "  Batch   240  of    500.    Elapsed: 0:22:21.\n",
            "  Batch   280  of    500.    Elapsed: 0:26:00.\n",
            "  Batch   320  of    500.    Elapsed: 0:29:39.\n",
            "  Batch   360  of    500.    Elapsed: 0:33:18.\n",
            "  Batch   400  of    500.    Elapsed: 0:36:57.\n",
            "  Batch   440  of    500.    Elapsed: 0:40:35.\n",
            "  Batch   480  of    500.    Elapsed: 0:44:14.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:46:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.48\n",
            "  Validation took: 0:03:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    500.    Elapsed: 0:03:38.\n",
            "  Batch    80  of    500.    Elapsed: 0:07:16.\n",
            "  Batch   120  of    500.    Elapsed: 0:10:55.\n",
            "  Batch   160  of    500.    Elapsed: 0:14:33.\n",
            "  Batch   200  of    500.    Elapsed: 0:18:12.\n",
            "  Batch   240  of    500.    Elapsed: 0:21:51.\n",
            "  Batch   280  of    500.    Elapsed: 0:25:30.\n",
            "  Batch   320  of    500.    Elapsed: 0:29:08.\n",
            "  Batch   360  of    500.    Elapsed: 0:32:47.\n",
            "  Batch   400  of    500.    Elapsed: 0:36:25.\n",
            "  Batch   440  of    500.    Elapsed: 0:40:03.\n",
            "  Batch   480  of    500.    Elapsed: 0:43:42.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:45:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 0.80\n",
            "  Validation took: 0:03:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    500.    Elapsed: 0:03:38.\n",
            "  Batch    80  of    500.    Elapsed: 0:07:16.\n",
            "  Batch   120  of    500.    Elapsed: 0:10:54.\n",
            "  Batch   160  of    500.    Elapsed: 0:14:32.\n",
            "  Batch   200  of    500.    Elapsed: 0:18:11.\n",
            "  Batch   240  of    500.    Elapsed: 0:21:49.\n",
            "  Batch   280  of    500.    Elapsed: 0:25:27.\n",
            "  Batch   320  of    500.    Elapsed: 0:29:05.\n",
            "  Batch   360  of    500.    Elapsed: 0:32:43.\n",
            "  Batch   400  of    500.    Elapsed: 0:36:21.\n",
            "  Batch   440  of    500.    Elapsed: 0:39:58.\n",
            "  Batch   480  of    500.    Elapsed: 0:43:36.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:45:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:02:59\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    500.    Elapsed: 0:03:38.\n",
            "  Batch    80  of    500.    Elapsed: 0:07:15.\n",
            "  Batch   120  of    500.    Elapsed: 0:10:54.\n",
            "  Batch   160  of    500.    Elapsed: 0:14:31.\n",
            "  Batch   200  of    500.    Elapsed: 0:18:09.\n",
            "  Batch   240  of    500.    Elapsed: 0:21:47.\n",
            "  Batch   280  of    500.    Elapsed: 0:25:24.\n",
            "  Batch   320  of    500.    Elapsed: 0:29:02.\n",
            "  Batch   360  of    500.    Elapsed: 0:32:41.\n",
            "  Batch   400  of    500.    Elapsed: 0:36:18.\n",
            "  Batch   440  of    500.    Elapsed: 0:39:56.\n",
            "  Batch   480  of    500.    Elapsed: 0:43:34.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:45:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:03:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:14:23 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoc\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:46:03</td>\n",
              "      <td>0:03:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:45:31</td>\n",
              "      <td>0:03:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.17</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:45:25</td>\n",
              "      <td>0:02:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:45:23</td>\n",
              "      <td>0:03:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.29         0.48           0.85       0:46:03         0:03:02\n",
              "2               0.20         0.80           0.63       0:45:31         0:03:01\n",
              "3               0.17         0.59           0.82       0:45:25         0:02:59\n",
              "4               0.14         0.71           0.78       0:45:23         0:03:00"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%` not found.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,000 test sentences...\n",
            "  Batch    40  of     94.    Elapsed: 0:01:48.\n",
            "  Batch    80  of     94.    Elapsed: 0:03:37.\n",
            "    DONE.\n"
          ]
        }
      ],
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "t0 = time.time()\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for step,batch in enumerate(testing_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "  if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "    elapsed = format_time(time.time() - t0)\n",
        "    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(testing_dataloader), elapsed))\n",
        "\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toxic samples: 699 of 3000 (23.30%)\n"
          ]
        }
      ],
      "source": [
        "print('Toxic samples: %d of %d (%.2f%%)' % (df3.toxic.sum(), len(df3.toxic), (df3.toxic.sum() / len(df3.toxic) * 100.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[ 0.24871208, -0.5706789 ],\n",
            "       [ 0.9866019 , -1.3104534 ],\n",
            "       [ 2.6334898 , -2.9709299 ],\n",
            "       [ 1.1350842 , -1.4524695 ],\n",
            "       [ 1.9563595 , -2.3189394 ],\n",
            "       [ 3.08615   , -3.36703   ],\n",
            "       [ 0.0901994 , -0.39536664],\n",
            "       [ 3.0230162 , -3.316258  ],\n",
            "       [ 2.1108963 , -2.4529583 ],\n",
            "       [ 0.00368916, -0.28003964],\n",
            "       [ 2.827805  , -3.1599944 ],\n",
            "       [ 2.5646427 , -2.9203513 ],\n",
            "       [ 1.5777411 , -1.9322644 ],\n",
            "       [ 2.0924344 , -2.45437   ],\n",
            "       [-0.3094897 ,  0.05432946],\n",
            "       [-0.4735841 ,  0.21962158],\n",
            "       [ 2.986885  , -3.2851648 ],\n",
            "       [ 0.74665934, -1.0782636 ],\n",
            "       [ 2.8025713 , -3.150106  ],\n",
            "       [ 2.8188126 , -3.1432073 ],\n",
            "       [ 0.33537692, -0.6387907 ],\n",
            "       [ 2.4267008 , -2.8125076 ],\n",
            "       [ 0.5340896 , -0.8449312 ],\n",
            "       [ 1.6906191 , -2.0481403 ],\n",
            "       [ 2.4781735 , -2.836065  ],\n",
            "       [ 1.4660608 , -1.8114294 ],\n",
            "       [-0.12761389, -0.14030115],\n",
            "       [ 2.169318  , -2.550057  ],\n",
            "       [ 1.8786501 , -2.2302272 ],\n",
            "       [ 2.0285375 , -2.4051163 ],\n",
            "       [ 0.59976137, -0.9301604 ],\n",
            "       [ 2.5813186 , -2.9546692 ]], dtype=float32), array([[ 1.7593797 , -2.118058  ],\n",
            "       [ 2.273277  , -2.6237833 ],\n",
            "       [ 2.5657685 , -2.9140718 ],\n",
            "       [ 2.7074175 , -3.0509717 ],\n",
            "       [ 3.0604541 , -3.3303473 ],\n",
            "       [ 3.0634372 , -3.3407784 ],\n",
            "       [ 2.5344403 , -2.9076445 ],\n",
            "       [ 0.03112449, -0.31545845],\n",
            "       [ 2.0023668 , -2.3876185 ],\n",
            "       [ 0.3556092 , -0.6473856 ],\n",
            "       [ 2.134835  , -2.5135267 ],\n",
            "       [-1.7178468 ,  1.6568403 ],\n",
            "       [ 0.32291618, -0.62143534],\n",
            "       [-0.4840221 ,  0.2643794 ],\n",
            "       [ 2.0620031 , -2.4394023 ],\n",
            "       [ 1.5731369 , -1.8805324 ],\n",
            "       [ 1.4553344 , -1.8133737 ],\n",
            "       [ 1.7542528 , -2.121111  ],\n",
            "       [ 0.7165851 , -1.0480282 ],\n",
            "       [-1.2851813 ,  1.1556345 ],\n",
            "       [ 0.28446835, -0.56473684],\n",
            "       [-0.5154656 ,  0.27442524],\n",
            "       [-0.03921197, -0.21358301],\n",
            "       [ 2.2230115 , -2.588788  ],\n",
            "       [ 0.934606  , -1.258821  ],\n",
            "       [ 0.23098703, -0.51280195],\n",
            "       [ 1.5089089 , -1.8366826 ],\n",
            "       [ 1.7160175 , -2.0590444 ],\n",
            "       [ 1.9722553 , -2.310198  ],\n",
            "       [ 1.3335537 , -1.6584603 ],\n",
            "       [ 1.4937202 , -1.854827  ],\n",
            "       [ 2.3417974 , -2.7033598 ]], dtype=float32), array([[ 2.3223693 , -2.7137105 ],\n",
            "       [ 1.2506009 , -1.6016546 ],\n",
            "       [ 1.8357692 , -2.1959794 ],\n",
            "       [ 1.5960699 , -1.9466041 ],\n",
            "       [ 2.5743053 , -2.9377367 ],\n",
            "       [ 0.5948143 , -0.88682246],\n",
            "       [ 0.9997296 , -1.3250744 ],\n",
            "       [-0.5189712 ,  0.26197734],\n",
            "       [ 2.3344042 , -2.7187893 ],\n",
            "       [ 2.533066  , -2.860254  ],\n",
            "       [-0.88179606,  0.70102924],\n",
            "       [ 0.41511765, -0.71437633],\n",
            "       [ 1.8810636 , -2.261882  ],\n",
            "       [ 2.4909575 , -2.8341997 ],\n",
            "       [ 2.1378798 , -2.4924614 ],\n",
            "       [ 1.1654704 , -1.4754521 ],\n",
            "       [ 1.2384363 , -1.5741708 ],\n",
            "       [ 1.6906291 , -2.0444078 ],\n",
            "       [-1.0375324 ,  0.8635919 ],\n",
            "       [ 2.6302698 , -2.997216  ],\n",
            "       [ 1.0065569 , -1.311109  ],\n",
            "       [ 0.6071599 , -0.92128515],\n",
            "       [ 1.3925511 , -1.7436665 ],\n",
            "       [ 0.15652521, -0.45035282],\n",
            "       [ 1.8488642 , -2.204867  ],\n",
            "       [ 1.9028903 , -2.2812326 ],\n",
            "       [ 1.4793218 , -1.8293955 ],\n",
            "       [ 1.7292923 , -2.0885627 ],\n",
            "       [ 1.4753475 , -1.8339072 ],\n",
            "       [ 2.2959297 , -2.6422389 ],\n",
            "       [ 0.7539227 , -1.0533489 ],\n",
            "       [-2.0969985 ,  2.0980704 ]], dtype=float32), array([[ 2.1671376 , -2.53425   ],\n",
            "       [ 0.8520409 , -1.1684717 ],\n",
            "       [ 2.376079  , -2.760081  ],\n",
            "       [-0.08984242, -0.1828833 ],\n",
            "       [ 2.0704606 , -2.450113  ],\n",
            "       [-0.4144018 ,  0.19266571],\n",
            "       [ 2.3110507 , -2.662666  ],\n",
            "       [ 2.740452  , -3.074786  ],\n",
            "       [ 2.6895225 , -3.0451412 ],\n",
            "       [ 1.1172427 , -1.4621848 ],\n",
            "       [-0.00763435, -0.28794935],\n",
            "       [ 2.1943495 , -2.5353835 ],\n",
            "       [ 2.4028704 , -2.7764251 ],\n",
            "       [-0.03986208, -0.19939163],\n",
            "       [ 2.1036983 , -2.474219  ],\n",
            "       [ 1.4742675 , -1.8250275 ],\n",
            "       [-0.13940875, -0.14186186],\n",
            "       [ 2.6467712 , -3.0043714 ],\n",
            "       [ 2.2112396 , -2.5836391 ],\n",
            "       [ 1.1161952 , -1.473479  ],\n",
            "       [ 1.9996549 , -2.3809507 ],\n",
            "       [ 2.2250168 , -2.6036744 ],\n",
            "       [ 2.8705337 , -3.1958363 ],\n",
            "       [ 0.4315806 , -0.72404706],\n",
            "       [ 1.3404603 , -1.669019  ],\n",
            "       [ 0.70618564, -1.0278641 ],\n",
            "       [ 2.559933  , -2.9305441 ],\n",
            "       [ 1.6767005 , -2.0312042 ],\n",
            "       [ 1.2702302 , -1.6013602 ],\n",
            "       [ 1.4552925 , -1.8111553 ],\n",
            "       [ 1.5889567 , -1.9394716 ],\n",
            "       [ 1.3807615 , -1.6958481 ]], dtype=float32), array([[ 2.394697  , -2.761068  ],\n",
            "       [-2.208646  ,  2.2309864 ],\n",
            "       [ 2.3661878 , -2.743792  ],\n",
            "       [ 0.6316637 , -0.92753637],\n",
            "       [ 1.1347014 , -1.47081   ],\n",
            "       [ 1.8312464 , -2.196934  ],\n",
            "       [ 0.35075828, -0.66210544],\n",
            "       [ 1.2663598 , -1.5915247 ],\n",
            "       [ 1.1229423 , -1.4591366 ],\n",
            "       [ 2.36814   , -2.7374191 ],\n",
            "       [ 1.0787228 , -1.4001492 ],\n",
            "       [ 1.8207098 , -2.1724203 ],\n",
            "       [ 2.7447379 , -3.0727727 ],\n",
            "       [ 1.8976911 , -2.261669  ],\n",
            "       [ 1.7215084 , -2.088731  ],\n",
            "       [ 2.4065843 , -2.7667773 ],\n",
            "       [-0.21637549, -0.06102964],\n",
            "       [ 1.7865335 , -2.1527798 ],\n",
            "       [ 2.1894627 , -2.565155  ],\n",
            "       [ 2.3056195 , -2.6626656 ],\n",
            "       [ 1.7249881 , -2.0629778 ],\n",
            "       [ 1.3512567 , -1.7164971 ],\n",
            "       [ 2.8394873 , -3.1696298 ],\n",
            "       [ 0.04062371, -0.33124602],\n",
            "       [ 1.4587473 , -1.7770923 ],\n",
            "       [ 2.745292  , -3.0905838 ],\n",
            "       [ 2.568705  , -2.9206555 ],\n",
            "       [ 2.433282  , -2.7804172 ],\n",
            "       [-1.6767697 ,  1.5876132 ],\n",
            "       [ 1.5974954 , -1.9527279 ],\n",
            "       [ 2.0464346 , -2.4430344 ],\n",
            "       [ 2.0724251 , -2.41903   ]], dtype=float32), array([[-0.33406705,  0.06941638],\n",
            "       [ 0.9243761 , -1.2466881 ],\n",
            "       [ 0.6114782 , -0.93399763],\n",
            "       [ 2.4483306 , -2.8116953 ],\n",
            "       [ 1.7962976 , -2.1375425 ],\n",
            "       [ 2.6549008 , -2.9886684 ],\n",
            "       [ 1.885304  , -2.2596986 ],\n",
            "       [ 0.3422732 , -0.6538451 ],\n",
            "       [-0.60750604,  0.35328183],\n",
            "       [ 1.8597711 , -2.2235558 ],\n",
            "       [ 0.5055717 , -0.7900815 ],\n",
            "       [ 0.13342674, -0.41715953],\n",
            "       [ 1.5442226 , -1.8819042 ],\n",
            "       [ 2.4880588 , -2.8384602 ],\n",
            "       [ 2.7037008 , -3.0489907 ],\n",
            "       [ 2.1671011 , -2.5409167 ],\n",
            "       [ 1.6795695 , -2.0275447 ],\n",
            "       [ 2.6230638 , -2.9980493 ],\n",
            "       [ 2.3501112 , -2.7303207 ],\n",
            "       [ 1.9734532 , -2.3452206 ],\n",
            "       [ 0.17676823, -0.49929175],\n",
            "       [-0.11231685, -0.12797679],\n",
            "       [ 0.31222978, -0.62883407],\n",
            "       [ 1.2531184 , -1.5928785 ],\n",
            "       [ 1.9363273 , -2.27053   ],\n",
            "       [-0.4349476 ,  0.20210037],\n",
            "       [ 1.8116215 , -2.169693  ],\n",
            "       [ 1.7662164 , -2.1297777 ],\n",
            "       [ 2.4162252 , -2.7994356 ],\n",
            "       [ 1.9679432 , -2.3332422 ],\n",
            "       [ 0.6629199 , -1.0118328 ],\n",
            "       [ 2.3047278 , -2.6691291 ]], dtype=float32), array([[ 0.18620913, -0.5027578 ],\n",
            "       [ 2.4752352 , -2.8336978 ],\n",
            "       [ 1.1237807 , -1.491043  ],\n",
            "       [ 0.39017424, -0.71695346],\n",
            "       [ 2.6340873 , -2.984793  ],\n",
            "       [ 0.05004652, -0.36449167],\n",
            "       [-1.9457457 ,  1.9393278 ],\n",
            "       [ 2.3901885 , -2.754834  ],\n",
            "       [-0.03460724, -0.28248823],\n",
            "       [ 1.6878847 , -2.0413573 ],\n",
            "       [ 2.1645033 , -2.5032828 ],\n",
            "       [ 0.74888945, -1.0620244 ],\n",
            "       [ 2.007007  , -2.3793616 ],\n",
            "       [ 1.3655094 , -1.690892  ],\n",
            "       [ 2.3892715 , -2.722541  ],\n",
            "       [ 2.3966148 , -2.7407026 ],\n",
            "       [-0.878055  ,  0.644025  ],\n",
            "       [ 2.9223745 , -3.2374556 ],\n",
            "       [ 2.2530856 , -2.6301687 ],\n",
            "       [ 2.5210419 , -2.890124  ],\n",
            "       [ 1.4846923 , -1.8542974 ],\n",
            "       [ 2.0810015 , -2.4580271 ],\n",
            "       [-1.9189212 ,  1.8584695 ],\n",
            "       [ 0.7299619 , -1.0451602 ],\n",
            "       [ 1.8919656 , -2.2411788 ],\n",
            "       [ 0.0209988 , -0.33231264],\n",
            "       [ 1.7702619 , -2.1200364 ],\n",
            "       [ 1.8125664 , -2.1884007 ],\n",
            "       [-2.1154912 ,  2.1121504 ],\n",
            "       [ 2.009943  , -2.3862002 ],\n",
            "       [-0.6060186 ,  0.359481  ],\n",
            "       [ 2.5096993 , -2.8809717 ]], dtype=float32), array([[ 1.6100554 , -1.9837579 ],\n",
            "       [ 0.49035183, -0.79981637],\n",
            "       [ 2.0978982 , -2.4933078 ],\n",
            "       [ 2.5681322 , -2.9290347 ],\n",
            "       [ 0.51988983, -0.8488096 ],\n",
            "       [ 2.0518682 , -2.4148781 ],\n",
            "       [ 1.6063255 , -1.9582489 ],\n",
            "       [ 0.06222795, -0.36824414],\n",
            "       [ 2.1276314 , -2.4842567 ],\n",
            "       [ 1.8997396 , -2.2746975 ],\n",
            "       [ 2.4937515 , -2.8487298 ],\n",
            "       [-0.18991758, -0.06775238],\n",
            "       [ 1.6752928 , -2.0085175 ],\n",
            "       [ 1.0054474 , -1.3473085 ],\n",
            "       [ 1.3356707 , -1.6462775 ],\n",
            "       [-0.9313829 ,  0.75954795],\n",
            "       [ 1.7810086 , -2.1448    ],\n",
            "       [ 2.0933137 , -2.4516327 ],\n",
            "       [ 1.8207184 , -2.1752717 ],\n",
            "       [ 2.3943162 , -2.759259  ],\n",
            "       [ 0.3844181 , -0.70896554],\n",
            "       [ 2.3800554 , -2.7628095 ],\n",
            "       [-1.3209563 ,  1.2102319 ],\n",
            "       [-1.5337824 ,  1.4123574 ],\n",
            "       [ 0.88995725, -1.2335218 ],\n",
            "       [-1.7304426 ,  1.6592882 ],\n",
            "       [ 0.34706283, -0.60201776],\n",
            "       [ 1.3539286 , -1.7245884 ],\n",
            "       [ 2.7180338 , -3.068028  ],\n",
            "       [ 1.0799667 , -1.3799453 ],\n",
            "       [ 1.2469863 , -1.5814036 ],\n",
            "       [ 2.3621898 , -2.7249677 ]], dtype=float32), array([[ 1.6326797 , -1.9996722 ],\n",
            "       [ 1.6492875 , -1.9799404 ],\n",
            "       [ 1.6844393 , -2.0460353 ],\n",
            "       [ 2.060862  , -2.417989  ],\n",
            "       [-2.3935523 ,  2.4334671 ],\n",
            "       [ 1.673028  , -2.023854  ],\n",
            "       [-0.3668507 ,  0.09338835],\n",
            "       [ 0.92430377, -1.2649113 ],\n",
            "       [ 2.446688  , -2.7996    ],\n",
            "       [ 1.823676  , -2.1889935 ],\n",
            "       [ 2.0605786 , -2.4265304 ],\n",
            "       [ 3.0951984 , -3.3606145 ],\n",
            "       [ 0.9359022 , -1.2627503 ],\n",
            "       [ 2.0257733 , -2.3840225 ],\n",
            "       [ 2.5985754 , -2.9149337 ],\n",
            "       [ 2.7636378 , -3.1136181 ],\n",
            "       [ 3.0302198 , -3.316799  ],\n",
            "       [ 0.9630979 , -1.3130392 ],\n",
            "       [-1.1961275 ,  1.0672327 ],\n",
            "       [ 2.7445433 , -3.0905545 ],\n",
            "       [ 1.0392445 , -1.3436154 ],\n",
            "       [ 1.2813966 , -1.6453879 ],\n",
            "       [ 1.9251211 , -2.3003986 ],\n",
            "       [-0.35727558,  0.13059168],\n",
            "       [ 2.2620904 , -2.62868   ],\n",
            "       [-0.87689275,  0.7514097 ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 1.6605386 , -2.0150647 ],\n",
            "       [ 1.5829422 , -1.928444  ],\n",
            "       [ 1.3416923 , -1.7010065 ],\n",
            "       [ 1.7034128 , -2.0450768 ],\n",
            "       [ 0.9128866 , -1.2636812 ]], dtype=float32), array([[ 1.1287165 , -1.4627949 ],\n",
            "       [-1.6290497 ,  1.5842772 ],\n",
            "       [ 2.1308002 , -2.4959953 ],\n",
            "       [ 2.1581504 , -2.543622  ],\n",
            "       [ 2.5767722 , -2.9445736 ],\n",
            "       [ 1.3959669 , -1.726943  ],\n",
            "       [-1.1343895 ,  0.9651892 ],\n",
            "       [ 0.51543456, -0.8390943 ],\n",
            "       [-0.03905497, -0.24378635],\n",
            "       [ 1.6994663 , -2.0452013 ],\n",
            "       [ 2.0971987 , -2.461923  ],\n",
            "       [ 0.76747847, -1.1245576 ],\n",
            "       [ 2.5724514 , -2.917082  ],\n",
            "       [-0.1057545 , -0.20713806],\n",
            "       [ 1.5676305 , -1.9231535 ],\n",
            "       [ 0.22305839, -0.5076205 ],\n",
            "       [ 1.1577741 , -1.4755348 ],\n",
            "       [ 2.3588884 , -2.7336714 ],\n",
            "       [-0.16590898, -0.07003145],\n",
            "       [ 0.7997739 , -1.1054993 ],\n",
            "       [-0.37256965,  0.13478433],\n",
            "       [ 2.268294  , -2.6195922 ],\n",
            "       [ 2.495151  , -2.8476064 ],\n",
            "       [ 2.812486  , -3.138676  ],\n",
            "       [ 2.7252433 , -3.0693781 ],\n",
            "       [-0.11075483, -0.16748731],\n",
            "       [ 0.19705401, -0.48167887],\n",
            "       [-0.47799155,  0.26818562],\n",
            "       [ 1.9506661 , -2.3139033 ],\n",
            "       [ 2.4630167 , -2.8158734 ],\n",
            "       [ 1.6375357 , -1.9800535 ],\n",
            "       [-0.0412509 , -0.25664076]], dtype=float32), array([[ 1.884697  , -2.2597945 ],\n",
            "       [ 2.9606118 , -3.2621036 ],\n",
            "       [ 2.7618363 , -3.101954  ],\n",
            "       [ 2.0148265 , -2.3885994 ],\n",
            "       [ 0.5338141 , -0.8534266 ],\n",
            "       [ 1.1670678 , -1.4929824 ],\n",
            "       [ 2.5072258 , -2.858671  ],\n",
            "       [ 2.2762878 , -2.644735  ],\n",
            "       [ 1.9108068 , -2.225995  ],\n",
            "       [-1.1184205 ,  0.93130535],\n",
            "       [-1.6493281 ,  1.578756  ],\n",
            "       [-1.8358043 ,  1.7593431 ],\n",
            "       [-1.9631606 ,  1.937365  ],\n",
            "       [ 2.2084744 , -2.5729651 ],\n",
            "       [-1.1660192 ,  1.0082964 ],\n",
            "       [ 2.3480046 , -2.716614  ],\n",
            "       [ 1.4480724 , -1.7896746 ],\n",
            "       [ 2.032639  , -2.3726296 ],\n",
            "       [ 0.3729622 , -0.64975405],\n",
            "       [-2.5060806 ,  2.5216482 ],\n",
            "       [ 0.9508464 , -1.2863903 ],\n",
            "       [ 1.7209629 , -2.0947435 ],\n",
            "       [ 2.9126973 , -3.2349913 ],\n",
            "       [ 1.3753699 , -1.7369941 ],\n",
            "       [ 2.047043  , -2.4051332 ],\n",
            "       [ 2.5407112 , -2.896777  ],\n",
            "       [ 2.4429553 , -2.8244696 ],\n",
            "       [ 1.6292528 , -1.9520687 ],\n",
            "       [ 1.4260765 , -1.7753216 ],\n",
            "       [-0.7752917 ,  0.5449558 ],\n",
            "       [ 0.4346541 , -0.7089963 ],\n",
            "       [ 2.5971236 , -2.9678857 ]], dtype=float32), array([[ 2.3561418 , -2.70305   ],\n",
            "       [ 2.4920838 , -2.8389776 ],\n",
            "       [ 2.0552886 , -2.424301  ],\n",
            "       [ 0.9867034 , -1.2869493 ],\n",
            "       [ 0.6214687 , -0.897441  ],\n",
            "       [-1.8159884 ,  1.7482888 ],\n",
            "       [ 0.9948929 , -1.3130687 ],\n",
            "       [ 2.0824678 , -2.4374034 ],\n",
            "       [ 2.1308002 , -2.4959953 ],\n",
            "       [ 0.26455334, -0.5479468 ],\n",
            "       [-1.1371356 ,  0.9772225 ],\n",
            "       [-1.2338631 ,  1.0830652 ],\n",
            "       [ 1.7552502 , -2.1177433 ],\n",
            "       [ 1.8962237 , -2.2672281 ],\n",
            "       [ 1.2757843 , -1.6052674 ],\n",
            "       [ 0.2916849 , -0.5925112 ],\n",
            "       [ 1.1689111 , -1.5021473 ],\n",
            "       [ 0.68583655, -0.9949962 ],\n",
            "       [ 1.8223935 , -2.1608076 ],\n",
            "       [-0.45459566,  0.19106631],\n",
            "       [ 2.0501602 , -2.4290376 ],\n",
            "       [ 1.0882518 , -1.4115988 ],\n",
            "       [ 0.76051915, -1.0861557 ],\n",
            "       [ 2.0159545 , -2.399062  ],\n",
            "       [ 1.692664  , -2.0391676 ],\n",
            "       [-0.91050875,  0.7581887 ],\n",
            "       [ 1.3964388 , -1.7481344 ],\n",
            "       [ 1.9038516 , -2.284548  ],\n",
            "       [ 2.0753987 , -2.4238806 ],\n",
            "       [ 0.2755514 , -0.5802015 ],\n",
            "       [ 0.88856566, -1.2128819 ],\n",
            "       [ 2.1354144 , -2.5132024 ]], dtype=float32), array([[ 2.6646123 , -3.030417  ],\n",
            "       [ 1.2103515 , -1.5314893 ],\n",
            "       [ 0.59483266, -0.9137739 ],\n",
            "       [ 2.51585   , -2.8867693 ],\n",
            "       [ 1.603996  , -1.9489061 ],\n",
            "       [ 2.7050986 , -3.0360055 ],\n",
            "       [-1.4017946 ,  1.2619694 ],\n",
            "       [ 2.404299  , -2.783261  ],\n",
            "       [ 2.7786582 , -3.1164062 ],\n",
            "       [ 0.31667152, -0.6256528 ],\n",
            "       [ 2.462416  , -2.841748  ],\n",
            "       [ 1.8632121 , -2.242174  ],\n",
            "       [-0.57905596,  0.36021656],\n",
            "       [-1.2895375 ,  1.1320926 ],\n",
            "       [-1.2362752 ,  1.0906078 ],\n",
            "       [ 1.3920721 , -1.7369124 ],\n",
            "       [ 1.788778  , -2.1456316 ],\n",
            "       [ 2.531665  , -2.8783062 ],\n",
            "       [ 2.7111416 , -3.0630362 ],\n",
            "       [-0.4723922 ,  0.2234364 ],\n",
            "       [ 2.1003451 , -2.474973  ],\n",
            "       [ 2.3767607 , -2.7182238 ],\n",
            "       [ 1.5059168 , -1.8551682 ],\n",
            "       [ 2.3004653 , -2.6584446 ],\n",
            "       [-0.36478195,  0.13732068],\n",
            "       [-0.25697166, -0.00939206],\n",
            "       [ 2.6894658 , -3.0106578 ],\n",
            "       [-0.39515665,  0.16854988],\n",
            "       [-1.6570908 ,  1.556698  ],\n",
            "       [ 2.3640914 , -2.7343447 ],\n",
            "       [ 1.0291901 , -1.3364589 ],\n",
            "       [ 2.5389404 , -2.8999887 ]], dtype=float32), array([[ 1.9999254 , -2.3561401 ],\n",
            "       [ 2.7122097 , -3.0501568 ],\n",
            "       [ 2.263976  , -2.6146357 ],\n",
            "       [ 2.2698236 , -2.6379416 ],\n",
            "       [ 2.5869381 , -2.9140031 ],\n",
            "       [ 0.8771653 , -1.1726693 ],\n",
            "       [ 2.5086854 , -2.8732703 ],\n",
            "       [ 0.6724259 , -0.9919903 ],\n",
            "       [ 2.071804  , -2.4554088 ],\n",
            "       [ 2.3305304 , -2.6942399 ],\n",
            "       [ 2.338385  , -2.7087061 ],\n",
            "       [ 1.2859509 , -1.6387061 ],\n",
            "       [ 2.7765718 , -3.1154234 ],\n",
            "       [ 1.3135965 , -1.6454655 ],\n",
            "       [ 2.4794865 , -2.8373153 ],\n",
            "       [ 2.746946  , -3.0891552 ],\n",
            "       [ 2.4146502 , -2.7837422 ],\n",
            "       [ 3.1216567 , -3.3814216 ],\n",
            "       [ 2.6141589 , -2.9489377 ],\n",
            "       [ 0.88914144, -1.2224865 ],\n",
            "       [ 2.7326555 , -3.0804303 ],\n",
            "       [ 2.211124  , -2.566845  ],\n",
            "       [ 1.7539693 , -2.1063085 ],\n",
            "       [ 1.4287721 , -1.7762958 ],\n",
            "       [ 2.5801084 , -2.9548233 ],\n",
            "       [-0.8253741 ,  0.6519959 ],\n",
            "       [ 0.9940393 , -1.2909304 ],\n",
            "       [ 1.7881404 , -2.121476  ],\n",
            "       [ 2.198434  , -2.5796978 ],\n",
            "       [ 0.4394453 , -0.7478431 ],\n",
            "       [ 2.9352612 , -3.2498913 ],\n",
            "       [ 1.8365875 , -2.2069821 ]], dtype=float32), array([[ 1.6238772 , -1.9620979 ],\n",
            "       [ 2.8580315 , -3.1653435 ],\n",
            "       [ 2.5706208 , -2.9201365 ],\n",
            "       [ 0.826072  , -1.1746267 ],\n",
            "       [ 2.406359  , -2.779386  ],\n",
            "       [ 1.9794762 , -2.353593  ],\n",
            "       [-0.75351536,  0.5393917 ],\n",
            "       [ 2.1037543 , -2.4688144 ],\n",
            "       [ 1.2183429 , -1.5612652 ],\n",
            "       [ 0.40831438, -0.7083181 ],\n",
            "       [ 1.1599501 , -1.5052013 ],\n",
            "       [ 0.3461232 , -0.630934  ],\n",
            "       [ 1.3201386 , -1.6651238 ],\n",
            "       [ 2.231065  , -2.6083314 ],\n",
            "       [ 2.5679624 , -2.918853  ],\n",
            "       [-1.1847779 ,  1.0343761 ],\n",
            "       [-0.6812958 ,  0.46797308],\n",
            "       [ 0.33390108, -0.64637446],\n",
            "       [-1.0114917 ,  0.8339784 ],\n",
            "       [ 2.523061  , -2.9008656 ],\n",
            "       [-0.53670543,  0.2872671 ],\n",
            "       [ 1.1975654 , -1.5217589 ],\n",
            "       [-1.9774309 ,  1.9388319 ],\n",
            "       [ 0.46767548, -0.7662116 ],\n",
            "       [ 2.4971948 , -2.8532524 ],\n",
            "       [ 2.4676492 , -2.8171837 ],\n",
            "       [ 2.190091  , -2.5627196 ],\n",
            "       [ 2.1701639 , -2.5438533 ],\n",
            "       [ 1.1775315 , -1.500193  ],\n",
            "       [ 2.3976765 , -2.7596526 ],\n",
            "       [ 0.07222142, -0.34779435],\n",
            "       [ 1.9052767 , -2.2473211 ]], dtype=float32), array([[ 2.863115  , -3.1842625 ],\n",
            "       [ 1.2885981 , -1.6226565 ],\n",
            "       [ 1.5611764 , -1.8891007 ],\n",
            "       [ 2.3702362 , -2.7405393 ],\n",
            "       [ 2.7213762 , -3.0775442 ],\n",
            "       [ 2.1329296 , -2.5040379 ],\n",
            "       [ 1.3540734 , -1.7004703 ],\n",
            "       [ 1.5151571 , -1.8710852 ],\n",
            "       [-0.9794098 ,  0.7895474 ],\n",
            "       [ 2.653548  , -3.0163548 ],\n",
            "       [-1.9770854 ,  1.9648753 ],\n",
            "       [ 2.4880798 , -2.863353  ],\n",
            "       [ 2.3493383 , -2.6879184 ],\n",
            "       [-1.9175497 ,  1.8762078 ],\n",
            "       [ 1.6890174 , -2.0605023 ],\n",
            "       [ 1.3770264 , -1.727092  ],\n",
            "       [-0.9185161 ,  0.73676753],\n",
            "       [ 1.8383577 , -2.21997   ],\n",
            "       [ 2.0709598 , -2.4492016 ],\n",
            "       [ 0.28636882, -0.5697819 ],\n",
            "       [ 2.3771865 , -2.7429945 ],\n",
            "       [-0.33760098,  0.10874362],\n",
            "       [ 0.2748195 , -0.6018281 ],\n",
            "       [-0.47585985,  0.24584647],\n",
            "       [ 2.4738123 , -2.8474002 ],\n",
            "       [ 0.679335  , -0.969243  ],\n",
            "       [ 1.653138  , -1.9952977 ],\n",
            "       [ 2.2293293 , -2.5956242 ],\n",
            "       [ 2.6081138 , -2.963261  ],\n",
            "       [ 2.4830084 , -2.8400607 ],\n",
            "       [ 1.7458397 , -2.0968955 ],\n",
            "       [ 1.913564  , -2.2594774 ]], dtype=float32), array([[ 0.04339205, -0.3211126 ],\n",
            "       [ 2.2600174 , -2.5985432 ],\n",
            "       [ 1.2348938 , -1.590161  ],\n",
            "       [ 2.521335  , -2.886089  ],\n",
            "       [ 0.8173787 , -1.1371437 ],\n",
            "       [-0.5614329 ,  0.35196277],\n",
            "       [-0.12523292, -0.1383427 ],\n",
            "       [ 0.98477614, -1.3297039 ],\n",
            "       [ 1.8785408 , -2.2556667 ],\n",
            "       [-1.4335767 ,  1.2941366 ],\n",
            "       [ 1.1956892 , -1.5424219 ],\n",
            "       [ 1.111064  , -1.4485866 ],\n",
            "       [ 1.707234  , -2.05392   ],\n",
            "       [ 1.1669747 , -1.5055015 ],\n",
            "       [ 2.6386607 , -2.9901633 ],\n",
            "       [ 2.1281087 , -2.5061607 ],\n",
            "       [ 2.6091862 , -2.9715483 ],\n",
            "       [ 1.7831976 , -2.1444829 ],\n",
            "       [ 1.8692236 , -2.2003095 ],\n",
            "       [ 2.0893028 , -2.4402359 ],\n",
            "       [-0.19010301, -0.0842191 ],\n",
            "       [ 1.8073903 , -2.1734297 ],\n",
            "       [ 2.681687  , -3.041332  ],\n",
            "       [ 2.5821974 , -2.9361742 ],\n",
            "       [ 0.6164471 , -0.9386995 ],\n",
            "       [ 0.72484565, -0.9989073 ],\n",
            "       [ 2.440434  , -2.7945395 ],\n",
            "       [ 1.8163317 , -2.1734898 ],\n",
            "       [-0.7480633 ,  0.5330777 ],\n",
            "       [ 0.8390683 , -1.1695472 ],\n",
            "       [ 1.5384432 , -1.8930262 ],\n",
            "       [ 0.1713414 , -0.45827544]], dtype=float32), array([[ 1.3104391 , -1.6476277 ],\n",
            "       [ 2.5217144 , -2.8829882 ],\n",
            "       [ 1.6153632 , -1.9976617 ],\n",
            "       [-1.8937377 ,  1.8310844 ],\n",
            "       [ 1.1489775 , -1.4827697 ],\n",
            "       [ 2.5433166 , -2.9086487 ],\n",
            "       [ 0.01186042, -0.26629654],\n",
            "       [-0.503168  ,  0.28478637],\n",
            "       [ 1.1699723 , -1.5086783 ],\n",
            "       [-0.08183018, -0.18571387],\n",
            "       [ 0.4857531 , -0.80700743],\n",
            "       [ 2.0185354 , -2.3922439 ],\n",
            "       [ 1.7837864 , -2.1370711 ],\n",
            "       [ 2.287474  , -2.638715  ],\n",
            "       [ 2.1654837 , -2.5334823 ],\n",
            "       [ 1.3017105 , -1.6369668 ],\n",
            "       [-0.49610955,  0.260595  ],\n",
            "       [ 2.5247636 , -2.8937688 ],\n",
            "       [ 2.7415297 , -3.0939698 ],\n",
            "       [-1.412006  ,  1.2672939 ],\n",
            "       [ 2.3958993 , -2.7681277 ],\n",
            "       [-2.184197  ,  2.1880991 ],\n",
            "       [ 2.2761452 , -2.646559  ],\n",
            "       [ 0.7457861 , -1.072409  ],\n",
            "       [-1.6959656 ,  1.6306854 ],\n",
            "       [ 0.804828  , -1.155703  ],\n",
            "       [-1.7301453 ,  1.6215066 ],\n",
            "       [ 1.982678  , -2.3353524 ],\n",
            "       [ 2.7638047 , -3.0987027 ],\n",
            "       [ 2.0147636 , -2.3825476 ],\n",
            "       [ 1.9637874 , -2.3117957 ],\n",
            "       [ 2.4958754 , -2.8681538 ]], dtype=float32), array([[-0.8719514 ,  0.69295126],\n",
            "       [-0.5578466 ,  0.29632244],\n",
            "       [ 1.2613633 , -1.6133864 ],\n",
            "       [ 2.8609638 , -3.165221  ],\n",
            "       [ 1.0563406 , -1.387075  ],\n",
            "       [-1.314786  ,  1.1641892 ],\n",
            "       [ 2.0236914 , -2.3854604 ],\n",
            "       [ 0.43426263, -0.7276327 ],\n",
            "       [ 2.668481  , -3.029596  ],\n",
            "       [ 0.9612037 , -1.2883276 ],\n",
            "       [ 2.5739772 , -2.9367378 ],\n",
            "       [ 2.299545  , -2.6682093 ],\n",
            "       [ 2.2102125 , -2.5632548 ],\n",
            "       [-1.7925438 ,  1.7083706 ],\n",
            "       [ 2.4688478 , -2.8429508 ],\n",
            "       [ 2.6728466 , -3.0338185 ],\n",
            "       [ 2.286026  , -2.6568587 ],\n",
            "       [ 1.1825153 , -1.5139827 ],\n",
            "       [ 2.6462977 , -2.9939919 ],\n",
            "       [ 0.7372357 , -1.0598761 ],\n",
            "       [ 0.31758985, -0.64271986],\n",
            "       [ 1.6762246 , -2.0405488 ],\n",
            "       [ 2.3292332 , -2.700268  ],\n",
            "       [-0.19307955, -0.07440193],\n",
            "       [ 2.509182  , -2.8628376 ],\n",
            "       [ 0.9383565 , -1.2757832 ],\n",
            "       [ 1.3331252 , -1.6981006 ],\n",
            "       [ 1.3366847 , -1.6701041 ],\n",
            "       [ 2.708792  , -3.067384  ],\n",
            "       [ 1.580387  , -1.937145  ],\n",
            "       [ 2.506681  , -2.8799326 ],\n",
            "       [ 2.5830705 , -2.945652  ]], dtype=float32), array([[ 2.4722788 , -2.827316  ],\n",
            "       [ 2.1884463 , -2.5199559 ],\n",
            "       [ 2.4833276 , -2.8559906 ],\n",
            "       [ 2.5677645 , -2.9423788 ],\n",
            "       [-0.4537907 ,  0.20207532],\n",
            "       [ 1.952875  , -2.3032315 ],\n",
            "       [ 1.5725516 , -1.9437133 ],\n",
            "       [ 1.6621853 , -2.0281043 ],\n",
            "       [ 2.0326827 , -2.3999195 ],\n",
            "       [ 2.485435  , -2.834369  ],\n",
            "       [ 1.7723551 , -2.1211133 ],\n",
            "       [ 1.6294816 , -1.983589  ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [-0.119909  , -0.14332093],\n",
            "       [ 1.307863  , -1.6464157 ],\n",
            "       [ 1.7401265 , -2.081304  ],\n",
            "       [ 0.5460218 , -0.83147883],\n",
            "       [-0.2505412 , -0.02249842],\n",
            "       [ 1.8427461 , -2.2191732 ],\n",
            "       [ 2.03637   , -2.4112556 ],\n",
            "       [ 2.7933915 , -3.1371863 ],\n",
            "       [ 2.387676  , -2.7452726 ],\n",
            "       [ 2.3571184 , -2.6800091 ],\n",
            "       [ 2.2693617 , -2.6107767 ],\n",
            "       [ 2.51771   , -2.858523  ],\n",
            "       [ 0.04498457, -0.33864298],\n",
            "       [ 2.9264524 , -3.2492075 ],\n",
            "       [-1.8236768 ,  1.7518923 ],\n",
            "       [ 1.4794222 , -1.8296202 ],\n",
            "       [ 1.8247824 , -2.1410599 ],\n",
            "       [ 2.378269  , -2.739319  ],\n",
            "       [ 2.2892916 , -2.6556845 ]], dtype=float32), array([[ 1.8694328 , -2.23716   ],\n",
            "       [ 2.7209737 , -3.0512917 ],\n",
            "       [-1.6671834 ,  1.571953  ],\n",
            "       [ 0.19533004, -0.48125944],\n",
            "       [ 2.427589  , -2.812915  ],\n",
            "       [ 0.514727  , -0.8106544 ],\n",
            "       [-1.3848265 ,  1.2480537 ],\n",
            "       [ 2.5370762 , -2.8955512 ],\n",
            "       [ 1.8939847 , -2.2550082 ],\n",
            "       [ 0.50588894, -0.78910935],\n",
            "       [ 2.1533453 , -2.5156672 ],\n",
            "       [ 2.3108857 , -2.6577451 ],\n",
            "       [ 2.9599645 , -3.2710493 ],\n",
            "       [ 0.41042307, -0.72143596],\n",
            "       [-1.5102993 ,  1.3694876 ],\n",
            "       [ 1.1385883 , -1.4910752 ],\n",
            "       [ 2.8226247 , -3.1577342 ],\n",
            "       [ 2.5985243 , -2.9755852 ],\n",
            "       [ 0.06050913, -0.33135644],\n",
            "       [ 0.14998977, -0.4688889 ],\n",
            "       [ 1.2285187 , -1.5651382 ],\n",
            "       [ 2.5850937 , -2.9339018 ],\n",
            "       [ 1.2977123 , -1.6442307 ],\n",
            "       [ 2.7805598 , -3.1031783 ],\n",
            "       [ 1.9382912 , -2.300152  ],\n",
            "       [ 1.9608042 , -2.3313015 ],\n",
            "       [ 1.5876139 , -1.9090917 ],\n",
            "       [ 2.242533  , -2.5913951 ],\n",
            "       [ 0.6372386 , -0.95858335],\n",
            "       [ 2.9381776 , -3.2569876 ],\n",
            "       [ 0.52421355, -0.8366038 ],\n",
            "       [ 2.5672433 , -2.9281206 ]], dtype=float32), array([[ 0.46842945, -0.81495655],\n",
            "       [ 0.32453886, -0.63241214],\n",
            "       [ 0.79887325, -1.128687  ],\n",
            "       [ 1.7537684 , -2.1071892 ],\n",
            "       [-1.2087461 ,  1.0348002 ],\n",
            "       [ 1.2166739 , -1.541015  ],\n",
            "       [ 1.3738455 , -1.7340909 ],\n",
            "       [ 1.8037041 , -2.1526628 ],\n",
            "       [ 2.2111738 , -2.5520802 ],\n",
            "       [ 0.5659169 , -0.87597066],\n",
            "       [ 2.0712538 , -2.4300172 ],\n",
            "       [-1.6267452 ,  1.5349686 ],\n",
            "       [ 2.0514696 , -2.432922  ],\n",
            "       [ 2.5157027 , -2.8643105 ],\n",
            "       [ 2.3588204 , -2.7212715 ],\n",
            "       [ 1.7226045 , -2.0751393 ],\n",
            "       [ 2.5736496 , -2.9362385 ],\n",
            "       [ 1.8525248 , -2.2209604 ],\n",
            "       [ 2.738425  , -3.084987  ],\n",
            "       [ 1.8844404 , -2.2248    ],\n",
            "       [ 2.319734  , -2.68628   ],\n",
            "       [ 2.4865901 , -2.8285189 ],\n",
            "       [-1.0301038 ,  0.8007251 ],\n",
            "       [ 2.3110414 , -2.6726344 ],\n",
            "       [-0.17441814, -0.08940505],\n",
            "       [ 1.8219746 , -2.213702  ],\n",
            "       [ 0.62282777, -0.911448  ],\n",
            "       [-0.06983636, -0.22762753],\n",
            "       [ 2.0144897 , -2.3786447 ],\n",
            "       [ 1.0028585 , -1.3013452 ],\n",
            "       [ 2.526655  , -2.8638813 ],\n",
            "       [ 1.6843318 , -2.0577638 ]], dtype=float32), array([[ 3.057243  , -3.3415346 ],\n",
            "       [ 2.1330972 , -2.4889815 ],\n",
            "       [ 2.4790666 , -2.8544621 ],\n",
            "       [ 2.147401  , -2.5110476 ],\n",
            "       [ 2.9408517 , -3.2416613 ],\n",
            "       [ 0.06789907, -0.32359877],\n",
            "       [ 1.6930737 , -2.0355113 ],\n",
            "       [ 1.6502634 , -2.0018969 ],\n",
            "       [ 0.06108995, -0.38102278],\n",
            "       [ 1.7194293 , -2.097533  ],\n",
            "       [ 2.3150253 , -2.7051532 ],\n",
            "       [ 0.27794513, -0.5706334 ],\n",
            "       [ 2.1035788 , -2.441007  ],\n",
            "       [ 1.1032752 , -1.4595569 ],\n",
            "       [ 2.6033049 , -2.9671447 ],\n",
            "       [ 2.029482  , -2.4001048 ],\n",
            "       [ 0.1142452 , -0.42360833],\n",
            "       [ 1.4817029 , -1.8449633 ],\n",
            "       [-2.5361865 ,  2.591194  ],\n",
            "       [ 1.9970862 , -2.3368394 ],\n",
            "       [ 2.147485  , -2.522373  ],\n",
            "       [ 2.080832  , -2.448753  ],\n",
            "       [ 2.7775073 , -3.1205604 ],\n",
            "       [ 2.2461355 , -2.6199486 ],\n",
            "       [-1.2826846 ,  1.1431918 ],\n",
            "       [ 1.8810424 , -2.2574794 ],\n",
            "       [ 3.1351812 , -3.3839898 ],\n",
            "       [ 0.38127044, -0.68704325],\n",
            "       [ 2.7257912 , -3.0711105 ],\n",
            "       [ 1.1090062 , -1.4192047 ],\n",
            "       [ 2.0368726 , -2.4039462 ],\n",
            "       [ 2.4898095 , -2.8409262 ]], dtype=float32), array([[ 0.2593029 , -0.5787252 ],\n",
            "       [ 2.8339388 , -3.1665878 ],\n",
            "       [ 1.2273921 , -1.5782965 ],\n",
            "       [-0.9706616 ,  0.78693485],\n",
            "       [ 0.9737689 , -1.2575052 ],\n",
            "       [-0.57591736,  0.3494536 ],\n",
            "       [ 0.6367259 , -0.95478976],\n",
            "       [ 2.5549622 , -2.9290404 ],\n",
            "       [ 2.5790503 , -2.9267595 ],\n",
            "       [ 0.62590224, -0.94982445],\n",
            "       [ 2.2923324 , -2.6603024 ],\n",
            "       [-0.7089742 ,  0.4966819 ],\n",
            "       [ 3.0463889 , -3.3351672 ],\n",
            "       [ 2.0097802 , -2.3731477 ],\n",
            "       [ 0.37970895, -0.66143537],\n",
            "       [ 1.4934837 , -1.8452982 ],\n",
            "       [ 0.9401875 , -1.28757   ],\n",
            "       [ 2.139918  , -2.4992938 ],\n",
            "       [ 1.4783012 , -1.8150696 ],\n",
            "       [ 0.8734449 , -1.2176248 ],\n",
            "       [-0.5038426 ,  0.23051272],\n",
            "       [ 2.019344  , -2.420789  ],\n",
            "       [ 2.8078487 , -3.1272342 ],\n",
            "       [ 2.1092231 , -2.4802086 ],\n",
            "       [ 0.48174924, -0.808442  ],\n",
            "       [-0.2523212 ,  0.02595739],\n",
            "       [ 1.9867486 , -2.3553474 ],\n",
            "       [ 2.1117985 , -2.465956  ],\n",
            "       [ 1.2086542 , -1.5500293 ],\n",
            "       [ 2.485288  , -2.8520448 ],\n",
            "       [ 0.87113595, -1.2133831 ],\n",
            "       [ 1.7385414 , -2.084257  ]], dtype=float32), array([[-1.0303222 ,  0.8704487 ],\n",
            "       [ 1.952875  , -2.3032315 ],\n",
            "       [ 1.918301  , -2.2827213 ],\n",
            "       [ 1.577606  , -1.9212531 ],\n",
            "       [ 1.8435498 , -2.2045615 ],\n",
            "       [ 2.1323435 , -2.4998362 ],\n",
            "       [ 2.4835494 , -2.8541899 ],\n",
            "       [ 1.9216769 , -2.3100483 ],\n",
            "       [ 2.5720978 , -2.9172065 ],\n",
            "       [ 2.7119162 , -3.0662925 ],\n",
            "       [ 2.5799828 , -2.95277   ],\n",
            "       [ 1.8275573 , -2.1904442 ],\n",
            "       [ 1.426775  , -1.7745478 ],\n",
            "       [ 1.8843095 , -2.2263196 ],\n",
            "       [-1.347823  ,  1.2143978 ],\n",
            "       [ 2.3035986 , -2.6826427 ],\n",
            "       [ 0.546642  , -0.86987376],\n",
            "       [ 2.4296052 , -2.7901745 ],\n",
            "       [ 0.24286498, -0.5344261 ],\n",
            "       [ 1.8831364 , -2.2521274 ],\n",
            "       [ 1.6656841 , -2.0012567 ],\n",
            "       [ 2.3675182 , -2.7148664 ],\n",
            "       [ 1.8975586 , -2.266494  ],\n",
            "       [ 0.66982776, -0.97469026],\n",
            "       [ 2.4075274 , -2.7765093 ],\n",
            "       [ 0.69480836, -1.0265388 ],\n",
            "       [-0.7614827 ,  0.56634593],\n",
            "       [ 2.0245178 , -2.395651  ],\n",
            "       [ 2.7088568 , -3.0496833 ],\n",
            "       [ 2.03111   , -2.3409956 ],\n",
            "       [ 1.4075168 , -1.7463145 ],\n",
            "       [ 2.4643574 , -2.7938316 ]], dtype=float32), array([[ 2.2591062 , -2.6208966 ],\n",
            "       [ 2.4616735 , -2.8288848 ],\n",
            "       [ 1.3017472 , -1.6338423 ],\n",
            "       [ 0.12760226, -0.41998973],\n",
            "       [ 2.938905  , -3.2487583 ],\n",
            "       [ 2.127039  , -2.462835  ],\n",
            "       [ 2.4059615 , -2.7769997 ],\n",
            "       [ 0.79866576, -1.1052998 ],\n",
            "       [-1.3632381 ,  1.2220672 ],\n",
            "       [ 1.3522657 , -1.6915189 ],\n",
            "       [ 0.36955723, -0.67870337],\n",
            "       [-1.0411768 ,  0.8536772 ],\n",
            "       [ 2.7513182 , -3.0686715 ],\n",
            "       [ 2.0712538 , -2.4300172 ],\n",
            "       [ 0.7209262 , -1.0290841 ],\n",
            "       [-2.0108087 ,  1.9908057 ],\n",
            "       [-1.1452037 ,  0.98881495],\n",
            "       [ 2.2237165 , -2.5984635 ],\n",
            "       [-1.5396897 ,  1.4366516 ],\n",
            "       [ 1.8138349 , -2.1739552 ],\n",
            "       [ 1.3169492 , -1.6355945 ],\n",
            "       [ 2.8394778 , -3.1650326 ],\n",
            "       [ 2.2025104 , -2.5737667 ],\n",
            "       [ 2.9644907 , -3.2444823 ],\n",
            "       [ 0.5978151 , -0.88691723],\n",
            "       [-2.1842048 ,  2.180521  ],\n",
            "       [-0.9128546 ,  0.71787393],\n",
            "       [ 0.6598224 , -0.9273951 ],\n",
            "       [ 1.7423373 , -2.1121027 ],\n",
            "       [ 1.8605605 , -2.2289112 ],\n",
            "       [ 2.0593917 , -2.41338   ],\n",
            "       [ 1.3096699 , -1.6594208 ]], dtype=float32), array([[ 1.1055326 , -1.4542266 ],\n",
            "       [ 2.4724104 , -2.8452933 ],\n",
            "       [ 1.3161827 , -1.6723493 ],\n",
            "       [-0.57369757,  0.35115626],\n",
            "       [ 1.4652176 , -1.8043497 ],\n",
            "       [ 1.6757485 , -2.047479  ],\n",
            "       [ 2.6180634 , -2.9800684 ],\n",
            "       [ 0.16958977, -0.46675017],\n",
            "       [ 0.9012308 , -1.2655643 ],\n",
            "       [ 2.9642875 , -3.2745688 ],\n",
            "       [ 1.6518927 , -1.9875417 ],\n",
            "       [ 2.0289285 , -2.4060264 ],\n",
            "       [ 1.3769286 , -1.7627584 ],\n",
            "       [ 1.8072233 , -2.1228373 ],\n",
            "       [ 2.0448146 , -2.4135041 ],\n",
            "       [ 1.595529  , -1.9443367 ],\n",
            "       [ 1.455967  , -1.7927188 ],\n",
            "       [-1.9693197 ,  1.9153044 ],\n",
            "       [ 0.6488428 , -0.98221534],\n",
            "       [ 0.4504396 , -0.76134896],\n",
            "       [ 2.2052639 , -2.5476608 ],\n",
            "       [ 2.0037813 , -2.3687994 ],\n",
            "       [ 2.747512  , -3.07835   ],\n",
            "       [ 2.3058498 , -2.6757042 ],\n",
            "       [ 1.9438368 , -2.2713652 ],\n",
            "       [ 2.1230872 , -2.493648  ],\n",
            "       [-0.96283716,  0.791565  ],\n",
            "       [ 2.5828986 , -2.9604807 ],\n",
            "       [ 1.3382725 , -1.6627803 ],\n",
            "       [ 0.45797345, -0.79152584],\n",
            "       [-0.27009612,  0.02485182],\n",
            "       [ 2.494097  , -2.8687544 ]], dtype=float32), array([[ 0.975057  , -1.3120406 ],\n",
            "       [ 0.48158255, -0.8278657 ],\n",
            "       [ 2.4597695 , -2.8302255 ],\n",
            "       [-1.1303617 ,  0.977715  ],\n",
            "       [ 2.8601587 , -3.1787858 ],\n",
            "       [ 1.5185574 , -1.8714112 ],\n",
            "       [ 1.9054633 , -2.2977998 ],\n",
            "       [ 2.58726   , -2.935866  ],\n",
            "       [ 2.1446216 , -2.5147169 ],\n",
            "       [-1.2507852 ,  1.0602378 ],\n",
            "       [ 2.0096388 , -2.3647418 ],\n",
            "       [ 2.015425  , -2.395271  ],\n",
            "       [ 1.3352324 , -1.6859506 ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 1.6795772 , -2.025678  ],\n",
            "       [ 2.631989  , -2.9795084 ],\n",
            "       [ 1.7498227 , -2.0706656 ],\n",
            "       [ 1.7352808 , -2.091378  ],\n",
            "       [ 2.324021  , -2.6856291 ],\n",
            "       [ 2.3930433 , -2.7539265 ],\n",
            "       [ 1.2702891 , -1.611048  ],\n",
            "       [ 3.128823  , -3.3826044 ],\n",
            "       [-0.64694834,  0.4542434 ],\n",
            "       [ 1.3170309 , -1.6771921 ],\n",
            "       [ 0.87773263, -1.1974059 ],\n",
            "       [ 2.4641178 , -2.8370497 ],\n",
            "       [-1.561086  ,  1.4350562 ],\n",
            "       [ 2.1202364 , -2.490925  ],\n",
            "       [ 2.2710466 , -2.6187625 ],\n",
            "       [ 2.5854335 , -2.9472957 ],\n",
            "       [ 2.0771537 , -2.4493587 ],\n",
            "       [ 2.458858  , -2.8160555 ]], dtype=float32), array([[ 2.2723837 , -2.6346767 ],\n",
            "       [ 0.07247918, -0.37554857],\n",
            "       [-1.6726445 ,  1.6092896 ],\n",
            "       [ 2.99148   , -3.2938282 ],\n",
            "       [ 1.0876349 , -1.4221319 ],\n",
            "       [ 2.0414715 , -2.4045951 ],\n",
            "       [ 2.7597158 , -3.0958037 ],\n",
            "       [ 1.853753  , -2.2132988 ],\n",
            "       [ 1.49724   , -1.8546306 ],\n",
            "       [ 0.56238794, -0.86931336],\n",
            "       [ 2.3268533 , -2.6762898 ],\n",
            "       [ 2.619222  , -2.9596827 ],\n",
            "       [ 2.648983  , -3.001675  ],\n",
            "       [ 2.7632217 , -3.0842922 ],\n",
            "       [ 0.380317  , -0.6895038 ],\n",
            "       [ 2.0113328 , -2.3928869 ],\n",
            "       [ 1.1607274 , -1.5078549 ],\n",
            "       [ 1.981322  , -2.3449905 ],\n",
            "       [-1.0666865 ,  0.9185175 ],\n",
            "       [ 2.5569222 , -2.9244182 ],\n",
            "       [ 2.9729965 , -3.2817547 ],\n",
            "       [ 1.418526  , -1.7561942 ],\n",
            "       [ 1.5738407 , -1.9155984 ],\n",
            "       [ 1.875154  , -2.2334144 ],\n",
            "       [-0.7296621 ,  0.49758255],\n",
            "       [ 1.8360173 , -2.1930478 ],\n",
            "       [ 1.1022652 , -1.448108  ],\n",
            "       [ 1.7552502 , -2.1177433 ],\n",
            "       [ 0.5982191 , -0.9189539 ],\n",
            "       [-0.07399959, -0.22257581],\n",
            "       [-0.94462   ,  0.768777  ],\n",
            "       [ 2.122231  , -2.4765625 ]], dtype=float32), array([[-1.3204782 ,  1.17207   ],\n",
            "       [ 2.0775073 , -2.4442718 ],\n",
            "       [ 2.2713473 , -2.6429877 ],\n",
            "       [ 2.11596   , -2.4798186 ],\n",
            "       [ 1.4662002 , -1.7950699 ],\n",
            "       [ 1.2451286 , -1.5981265 ],\n",
            "       [ 0.72894377, -1.0536706 ],\n",
            "       [-0.8369223 ,  0.62941897],\n",
            "       [ 2.7500155 , -3.0863466 ],\n",
            "       [ 2.183348  , -2.5480044 ],\n",
            "       [ 2.2868135 , -2.6250627 ],\n",
            "       [ 1.2061304 , -1.5521349 ],\n",
            "       [ 2.9720197 , -3.2678714 ],\n",
            "       [ 0.9377669 , -1.2724253 ],\n",
            "       [ 1.4285277 , -1.7556574 ],\n",
            "       [-2.3003805 ,  2.33998   ],\n",
            "       [ 0.8927641 , -1.1656619 ],\n",
            "       [ 1.0317175 , -1.3599662 ],\n",
            "       [-0.5824488 ,  0.35587814],\n",
            "       [ 2.1653857 , -2.5337775 ],\n",
            "       [ 1.6400386 , -2.0090008 ],\n",
            "       [ 1.3046207 , -1.6798593 ],\n",
            "       [-0.27686676,  0.03667353],\n",
            "       [ 2.465871  , -2.8360026 ],\n",
            "       [ 1.546704  , -1.9025949 ],\n",
            "       [ 1.4436743 , -1.800111  ],\n",
            "       [ 2.1169727 , -2.5013483 ],\n",
            "       [ 1.7255869 , -2.0423868 ],\n",
            "       [ 0.7454385 , -1.0760475 ],\n",
            "       [ 2.141076  , -2.4840765 ],\n",
            "       [ 0.9238722 , -1.2414304 ],\n",
            "       [ 0.6712842 , -0.96100605]], dtype=float32), array([[ 2.3187115 , -2.6750891 ],\n",
            "       [ 2.4907486 , -2.8153768 ],\n",
            "       [ 0.5024501 , -0.830637  ],\n",
            "       [ 2.2640111 , -2.6355245 ],\n",
            "       [ 0.31051436, -0.6012777 ],\n",
            "       [ 0.9866019 , -1.3104534 ],\n",
            "       [ 2.4165394 , -2.7895749 ],\n",
            "       [ 1.4156457 , -1.7744398 ],\n",
            "       [ 2.7168036 , -3.0610125 ],\n",
            "       [ 0.5319828 , -0.85049963],\n",
            "       [ 2.948754  , -3.2382324 ],\n",
            "       [ 1.0639713 , -1.3783326 ],\n",
            "       [ 2.2362468 , -2.5941043 ],\n",
            "       [-0.05986191, -0.20130055],\n",
            "       [ 2.2203948 , -2.5744998 ],\n",
            "       [-1.0549306 ,  0.88906336],\n",
            "       [ 1.8931347 , -2.2838032 ],\n",
            "       [ 2.1717274 , -2.519384  ],\n",
            "       [ 2.5434365 , -2.8952134 ],\n",
            "       [ 1.8308412 , -2.1740105 ],\n",
            "       [ 0.8003921 , -1.104568  ],\n",
            "       [ 1.3865255 , -1.7512312 ],\n",
            "       [ 3.0114582 , -3.2985528 ],\n",
            "       [ 2.8298342 , -3.1640217 ],\n",
            "       [ 1.3758785 , -1.739401  ],\n",
            "       [ 0.33805355, -0.6273428 ],\n",
            "       [ 2.4353654 , -2.793422  ],\n",
            "       [ 2.2463324 , -2.6144338 ],\n",
            "       [ 0.45568678, -0.76376057],\n",
            "       [ 2.0128133 , -2.3886228 ],\n",
            "       [ 1.9593986 , -2.3222294 ],\n",
            "       [ 1.7482463 , -2.1129982 ]], dtype=float32), array([[ 2.2763417 , -2.6376173 ],\n",
            "       [ 2.6694746 , -3.0319448 ],\n",
            "       [ 1.2750759 , -1.599008  ],\n",
            "       [ 1.426536  , -1.7813115 ],\n",
            "       [-1.7728168 ,  1.7081295 ],\n",
            "       [-0.52066225,  0.30479962],\n",
            "       [-2.4383762 ,  2.4645422 ],\n",
            "       [-1.2437192 ,  1.0899527 ],\n",
            "       [ 0.74252594, -1.0390859 ],\n",
            "       [ 1.8233606 , -2.176515  ],\n",
            "       [ 1.2921225 , -1.6369798 ],\n",
            "       [-1.2859116 ,  1.157055  ],\n",
            "       [ 2.113492  , -2.4876206 ],\n",
            "       [ 0.16323511, -0.4683874 ],\n",
            "       [ 1.4950018 , -1.8547144 ],\n",
            "       [ 2.546946  , -2.9236739 ],\n",
            "       [ 1.849637  , -2.2006426 ],\n",
            "       [ 1.9463959 , -2.3225415 ],\n",
            "       [-0.6904598 ,  0.51052845],\n",
            "       [ 2.6872814 , -3.0217018 ],\n",
            "       [ 0.93919724, -1.2766917 ],\n",
            "       [ 2.1524522 , -2.5160186 ],\n",
            "       [ 1.8112928 , -2.1590955 ],\n",
            "       [ 1.5333058 , -1.906494  ],\n",
            "       [ 2.5146224 , -2.8731701 ],\n",
            "       [ 1.7334442 , -2.0874202 ],\n",
            "       [ 0.6747905 , -0.99307865],\n",
            "       [ 1.7595496 , -2.1235452 ],\n",
            "       [ 1.6997639 , -2.062093  ],\n",
            "       [ 0.23017432, -0.51352763],\n",
            "       [ 0.35387254, -0.62660253],\n",
            "       [ 2.521212  , -2.8948429 ]], dtype=float32), array([[-0.5452232 ,  0.3070501 ],\n",
            "       [ 0.9862891 , -1.3085405 ],\n",
            "       [ 2.5458715 , -2.9178033 ],\n",
            "       [ 2.6883574 , -3.0422552 ],\n",
            "       [ 2.2553942 , -2.6345367 ],\n",
            "       [ 2.4920957 , -2.8576155 ],\n",
            "       [ 2.0052376 , -2.3655381 ],\n",
            "       [ 2.0056942 , -2.3683426 ],\n",
            "       [-0.9027081 ,  0.6690015 ],\n",
            "       [ 2.2987392 , -2.6728878 ],\n",
            "       [ 1.255701  , -1.590046  ],\n",
            "       [ 1.7116483 , -2.0539916 ],\n",
            "       [ 1.1206566 , -1.4668486 ],\n",
            "       [ 2.6381648 , -2.9877274 ],\n",
            "       [ 0.50607115, -0.79470897],\n",
            "       [ 1.9325569 , -2.2803948 ],\n",
            "       [-2.0810966 ,  2.0127976 ],\n",
            "       [ 2.0274928 , -2.3925545 ],\n",
            "       [ 1.8945624 , -2.24493   ],\n",
            "       [ 0.02954443, -0.33101007],\n",
            "       [ 2.5418384 , -2.8882673 ],\n",
            "       [-0.9839301 ,  0.81348395],\n",
            "       [ 0.68953294, -1.0279979 ],\n",
            "       [ 0.39887023, -0.6853553 ],\n",
            "       [ 2.9791925 , -3.2569864 ],\n",
            "       [ 1.9310728 , -2.2791698 ],\n",
            "       [ 2.5663178 , -2.9222229 ],\n",
            "       [ 1.8439102 , -2.1721952 ],\n",
            "       [ 1.8326986 , -2.2006056 ],\n",
            "       [ 1.6944131 , -2.0412009 ],\n",
            "       [ 2.4236698 , -2.780835  ],\n",
            "       [-0.18991758, -0.06775238]], dtype=float32), array([[ 2.1778548 , -2.5561635 ],\n",
            "       [ 2.2045252 , -2.563737  ],\n",
            "       [ 0.35470203, -0.6312053 ],\n",
            "       [ 0.6713407 , -1.0074586 ],\n",
            "       [-1.1262087 ,  0.9660985 ],\n",
            "       [ 1.2580931 , -1.6045392 ],\n",
            "       [ 0.1881253 , -0.46238092],\n",
            "       [ 0.62974817, -0.9549868 ],\n",
            "       [ 1.7792517 , -2.1428297 ],\n",
            "       [ 1.7130926 , -2.0542784 ],\n",
            "       [ 2.6819127 , -3.035116  ],\n",
            "       [ 2.8077214 , -3.1439636 ],\n",
            "       [ 0.20582153, -0.4782476 ],\n",
            "       [-1.4642771 ,  1.3708625 ],\n",
            "       [ 0.5518272 , -0.8665534 ],\n",
            "       [ 1.2920115 , -1.6228787 ],\n",
            "       [ 1.2220631 , -1.5619143 ],\n",
            "       [ 1.7924072 , -2.1558077 ],\n",
            "       [-0.32046524,  0.04095035],\n",
            "       [ 2.37354   , -2.7474034 ],\n",
            "       [ 2.177107  , -2.5604126 ],\n",
            "       [ 2.9102256 , -3.21372   ],\n",
            "       [ 1.0674324 , -1.3960321 ],\n",
            "       [ 0.62929624, -0.93555623],\n",
            "       [ 0.9690799 , -1.3180596 ],\n",
            "       [ 1.4175206 , -1.7312645 ],\n",
            "       [ 2.2577775 , -2.6313376 ],\n",
            "       [ 0.26299357, -0.55386055],\n",
            "       [-1.2580706 ,  1.1203884 ],\n",
            "       [ 2.641296  , -3.007408  ],\n",
            "       [-1.9102772 ,  1.9014705 ],\n",
            "       [ 2.5090156 , -2.8756049 ]], dtype=float32), array([[ 2.1221187 , -2.4829044 ],\n",
            "       [ 1.9536871 , -2.3522055 ],\n",
            "       [ 0.58874226, -0.9097301 ],\n",
            "       [ 1.3416743 , -1.665091  ],\n",
            "       [ 2.8384545 , -3.168751  ],\n",
            "       [ 2.0534282 , -2.4240139 ],\n",
            "       [ 2.011288  , -2.3578584 ],\n",
            "       [ 2.6879685 , -3.0373409 ],\n",
            "       [-2.5788782 ,  2.629635  ],\n",
            "       [-0.3955808 ,  0.17049827],\n",
            "       [ 2.8472884 , -3.1801682 ],\n",
            "       [ 1.7956818 , -2.1560483 ],\n",
            "       [ 2.5590246 , -2.8859916 ],\n",
            "       [-0.7381829 ,  0.5630589 ],\n",
            "       [ 1.7971398 , -2.1337585 ],\n",
            "       [ 2.7057302 , -3.0592034 ],\n",
            "       [ 2.4341042 , -2.8066552 ],\n",
            "       [ 2.16771   , -2.536072  ],\n",
            "       [ 2.3566697 , -2.7331743 ],\n",
            "       [ 2.5785596 , -2.936515  ],\n",
            "       [ 2.6244323 , -2.9816368 ],\n",
            "       [-0.26155835, -0.00888503],\n",
            "       [ 1.2566031 , -1.6074151 ],\n",
            "       [ 2.4786637 , -2.8463717 ],\n",
            "       [ 1.7331225 , -2.0672126 ],\n",
            "       [-0.555348  ,  0.349552  ],\n",
            "       [ 1.2041003 , -1.5415756 ],\n",
            "       [ 0.33358678, -0.6255455 ],\n",
            "       [ 2.502577  , -2.8723636 ],\n",
            "       [ 2.7016935 , -3.0638335 ],\n",
            "       [ 2.4606411 , -2.8283846 ],\n",
            "       [ 1.175152  , -1.525663  ]], dtype=float32), array([[ 1.3634688 , -1.6973866 ],\n",
            "       [ 2.8645148 , -3.1778803 ],\n",
            "       [ 1.8200692 , -2.1769323 ],\n",
            "       [ 1.8762568 , -2.2527115 ],\n",
            "       [ 2.3191884 , -2.7093654 ],\n",
            "       [ 0.13348065, -0.42473516],\n",
            "       [ 0.36498496, -0.66934234],\n",
            "       [ 0.76269615, -1.0577726 ],\n",
            "       [ 0.8820543 , -1.1953369 ],\n",
            "       [ 2.7494597 , -3.063504  ],\n",
            "       [ 2.0528421 , -2.4250515 ],\n",
            "       [ 0.8622232 , -1.1948831 ],\n",
            "       [ 1.7248408 , -2.0741012 ],\n",
            "       [-0.40660766,  0.1577199 ],\n",
            "       [ 1.7540435 , -2.100724  ],\n",
            "       [ 0.8153717 , -1.1564643 ],\n",
            "       [ 2.5615618 , -2.9187717 ],\n",
            "       [ 0.09997877, -0.33680746],\n",
            "       [ 0.84086096, -1.1633407 ],\n",
            "       [ 2.1217043 , -2.5071535 ],\n",
            "       [ 1.5884837 , -1.9503281 ],\n",
            "       [ 0.66239065, -0.96773815],\n",
            "       [ 2.243248  , -2.6012409 ],\n",
            "       [ 1.617798  , -1.9852237 ],\n",
            "       [ 1.9496006 , -2.320123  ],\n",
            "       [ 0.33086208, -0.6517967 ],\n",
            "       [ 2.299884  , -2.6837518 ],\n",
            "       [ 2.795825  , -3.1490748 ],\n",
            "       [ 1.656998  , -1.9916303 ],\n",
            "       [ 1.4723927 , -1.8003823 ],\n",
            "       [ 3.0132973 , -3.2913404 ],\n",
            "       [ 2.4838557 , -2.8604593 ]], dtype=float32), array([[ 2.9842792 , -3.2768652 ],\n",
            "       [ 1.6908958 , -2.0407083 ],\n",
            "       [-1.1786455 ,  1.0318588 ],\n",
            "       [-0.50666857,  0.27245528],\n",
            "       [ 1.0080987 , -1.3478988 ],\n",
            "       [ 1.70544   , -2.0189614 ],\n",
            "       [ 1.6425471 , -1.982956  ],\n",
            "       [ 1.7552502 , -2.1177433 ],\n",
            "       [ 3.1197042 , -3.3854585 ],\n",
            "       [ 2.2159412 , -2.5913608 ],\n",
            "       [ 2.5372794 , -2.895103  ],\n",
            "       [ 0.64217836, -0.9693612 ],\n",
            "       [ 1.795905  , -2.1658819 ],\n",
            "       [-0.17552699, -0.08218747],\n",
            "       [ 2.1451066 , -2.5000746 ],\n",
            "       [ 2.1683347 , -2.5172465 ],\n",
            "       [ 1.0754881 , -1.4078441 ],\n",
            "       [ 1.7067822 , -2.0611746 ],\n",
            "       [ 2.4539883 , -2.7746952 ],\n",
            "       [ 1.1161458 , -1.4447409 ],\n",
            "       [-0.0202663 , -0.23741026],\n",
            "       [-0.3999871 ,  0.14451508],\n",
            "       [ 1.9100841 , -2.2495382 ],\n",
            "       [ 2.724269  , -3.0551527 ],\n",
            "       [-0.8241615 ,  0.62638164],\n",
            "       [ 1.74461   , -2.104502  ],\n",
            "       [ 1.9747537 , -2.3485222 ],\n",
            "       [ 1.2276529 , -1.553675  ],\n",
            "       [ 1.6723353 , -2.03771   ],\n",
            "       [ 2.4941556 , -2.8778877 ],\n",
            "       [ 2.177736  , -2.5537941 ],\n",
            "       [ 2.9195788 , -3.2111168 ]], dtype=float32), array([[ 1.9144874 , -2.2640269 ],\n",
            "       [-0.23129179, -0.04253848],\n",
            "       [ 1.6036066 , -1.948794  ],\n",
            "       [ 1.6672848 , -2.0168767 ],\n",
            "       [ 2.0065513 , -2.380892  ],\n",
            "       [-1.9108065 ,  1.8717734 ],\n",
            "       [ 1.4596578 , -1.8133036 ],\n",
            "       [ 2.265735  , -2.6155813 ],\n",
            "       [ 1.1031079 , -1.4244727 ],\n",
            "       [ 1.7564154 , -2.106792  ],\n",
            "       [ 1.6357033 , -2.0094912 ],\n",
            "       [ 1.8978443 , -2.2781296 ],\n",
            "       [ 0.6537682 , -0.97833145],\n",
            "       [ 0.36651987, -0.6439475 ],\n",
            "       [ 2.7703326 , -3.1036804 ],\n",
            "       [ 1.012     , -1.3237395 ],\n",
            "       [ 2.039828  , -2.3965862 ],\n",
            "       [ 2.3572009 , -2.7315118 ],\n",
            "       [ 2.5038598 , -2.8782456 ],\n",
            "       [ 2.4578576 , -2.8358555 ],\n",
            "       [ 2.3192506 , -2.6752126 ],\n",
            "       [ 1.810681  , -2.1659408 ],\n",
            "       [ 2.1853297 , -2.5561135 ],\n",
            "       [ 2.4143069 , -2.7848375 ],\n",
            "       [ 1.7716118 , -2.1439288 ],\n",
            "       [ 0.8265589 , -1.1245672 ],\n",
            "       [ 2.0384846 , -2.4139555 ],\n",
            "       [ 2.059454  , -2.4093711 ],\n",
            "       [ 1.9959619 , -2.3484368 ],\n",
            "       [ 2.7735593 , -3.117633  ],\n",
            "       [ 2.2973485 , -2.6750023 ],\n",
            "       [ 1.0212611 , -1.3408514 ]], dtype=float32), array([[ 1.1360557 , -1.4954098 ],\n",
            "       [ 0.5355321 , -0.83647096],\n",
            "       [ 1.7361134 , -2.0859075 ],\n",
            "       [ 2.224892  , -2.5890117 ],\n",
            "       [-1.771109  ,  1.7050518 ],\n",
            "       [ 2.2361887 , -2.6018991 ],\n",
            "       [ 0.49190387, -0.7977218 ],\n",
            "       [ 2.0627322 , -2.4364352 ],\n",
            "       [ 1.8043973 , -2.1545424 ],\n",
            "       [ 1.5673113 , -1.8984824 ],\n",
            "       [ 2.4891505 , -2.8512294 ],\n",
            "       [ 2.6212828 , -2.9515378 ],\n",
            "       [ 0.32381245, -0.62374336],\n",
            "       [ 1.6512097 , -1.9856759 ],\n",
            "       [ 0.90609485, -1.217452  ],\n",
            "       [ 0.9866019 , -1.3104534 ],\n",
            "       [ 2.6498506 , -3.006834  ],\n",
            "       [ 1.0465903 , -1.390123  ],\n",
            "       [-0.760593  ,  0.56895757],\n",
            "       [ 1.7150503 , -2.0579076 ],\n",
            "       [ 2.3070626 , -2.6794283 ],\n",
            "       [ 2.1111486 , -2.4779623 ],\n",
            "       [ 2.487495  , -2.8490343 ],\n",
            "       [-0.14420788, -0.07808863],\n",
            "       [ 1.951126  , -2.3181078 ],\n",
            "       [ 0.30029008, -0.5997642 ],\n",
            "       [ 1.3046219 , -1.6414124 ],\n",
            "       [-0.18707417, -0.08147176],\n",
            "       [ 1.1923578 , -1.5497054 ],\n",
            "       [ 2.5684693 , -2.9222438 ],\n",
            "       [-2.6702526 ,  2.7388942 ],\n",
            "       [ 1.4578427 , -1.790368  ]], dtype=float32), array([[ 1.2572612 , -1.5896456 ],\n",
            "       [ 2.462471  , -2.8293228 ],\n",
            "       [ 2.441553  , -2.805259  ],\n",
            "       [ 1.2935019 , -1.6280391 ],\n",
            "       [ 1.213464  , -1.5332056 ],\n",
            "       [ 1.8879436 , -2.2345822 ],\n",
            "       [-1.1213852 ,  0.94702256],\n",
            "       [-1.525535  ,  1.444418  ],\n",
            "       [ 1.5083166 , -1.8358171 ],\n",
            "       [ 2.4000204 , -2.757034  ],\n",
            "       [ 1.0775462 , -1.4139102 ],\n",
            "       [-1.5282615 ,  1.4440674 ],\n",
            "       [ 1.5815872 , -1.9174863 ],\n",
            "       [ 1.2444319 , -1.5769542 ],\n",
            "       [ 0.7737877 , -1.0821363 ],\n",
            "       [ 1.5898143 , -1.9617053 ],\n",
            "       [-1.2913128 ,  1.1672021 ],\n",
            "       [ 1.2682794 , -1.6023809 ],\n",
            "       [-1.6510679 ,  1.537697  ],\n",
            "       [-0.66850173,  0.46514252],\n",
            "       [ 1.7370569 , -2.0889616 ],\n",
            "       [-2.2550447 ,  2.2712953 ],\n",
            "       [ 1.2648357 , -1.5815849 ],\n",
            "       [ 0.7155063 , -1.0341457 ],\n",
            "       [ 2.2725022 , -2.6498098 ],\n",
            "       [ 1.264371  , -1.6035166 ],\n",
            "       [ 2.214156  , -2.591788  ],\n",
            "       [ 1.5823673 , -1.9200798 ],\n",
            "       [-1.2906541 ,  1.1927737 ],\n",
            "       [ 1.4755708 , -1.8413173 ],\n",
            "       [ 0.4273629 , -0.7559398 ],\n",
            "       [ 2.1867921 , -2.5494542 ]], dtype=float32), array([[ 1.1853322 , -1.5028437 ],\n",
            "       [ 0.55383   , -0.85051847],\n",
            "       [ 1.4706175 , -1.8508054 ],\n",
            "       [ 1.2816728 , -1.6078638 ],\n",
            "       [ 0.6600795 , -0.9810064 ],\n",
            "       [ 2.3411815 , -2.6814206 ],\n",
            "       [-2.1482952 ,  2.1564426 ],\n",
            "       [-1.1518427 ,  1.0062091 ],\n",
            "       [-1.707501  ,  1.6406063 ],\n",
            "       [ 2.6377895 , -2.9996994 ],\n",
            "       [ 1.6236959 , -1.975645  ],\n",
            "       [ 2.2227051 , -2.611379  ],\n",
            "       [ 1.7320162 , -2.1134121 ],\n",
            "       [ 2.153548  , -2.5060713 ],\n",
            "       [ 2.3502238 , -2.6739097 ],\n",
            "       [ 1.1082188 , -1.44596   ],\n",
            "       [ 1.4736135 , -1.8384964 ],\n",
            "       [ 3.2472293 , -3.4469106 ],\n",
            "       [-1.647958  ,  1.5392925 ],\n",
            "       [ 1.9705158 , -2.331597  ],\n",
            "       [ 1.335854  , -1.6524025 ],\n",
            "       [ 2.513885  , -2.880109  ],\n",
            "       [ 2.6233122 , -2.9649825 ],\n",
            "       [ 1.3299247 , -1.6798025 ],\n",
            "       [ 1.1831683 , -1.5272542 ],\n",
            "       [ 1.8108398 , -2.1564486 ],\n",
            "       [ 0.9811572 , -1.3184234 ],\n",
            "       [-1.6491371 ,  1.5551966 ],\n",
            "       [ 2.482565  , -2.8517258 ],\n",
            "       [ 2.8496487 , -3.1530223 ],\n",
            "       [ 1.4247688 , -1.7624815 ],\n",
            "       [ 2.1013343 , -2.4696817 ]], dtype=float32), array([[ 1.0789912 , -1.4100052 ],\n",
            "       [-0.06762675, -0.19362845],\n",
            "       [-1.1612544 ,  0.963855  ],\n",
            "       [ 1.6852123 , -2.0393643 ],\n",
            "       [ 1.238898  , -1.5824462 ],\n",
            "       [ 0.7342487 , -1.0461782 ],\n",
            "       [ 1.8363835 , -2.2052202 ],\n",
            "       [-0.80905765,  0.625726  ],\n",
            "       [ 1.1837337 , -1.5270455 ],\n",
            "       [-0.4350187 ,  0.21565013],\n",
            "       [ 0.8913812 , -1.2148256 ],\n",
            "       [ 0.73064554, -1.0619901 ],\n",
            "       [ 2.7576544 , -3.101236  ],\n",
            "       [ 0.8686081 , -1.1689011 ],\n",
            "       [ 2.4998834 , -2.8797264 ],\n",
            "       [ 1.5156814 , -1.8835679 ],\n",
            "       [-0.6441376 ,  0.41145703],\n",
            "       [ 0.06332498, -0.3314014 ],\n",
            "       [ 0.99728584, -1.3181522 ],\n",
            "       [ 1.8114415 , -2.1835194 ],\n",
            "       [ 2.4807482 , -2.848954  ],\n",
            "       [ 2.6078095 , -2.9660494 ],\n",
            "       [ 2.3519275 , -2.738235  ],\n",
            "       [ 2.408004  , -2.7610612 ],\n",
            "       [ 2.1798604 , -2.541592  ],\n",
            "       [-0.59798646,  0.3818337 ],\n",
            "       [-0.09982467, -0.18469493],\n",
            "       [ 0.98670906, -1.2920796 ],\n",
            "       [ 2.4257472 , -2.7807481 ],\n",
            "       [ 0.05383243, -0.34843633],\n",
            "       [-0.16639043, -0.10804308],\n",
            "       [ 2.0497158 , -2.4234974 ]], dtype=float32), array([[-1.5293922 ,  1.4577895 ],\n",
            "       [ 1.4940313 , -1.8400186 ],\n",
            "       [ 1.970086  , -2.339491  ],\n",
            "       [ 1.052537  , -1.3821436 ],\n",
            "       [ 2.260065  , -2.6172376 ],\n",
            "       [ 1.0269674 , -1.3633101 ],\n",
            "       [ 0.01859727, -0.26452413],\n",
            "       [ 2.3297381 , -2.6873434 ],\n",
            "       [ 3.1241271 , -3.3856816 ],\n",
            "       [ 2.908923  , -3.2528563 ],\n",
            "       [ 2.1851156 , -2.541599  ],\n",
            "       [ 2.5642745 , -2.9239352 ],\n",
            "       [ 1.7019081 , -2.0354915 ],\n",
            "       [ 2.6379883 , -2.983844  ],\n",
            "       [ 2.2124174 , -2.5936801 ],\n",
            "       [ 2.3731053 , -2.7363117 ],\n",
            "       [ 1.9170862 , -2.2723315 ],\n",
            "       [ 1.2400907 , -1.5940658 ],\n",
            "       [-0.7601983 ,  0.5557246 ],\n",
            "       [ 0.44949633, -0.7703355 ],\n",
            "       [ 1.947605  , -2.3041387 ],\n",
            "       [ 0.8207383 , -1.1298949 ],\n",
            "       [ 0.6868566 , -1.014702  ],\n",
            "       [ 1.907328  , -2.25422   ],\n",
            "       [ 2.1645205 , -2.5347297 ],\n",
            "       [ 0.30062285, -0.65491986],\n",
            "       [ 1.6765994 , -1.9956082 ],\n",
            "       [ 1.4418465 , -1.7650928 ],\n",
            "       [ 2.0276754 , -2.388245  ],\n",
            "       [ 2.505019  , -2.882777  ],\n",
            "       [ 1.9418521 , -2.3119075 ],\n",
            "       [ 2.1907842 , -2.5469372 ]], dtype=float32), array([[ 2.6995277 , -3.0600545 ],\n",
            "       [-0.11416496, -0.12771492],\n",
            "       [ 1.7490066 , -2.1032887 ],\n",
            "       [ 1.6692482 , -2.0115345 ],\n",
            "       [ 1.6120158 , -1.9917156 ],\n",
            "       [ 0.07989942, -0.29259756],\n",
            "       [ 0.58858824, -0.89991015],\n",
            "       [ 0.9221418 , -1.2373167 ],\n",
            "       [ 2.4966033 , -2.887665  ],\n",
            "       [ 2.0777898 , -2.4428031 ],\n",
            "       [ 1.9285288 , -2.2909    ],\n",
            "       [-1.688491  ,  1.5612179 ],\n",
            "       [-0.37432742,  0.14243256],\n",
            "       [ 2.0694525 , -2.4455004 ],\n",
            "       [ 2.2925992 , -2.6841567 ],\n",
            "       [ 1.3731074 , -1.6917225 ],\n",
            "       [ 2.1298573 , -2.5161629 ],\n",
            "       [ 0.28228185, -0.6094853 ],\n",
            "       [ 2.4046063 , -2.7871907 ],\n",
            "       [ 2.1964257 , -2.5882409 ],\n",
            "       [ 1.3748497 , -1.7497891 ],\n",
            "       [ 2.1308002 , -2.4959953 ],\n",
            "       [ 1.6396472 , -1.9945866 ],\n",
            "       [ 0.06623574, -0.36366448],\n",
            "       [ 1.9966099 , -2.355837  ],\n",
            "       [ 2.1269548 , -2.4952679 ],\n",
            "       [ 0.18596612, -0.458631  ],\n",
            "       [ 1.3817638 , -1.7239348 ],\n",
            "       [ 1.3552808 , -1.6827508 ],\n",
            "       [-0.49916646,  0.26602736],\n",
            "       [ 2.4637325 , -2.841223  ],\n",
            "       [ 1.4489881 , -1.8272004 ]], dtype=float32), array([[ 0.75497645, -1.0912867 ],\n",
            "       [ 1.021465  , -1.3560447 ],\n",
            "       [ 1.2920494 , -1.6295936 ],\n",
            "       [ 0.94893056, -1.2680147 ],\n",
            "       [ 2.855277  , -3.184112  ],\n",
            "       [ 2.0878508 , -2.4651697 ],\n",
            "       [ 2.4129093 , -2.7654736 ],\n",
            "       [-0.03955088, -0.23807995],\n",
            "       [ 1.2781409 , -1.5868845 ],\n",
            "       [ 0.38795516, -0.67639667],\n",
            "       [-2.0226836 ,  2.0034666 ],\n",
            "       [ 1.9976169 , -2.3658803 ],\n",
            "       [ 2.3668272 , -2.718671  ],\n",
            "       [ 2.5960648 , -2.9385695 ],\n",
            "       [ 2.2366061 , -2.6013358 ],\n",
            "       [ 1.8713589 , -2.2303998 ],\n",
            "       [-1.0757189 ,  0.9118952 ],\n",
            "       [ 2.2253397 , -2.6113617 ],\n",
            "       [ 0.9424155 , -1.2615544 ],\n",
            "       [ 1.7620356 , -2.101262  ],\n",
            "       [ 1.3073355 , -1.6944903 ],\n",
            "       [ 2.3287647 , -2.7038667 ],\n",
            "       [ 2.0866811 , -2.445107  ],\n",
            "       [ 2.619073  , -2.9740589 ],\n",
            "       [ 1.0772815 , -1.4321967 ],\n",
            "       [-0.6400274 ,  0.41795954],\n",
            "       [ 1.3511952 , -1.7062933 ],\n",
            "       [ 2.5639684 , -2.9254954 ],\n",
            "       [ 2.4089572 , -2.7710516 ],\n",
            "       [ 1.7395214 , -2.1003582 ],\n",
            "       [ 2.7093222 , -3.0388339 ],\n",
            "       [ 3.2312045 , -3.4440792 ]], dtype=float32), array([[ 1.6293217 , -1.9808208 ],\n",
            "       [ 1.2676598 , -1.6047984 ],\n",
            "       [ 2.1248658 , -2.475738  ],\n",
            "       [ 1.6847216 , -2.0511239 ],\n",
            "       [ 0.46027282, -0.79317737],\n",
            "       [ 2.164286  , -2.544837  ],\n",
            "       [ 1.6744745 , -2.0261276 ],\n",
            "       [ 1.8200524 , -2.1606247 ],\n",
            "       [ 2.3803031 , -2.7530694 ],\n",
            "       [ 1.8962055 , -2.265397  ],\n",
            "       [ 1.8727617 , -2.2399197 ],\n",
            "       [ 2.9210627 , -3.2434614 ],\n",
            "       [ 2.303972  , -2.6809492 ],\n",
            "       [ 2.7821844 , -3.1303108 ],\n",
            "       [ 1.3341405 , -1.6862084 ],\n",
            "       [ 1.319899  , -1.6961294 ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 2.3362362 , -2.717642  ],\n",
            "       [ 2.440995  , -2.8151622 ],\n",
            "       [ 2.070874  , -2.4358552 ],\n",
            "       [ 2.266448  , -2.6343095 ],\n",
            "       [-0.88065493,  0.68222654],\n",
            "       [ 2.9102573 , -3.230318  ],\n",
            "       [ 0.0948384 , -0.38149622],\n",
            "       [ 2.0529637 , -2.4262216 ],\n",
            "       [-0.8803736 ,  0.6685131 ],\n",
            "       [ 3.1439824 , -3.39482   ],\n",
            "       [-0.52126336,  0.2862973 ],\n",
            "       [ 1.0889047 , -1.4076914 ],\n",
            "       [ 2.0645525 , -2.4062245 ],\n",
            "       [ 2.0110142 , -2.3526409 ],\n",
            "       [ 1.4980482 , -1.8633012 ]], dtype=float32), array([[ 1.8438346 , -2.2111723 ],\n",
            "       [ 1.5981206 , -1.9432731 ],\n",
            "       [ 0.50422347, -0.8277334 ],\n",
            "       [ 2.0889416 , -2.4344282 ],\n",
            "       [ 1.0466195 , -1.3938369 ],\n",
            "       [-1.3113093 ,  1.153699  ],\n",
            "       [ 1.8694066 , -2.2156978 ],\n",
            "       [ 2.0623496 , -2.4124696 ],\n",
            "       [-0.60860145,  0.37370303],\n",
            "       [ 0.10185423, -0.39484033],\n",
            "       [ 1.9099317 , -2.278502  ],\n",
            "       [ 2.0945191 , -2.4349935 ],\n",
            "       [-1.9525825 ,  1.8878057 ],\n",
            "       [-1.8793416 ,  1.7827266 ],\n",
            "       [ 0.7826732 , -1.113053  ],\n",
            "       [-0.09865356, -0.20549841],\n",
            "       [ 2.5290866 , -2.8804336 ],\n",
            "       [ 1.9781605 , -2.34106   ],\n",
            "       [ 0.06024965, -0.35493034],\n",
            "       [ 2.874933  , -3.254781  ],\n",
            "       [ 2.2566419 , -2.6201804 ],\n",
            "       [-1.0633749 ,  0.90379864],\n",
            "       [ 2.0484319 , -2.4091725 ],\n",
            "       [-0.01970301, -0.23801343],\n",
            "       [ 0.8391818 , -1.1373346 ],\n",
            "       [ 1.5979518 , -1.9550569 ],\n",
            "       [ 2.538353  , -2.9007142 ],\n",
            "       [ 2.1167986 , -2.478625  ],\n",
            "       [ 2.6976016 , -3.0490296 ],\n",
            "       [ 2.1025193 , -2.4741127 ],\n",
            "       [ 2.0664964 , -2.4063056 ],\n",
            "       [ 2.4975376 , -2.8597114 ]], dtype=float32), array([[ 2.6152585 , -2.9778664 ],\n",
            "       [ 1.4610249 , -1.814263  ],\n",
            "       [ 1.4602586 , -1.7971301 ],\n",
            "       [ 2.017777  , -2.3988864 ],\n",
            "       [ 1.3589872 , -1.6897916 ],\n",
            "       [ 2.5012214 , -2.8577855 ],\n",
            "       [-0.06593243, -0.22133808],\n",
            "       [ 3.1656454 , -3.423391  ],\n",
            "       [ 1.9307237 , -2.3010302 ],\n",
            "       [ 0.9704802 , -1.2700673 ],\n",
            "       [ 0.53900373, -0.85233945],\n",
            "       [-1.1872431 ,  1.0279984 ],\n",
            "       [-1.2049165 ,  1.0506288 ],\n",
            "       [ 2.8757021 , -3.2016118 ],\n",
            "       [ 2.382367  , -2.726283  ],\n",
            "       [ 1.7113997 , -2.0768812 ],\n",
            "       [ 1.0026858 , -1.346862  ],\n",
            "       [ 1.6402502 , -1.9931985 ],\n",
            "       [ 2.8063383 , -3.1506386 ],\n",
            "       [ 1.6727413 , -2.0479863 ],\n",
            "       [ 2.0900815 , -2.4565983 ],\n",
            "       [-0.05593507, -0.24029556],\n",
            "       [ 2.9233549 , -3.210489  ],\n",
            "       [ 1.1976329 , -1.5427703 ],\n",
            "       [ 2.7739685 , -3.1220012 ],\n",
            "       [ 2.922994  , -3.235599  ],\n",
            "       [ 2.4962482 , -2.8431518 ],\n",
            "       [ 2.5428636 , -2.9094949 ],\n",
            "       [ 0.94243646, -1.2587832 ],\n",
            "       [ 1.2921716 , -1.6467162 ],\n",
            "       [ 1.6690931 , -2.023683  ],\n",
            "       [ 1.7566104 , -2.105314  ]], dtype=float32), array([[-1.3946868 ,  1.2386354 ],\n",
            "       [ 2.4102085 , -2.7762341 ],\n",
            "       [ 1.425239  , -1.7600602 ],\n",
            "       [ 0.20305769, -0.5136504 ],\n",
            "       [ 2.7312796 , -3.0786216 ],\n",
            "       [ 2.0583475 , -2.4496894 ],\n",
            "       [ 2.4980738 , -2.8621714 ],\n",
            "       [ 2.2706914 , -2.6463833 ],\n",
            "       [-1.3911036 ,  1.2805496 ],\n",
            "       [-3.0494778 ,  3.242132  ],\n",
            "       [ 0.83693165, -1.1564623 ],\n",
            "       [-2.8037555 ,  2.8729296 ],\n",
            "       [ 2.8786013 , -3.1964962 ],\n",
            "       [ 2.2558966 , -2.623719  ],\n",
            "       [ 0.29692897, -0.6001723 ],\n",
            "       [ 1.439871  , -1.7970761 ],\n",
            "       [ 1.9539181 , -2.3343189 ],\n",
            "       [ 0.8081756 , -1.1118504 ],\n",
            "       [-0.01449035, -0.31807014],\n",
            "       [ 0.1545179 , -0.41267362],\n",
            "       [ 1.6176771 , -1.9675478 ],\n",
            "       [ 0.7514313 , -1.0866824 ],\n",
            "       [ 1.201487  , -1.5691131 ],\n",
            "       [ 2.5328145 , -2.893376  ],\n",
            "       [ 2.139793  , -2.506952  ],\n",
            "       [ 1.5333976 , -1.8885978 ],\n",
            "       [ 2.2901342 , -2.6368394 ],\n",
            "       [-0.04746873, -0.26164433],\n",
            "       [ 1.2926117 , -1.6264673 ],\n",
            "       [ 1.3999144 , -1.753152  ],\n",
            "       [ 2.7620156 , -3.1058247 ],\n",
            "       [ 2.059766  , -2.433181  ]], dtype=float32), array([[ 1.4338439 , -1.7372317 ],\n",
            "       [ 2.216872  , -2.5784676 ],\n",
            "       [ 2.790689  , -3.12864   ],\n",
            "       [ 2.3189108 , -2.6732395 ],\n",
            "       [-0.8721925 ,  0.6965667 ],\n",
            "       [ 0.9146396 , -1.2291468 ],\n",
            "       [ 1.8382252 , -2.1876218 ],\n",
            "       [ 1.8354683 , -2.1696148 ],\n",
            "       [ 2.0215557 , -2.3841407 ],\n",
            "       [ 2.1944828 , -2.56999   ],\n",
            "       [ 2.5697458 , -2.931564  ],\n",
            "       [ 1.823567  , -2.194464  ],\n",
            "       [ 2.3297553 , -2.6766806 ],\n",
            "       [-0.77834475,  0.5659889 ],\n",
            "       [-0.50388825,  0.27985314],\n",
            "       [-1.469312  ,  1.3450161 ],\n",
            "       [ 1.4878758 , -1.8429159 ],\n",
            "       [-0.3742718 ,  0.14292276],\n",
            "       [ 2.5788205 , -2.9312527 ],\n",
            "       [ 2.1533134 , -2.5314682 ],\n",
            "       [ 1.2713343 , -1.6001085 ],\n",
            "       [ 1.7122945 , -2.0615284 ],\n",
            "       [-0.03635142, -0.23688494],\n",
            "       [ 2.1612842 , -2.5453303 ],\n",
            "       [ 1.3319368 , -1.6693227 ],\n",
            "       [-0.01716174, -0.27021974],\n",
            "       [ 1.3442017 , -1.674949  ],\n",
            "       [ 1.5844792 , -1.9013892 ],\n",
            "       [-0.33870983,  0.07821073],\n",
            "       [ 2.9341528 , -3.2318227 ],\n",
            "       [ 2.962959  , -3.2644913 ],\n",
            "       [ 1.6636523 , -2.0032187 ]], dtype=float32), array([[ 2.786382  , -3.142357  ],\n",
            "       [-1.0764241 ,  0.9182888 ],\n",
            "       [ 2.7050073 , -3.05702   ],\n",
            "       [ 2.5691566 , -2.8945596 ],\n",
            "       [ 2.5869567 , -2.9573858 ],\n",
            "       [ 1.4384716 , -1.7945457 ],\n",
            "       [ 1.1878713 , -1.5618657 ],\n",
            "       [ 1.8623452 , -2.2143195 ],\n",
            "       [-1.4966316 ,  1.3691095 ],\n",
            "       [ 2.0528264 , -2.4162977 ],\n",
            "       [ 0.92919654, -1.2521663 ],\n",
            "       [ 0.520827  , -0.83652675],\n",
            "       [ 0.02407121, -0.35403416],\n",
            "       [-1.8624859 ,  1.785908  ],\n",
            "       [-2.142595  ,  2.1546192 ],\n",
            "       [-0.5212264 ,  0.25487527],\n",
            "       [ 2.7601821 , -3.1098726 ],\n",
            "       [ 2.1688154 , -2.519563  ],\n",
            "       [ 0.00812366, -0.3044519 ],\n",
            "       [ 1.6893607 , -2.0422523 ],\n",
            "       [ 0.54563403, -0.8505744 ],\n",
            "       [ 0.74802995, -1.0795399 ],\n",
            "       [-1.9647378 ,  1.9170008 ],\n",
            "       [ 1.4282889 , -1.7645456 ],\n",
            "       [ 1.8834702 , -2.239823  ],\n",
            "       [ 2.1553557 , -2.5140336 ],\n",
            "       [ 1.6657498 , -2.0128233 ],\n",
            "       [ 2.188879  , -2.55875   ],\n",
            "       [ 1.3481102 , -1.7122643 ],\n",
            "       [ 2.5802238 , -2.9227612 ],\n",
            "       [ 1.1768793 , -1.519509  ],\n",
            "       [ 0.48258144, -0.8148043 ]], dtype=float32), array([[ 2.1935632 , -2.5737598 ],\n",
            "       [ 2.3361185 , -2.6869724 ],\n",
            "       [ 0.27091745, -0.5831907 ],\n",
            "       [ 2.2414877 , -2.609905  ],\n",
            "       [ 2.324409  , -2.6880229 ],\n",
            "       [ 2.7834494 , -3.1308491 ],\n",
            "       [ 2.4953241 , -2.8568542 ],\n",
            "       [ 2.4284053 , -2.7999318 ],\n",
            "       [ 2.1282995 , -2.505695  ],\n",
            "       [-0.19617005, -0.07787199],\n",
            "       [ 3.156449  , -3.4141662 ],\n",
            "       [ 1.739772  , -2.089053  ],\n",
            "       [ 1.6593226 , -2.0302749 ],\n",
            "       [ 1.4762548 , -1.8333724 ],\n",
            "       [ 2.514303  , -2.8802903 ],\n",
            "       [-1.0094635 ,  0.8192047 ],\n",
            "       [-0.10066558, -0.19322896],\n",
            "       [ 0.68195   , -0.9728998 ],\n",
            "       [ 2.1746814 , -2.5466058 ],\n",
            "       [ 1.5237432 , -1.867484  ],\n",
            "       [ 2.7791831 , -3.092328  ],\n",
            "       [ 2.1191046 , -2.502344  ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 0.35779306, -0.6802619 ],\n",
            "       [ 1.7269824 , -2.0990307 ],\n",
            "       [ 2.34399   , -2.691934  ],\n",
            "       [-1.6622386 ,  1.546647  ],\n",
            "       [ 1.5229468 , -1.883174  ],\n",
            "       [-0.4366366 ,  0.19455959],\n",
            "       [ 2.7270725 , -3.0819237 ],\n",
            "       [ 0.01577761, -0.29799095],\n",
            "       [-1.532071  ,  1.4384848 ]], dtype=float32), array([[ 2.2971892 , -2.6673067 ],\n",
            "       [-0.46382532,  0.22022505],\n",
            "       [ 1.8079159 , -2.1845083 ],\n",
            "       [ 1.6377047 , -1.9960428 ],\n",
            "       [ 0.01980855, -0.29726008],\n",
            "       [ 2.226938  , -2.5885437 ],\n",
            "       [-0.69284606,  0.49018958],\n",
            "       [-1.6997002 ,  1.6057069 ],\n",
            "       [ 1.7990686 , -2.1712525 ],\n",
            "       [ 1.9406573 , -2.3030047 ],\n",
            "       [-1.2393134 ,  1.0779068 ],\n",
            "       [ 1.9339385 , -2.28602   ],\n",
            "       [ 0.7000056 , -1.0288965 ],\n",
            "       [ 2.8682349 , -3.2028387 ],\n",
            "       [ 1.416689  , -1.7834896 ],\n",
            "       [ 0.9979885 , -1.3202664 ],\n",
            "       [ 1.4440013 , -1.7784349 ],\n",
            "       [ 1.9985168 , -2.3396666 ],\n",
            "       [-0.592134  ,  0.37590128],\n",
            "       [ 1.6230212 , -1.9681486 ],\n",
            "       [ 0.7798675 , -1.0895818 ],\n",
            "       [ 3.0032012 , -3.2881753 ],\n",
            "       [ 0.3439508 , -0.62441814],\n",
            "       [ 1.6556457 , -2.0064695 ],\n",
            "       [ 2.0153039 , -2.367928  ],\n",
            "       [ 0.83361256, -1.1746062 ],\n",
            "       [ 2.5586524 , -2.9253547 ],\n",
            "       [ 2.5723965 , -2.9284499 ],\n",
            "       [ 2.0905135 , -2.459747  ],\n",
            "       [ 2.4738073 , -2.847549  ],\n",
            "       [ 2.6223307 , -2.9896739 ],\n",
            "       [ 1.4752542 , -1.8422934 ]], dtype=float32), array([[ 0.5280948 , -0.83425426],\n",
            "       [ 0.83906204, -1.1909109 ],\n",
            "       [ 2.320956  , -2.6919744 ],\n",
            "       [ 2.7795413 , -3.119713  ],\n",
            "       [-0.41530386,  0.18770929],\n",
            "       [ 0.9664123 , -1.2746    ],\n",
            "       [ 2.3902614 , -2.7592654 ],\n",
            "       [ 0.433724  , -0.73397464],\n",
            "       [ 1.4593278 , -1.8231738 ],\n",
            "       [ 1.7705101 , -2.1377738 ],\n",
            "       [ 1.619107  , -1.9740005 ],\n",
            "       [ 2.370298  , -2.741745  ],\n",
            "       [ 0.3707567 , -0.6676426 ],\n",
            "       [-0.02681563, -0.2402559 ],\n",
            "       [-0.52697325,  0.27790675],\n",
            "       [ 1.5506905 , -1.9099829 ],\n",
            "       [ 1.8384682 , -2.208563  ],\n",
            "       [ 1.6919212 , -2.0238402 ],\n",
            "       [ 0.69205236, -1.0188143 ],\n",
            "       [ 0.8584344 , -1.1962367 ],\n",
            "       [ 2.1233938 , -2.5210173 ],\n",
            "       [ 1.1523569 , -1.4743099 ],\n",
            "       [ 0.63300985, -0.94450873],\n",
            "       [ 2.0246727 , -2.4178355 ],\n",
            "       [ 0.09436908, -0.38494202],\n",
            "       [ 0.4825806 , -0.792839  ],\n",
            "       [ 0.18009372, -0.4391428 ],\n",
            "       [ 1.3725113 , -1.7304199 ],\n",
            "       [ 1.99712   , -2.363795  ],\n",
            "       [ 1.6863977 , -2.0738864 ],\n",
            "       [ 1.6363891 , -2.003736  ],\n",
            "       [ 0.28389925, -0.5746705 ]], dtype=float32), array([[ 2.4089859 , -2.7526422 ],\n",
            "       [ 1.8155982 , -2.1519608 ],\n",
            "       [ 1.2511367 , -1.6150898 ],\n",
            "       [-0.2972524 ,  0.02773619],\n",
            "       [ 2.1915264 , -2.5667076 ],\n",
            "       [ 2.028539  , -2.3798325 ],\n",
            "       [ 1.1174222 , -1.4314302 ],\n",
            "       [-0.54455966,  0.32658324],\n",
            "       [ 2.144442  , -2.4950829 ],\n",
            "       [ 2.4199486 , -2.8031974 ],\n",
            "       [ 2.865417  , -3.2052493 ],\n",
            "       [ 2.5467794 , -2.890006  ],\n",
            "       [-1.687261  ,  1.6070323 ],\n",
            "       [ 0.61839134, -0.9036894 ],\n",
            "       [ 1.8103269 , -2.1835554 ],\n",
            "       [ 1.083835  , -1.4166213 ],\n",
            "       [ 1.9954551 , -2.3573291 ],\n",
            "       [ 2.5666049 , -2.9312823 ],\n",
            "       [ 2.3113952 , -2.663976  ],\n",
            "       [ 1.7030514 , -2.0624359 ],\n",
            "       [ 2.0139835 , -2.357078  ],\n",
            "       [ 2.142175  , -2.511038  ],\n",
            "       [ 0.57329583, -0.9002668 ],\n",
            "       [-0.6878593 ,  0.4912053 ],\n",
            "       [ 1.3606926 , -1.6973494 ],\n",
            "       [ 0.34049562, -0.6630854 ],\n",
            "       [ 1.3629429 , -1.6722211 ],\n",
            "       [-0.30320174,  0.1024283 ],\n",
            "       [ 1.9677688 , -2.3292253 ],\n",
            "       [ 1.2330165 , -1.5622226 ],\n",
            "       [-1.0350419 ,  0.8464836 ],\n",
            "       [ 1.9110314 , -2.2933753 ]], dtype=float32), array([[ 1.1127204 , -1.455816  ],\n",
            "       [-1.5545001 ,  1.4401952 ],\n",
            "       [ 1.7552502 , -2.1177433 ],\n",
            "       [ 2.6125526 , -2.9517148 ],\n",
            "       [ 1.2872012 , -1.6090205 ],\n",
            "       [ 1.038241  , -1.3580582 ],\n",
            "       [ 2.529102  , -2.9017117 ],\n",
            "       [ 2.180783  , -2.5592453 ],\n",
            "       [ 1.236512  , -1.5961102 ],\n",
            "       [ 0.2649847 , -0.5575884 ],\n",
            "       [ 2.9754856 , -3.277919  ],\n",
            "       [-1.4661745 ,  1.3792199 ],\n",
            "       [ 2.589336  , -2.951825  ],\n",
            "       [ 3.0182233 , -3.3153815 ],\n",
            "       [ 1.819939  , -2.1962345 ],\n",
            "       [-0.70287573,  0.46753082],\n",
            "       [ 1.108988  , -1.4467142 ],\n",
            "       [ 2.6040862 , -2.961798  ],\n",
            "       [ 0.21782847, -0.5295877 ],\n",
            "       [ 0.47642693, -0.7914125 ],\n",
            "       [ 1.7034672 , -2.0654051 ],\n",
            "       [-0.00378097, -0.26574796],\n",
            "       [ 2.1308002 , -2.4959953 ],\n",
            "       [ 1.4646198 , -1.8075114 ],\n",
            "       [ 1.6541427 , -2.005225  ],\n",
            "       [ 2.644111  , -3.008828  ],\n",
            "       [-0.33039373,  0.05812454],\n",
            "       [ 1.2479442 , -1.5781573 ],\n",
            "       [ 0.86580646, -1.1577696 ],\n",
            "       [ 1.9294071 , -2.2871125 ],\n",
            "       [ 2.2897701 , -2.6613166 ],\n",
            "       [ 1.1957439 , -1.5530137 ]], dtype=float32), array([[ 2.0908523 , -2.4638581 ],\n",
            "       [ 1.9675549 , -2.3202631 ],\n",
            "       [ 2.7854936 , -3.12474   ],\n",
            "       [-1.9633727 ,  1.9097041 ],\n",
            "       [ 2.5937274 , -2.9313014 ],\n",
            "       [ 2.3489888 , -2.702533  ],\n",
            "       [ 1.3973147 , -1.7296275 ],\n",
            "       [ 2.293378  , -2.6504004 ],\n",
            "       [-0.8516483 ,  0.6504465 ],\n",
            "       [ 2.0494285 , -2.4115822 ],\n",
            "       [ 0.5701276 , -0.86790884],\n",
            "       [ 0.53316355, -0.8345611 ],\n",
            "       [ 2.5232148 , -2.8883474 ],\n",
            "       [ 1.8919356 , -2.2506297 ],\n",
            "       [ 1.9165368 , -2.2992628 ],\n",
            "       [ 0.33677894, -0.62215817],\n",
            "       [ 0.94458604, -1.2955676 ],\n",
            "       [ 2.3673725 , -2.7350276 ],\n",
            "       [ 1.5278083 , -1.8857795 ],\n",
            "       [ 2.5614526 , -2.9283614 ],\n",
            "       [ 1.4829161 , -1.8355211 ],\n",
            "       [ 2.0889313 , -2.4449413 ],\n",
            "       [ 2.1721487 , -2.5203784 ],\n",
            "       [ 2.5608919 , -2.9183958 ],\n",
            "       [-1.6017574 ,  1.498599  ],\n",
            "       [ 0.145945  , -0.45337754],\n",
            "       [ 1.7674831 , -2.1322293 ],\n",
            "       [ 2.124708  , -2.4876251 ],\n",
            "       [ 1.5381571 , -1.8520863 ],\n",
            "       [ 2.280724  , -2.6654556 ],\n",
            "       [ 0.87317604, -1.209114  ],\n",
            "       [-0.6768802 ,  0.44434258]], dtype=float32), array([[-0.6057783 ,  0.37777683],\n",
            "       [-2.3062224 ,  2.3428166 ],\n",
            "       [-0.89192665,  0.68963504],\n",
            "       [-1.1341157 ,  0.95356095],\n",
            "       [ 1.6096774 , -1.9641477 ],\n",
            "       [ 0.40699908, -0.73720825],\n",
            "       [ 1.1710169 , -1.5197716 ],\n",
            "       [ 1.0601603 , -1.4051307 ],\n",
            "       [ 2.2884233 , -2.622074  ],\n",
            "       [ 2.416271  , -2.760351  ],\n",
            "       [ 2.19185   , -2.5765042 ],\n",
            "       [ 1.0859029 , -1.4331154 ],\n",
            "       [ 2.114444  , -2.4849863 ],\n",
            "       [ 1.6747967 , -2.0515358 ],\n",
            "       [ 2.1148512 , -2.4872782 ],\n",
            "       [ 2.0608375 , -2.42816   ],\n",
            "       [ 1.4729081 , -1.8158602 ],\n",
            "       [-0.68499506,  0.44931674],\n",
            "       [ 2.906256  , -3.2152822 ],\n",
            "       [ 1.7167602 , -2.0599303 ],\n",
            "       [ 2.5814197 , -2.9447565 ],\n",
            "       [ 2.033181  , -2.4127767 ],\n",
            "       [ 1.5401256 , -1.8947674 ],\n",
            "       [ 1.8991715 , -2.2731698 ],\n",
            "       [ 1.8043011 , -2.1842449 ],\n",
            "       [ 0.9875657 , -1.3306211 ],\n",
            "       [ 1.8158827 , -2.1793597 ],\n",
            "       [ 2.178264  , -2.5550542 ],\n",
            "       [ 2.4129224 , -2.743835  ],\n",
            "       [ 1.4265654 , -1.7862144 ],\n",
            "       [ 2.6243744 , -2.9902236 ],\n",
            "       [-1.3706576 ,  1.2339187 ]], dtype=float32), array([[ 1.9667014 , -2.3466198 ],\n",
            "       [ 2.2867272 , -2.6637557 ],\n",
            "       [ 0.5827695 , -0.9148803 ],\n",
            "       [ 2.7517283 , -3.0935094 ],\n",
            "       [ 2.45889   , -2.8396537 ],\n",
            "       [ 1.9425199 , -2.324435  ],\n",
            "       [ 0.98199534, -1.2962545 ],\n",
            "       [ 0.02619713, -0.33264253],\n",
            "       [ 1.870382  , -2.2225564 ],\n",
            "       [ 1.2212971 , -1.5358514 ],\n",
            "       [ 2.23522   , -2.6040068 ],\n",
            "       [ 0.03661566, -0.32516685],\n",
            "       [ 2.2974994 , -2.6885102 ],\n",
            "       [-1.5194196 ,  1.415177  ],\n",
            "       [-0.1200643 , -0.13441102],\n",
            "       [ 1.7552502 , -2.1177433 ],\n",
            "       [ 0.5182012 , -0.80553585],\n",
            "       [-2.3114433 ,  2.3481123 ],\n",
            "       [ 2.0482934 , -2.3877084 ],\n",
            "       [ 1.64109   , -1.9832221 ],\n",
            "       [-0.931272  ,  0.7408219 ],\n",
            "       [ 1.8862804 , -2.2459657 ],\n",
            "       [ 0.1764208 , -0.4412168 ],\n",
            "       [ 1.7087952 , -2.0247288 ],\n",
            "       [ 2.0914397 , -2.4629667 ],\n",
            "       [ 2.6149724 , -2.9910457 ],\n",
            "       [-0.65382206,  0.41797075],\n",
            "       [-1.1921408 ,  1.0215802 ],\n",
            "       [ 2.558615  , -2.9222257 ],\n",
            "       [ 2.2037942 , -2.570251  ],\n",
            "       [ 2.2089546 , -2.5731285 ],\n",
            "       [-0.24164371, -0.02067786]], dtype=float32), array([[ 1.9729674 , -2.345535  ],\n",
            "       [ 2.4431129 , -2.8104556 ],\n",
            "       [-1.421621  ,  1.3110396 ],\n",
            "       [ 1.5625281 , -1.9549419 ],\n",
            "       [ 2.4028823 , -2.7474704 ],\n",
            "       [ 2.5355375 , -2.9122603 ],\n",
            "       [-0.13304083, -0.11069721],\n",
            "       [ 1.4731597 , -1.8004664 ],\n",
            "       [ 1.1465793 , -1.4596516 ],\n",
            "       [ 1.1380739 , -1.5236309 ],\n",
            "       [-0.10606454, -0.14575543],\n",
            "       [ 1.8516188 , -2.2186337 ],\n",
            "       [ 2.030824  , -2.3798575 ],\n",
            "       [ 2.2039626 , -2.578276  ],\n",
            "       [ 2.178293  , -2.5108302 ],\n",
            "       [-0.80588484,  0.6037067 ],\n",
            "       [ 2.4421182 , -2.8152933 ],\n",
            "       [ 2.418106  , -2.809287  ],\n",
            "       [ 0.86814886, -1.2000153 ],\n",
            "       [ 0.89232266, -1.2076083 ],\n",
            "       [-1.0811843 ,  0.9173092 ],\n",
            "       [ 2.2411327 , -2.5780892 ],\n",
            "       [ 1.6889942 , -2.0424688 ],\n",
            "       [-1.6133677 ,  1.5350543 ],\n",
            "       [ 0.6153539 , -0.92237866],\n",
            "       [ 2.108725  , -2.4771228 ],\n",
            "       [ 2.4189694 , -2.7800887 ],\n",
            "       [ 2.8438427 , -3.186014  ],\n",
            "       [-2.135741  ,  2.1146104 ],\n",
            "       [-0.02026231, -0.2531964 ],\n",
            "       [ 2.05534   , -2.4076002 ],\n",
            "       [ 1.469828  , -1.820789  ]], dtype=float32), array([[ 2.2698429 , -2.6382794 ],\n",
            "       [ 1.9157571 , -2.271424  ],\n",
            "       [-1.8968252 ,  1.816415  ],\n",
            "       [ 1.8700376 , -2.2307618 ],\n",
            "       [ 2.177981  , -2.549456  ],\n",
            "       [ 1.783634  , -2.1396332 ],\n",
            "       [-1.0361384 ,  0.8093184 ],\n",
            "       [ 0.25018674, -0.56825876],\n",
            "       [ 1.8156112 , -2.1878936 ],\n",
            "       [ 1.3546213 , -1.7125052 ],\n",
            "       [ 2.898639  , -3.2103915 ],\n",
            "       [ 1.0427831 , -1.3714718 ],\n",
            "       [ 0.64927125, -0.9763769 ],\n",
            "       [ 1.0327336 , -1.3369598 ],\n",
            "       [ 1.8258625 , -2.166712  ],\n",
            "       [ 2.2434728 , -2.6043475 ],\n",
            "       [ 2.6937056 , -3.047003  ],\n",
            "       [ 2.4088118 , -2.7640903 ],\n",
            "       [ 2.5418808 , -2.8812044 ],\n",
            "       [ 1.4442565 , -1.7900282 ],\n",
            "       [ 0.76442796, -1.0989598 ],\n",
            "       [ 0.6450331 , -0.97182345],\n",
            "       [ 2.8409903 , -3.1661706 ],\n",
            "       [ 2.798526  , -3.1218832 ],\n",
            "       [ 1.6536344 , -1.9974703 ],\n",
            "       [ 2.846401  , -3.1872842 ],\n",
            "       [ 2.6508274 , -3.0154986 ],\n",
            "       [ 2.4707947 , -2.8336802 ],\n",
            "       [ 1.7852569 , -2.1482596 ],\n",
            "       [ 0.9725576 , -1.3216385 ],\n",
            "       [ 2.2195804 , -2.5867636 ],\n",
            "       [ 0.3300546 , -0.636407  ]], dtype=float32), array([[-0.04999084, -0.22158512],\n",
            "       [ 0.08953866, -0.3974348 ],\n",
            "       [ 0.31615952, -0.60241354],\n",
            "       [ 0.2818019 , -0.6036426 ],\n",
            "       [ 1.8083372 , -2.1680202 ],\n",
            "       [ 1.766032  , -2.13158   ],\n",
            "       [ 2.1769812 , -2.54897   ],\n",
            "       [ 0.35669032, -0.6493113 ],\n",
            "       [ 1.0281277 , -1.3555753 ],\n",
            "       [ 2.5152407 , -2.8728082 ],\n",
            "       [ 1.3165356 , -1.6324393 ],\n",
            "       [ 2.6131065 , -2.9559622 ],\n",
            "       [ 0.61077744, -0.930517  ],\n",
            "       [ 1.546282  , -1.8931588 ],\n",
            "       [ 2.181984  , -2.5612705 ],\n",
            "       [ 2.4419088 , -2.799023  ],\n",
            "       [ 2.3432724 , -2.7193549 ],\n",
            "       [ 2.8425033 , -3.140773  ],\n",
            "       [ 2.3342664 , -2.688582  ],\n",
            "       [ 1.8861171 , -2.24183   ],\n",
            "       [ 1.167895  , -1.5206085 ],\n",
            "       [ 1.9875504 , -2.3674886 ],\n",
            "       [-0.0336949 , -0.24714293],\n",
            "       [-0.8113016 ,  0.6104354 ],\n",
            "       [ 2.5457416 , -2.903783  ],\n",
            "       [ 1.4652251 , -1.8188226 ],\n",
            "       [-0.24654607,  0.01163933],\n",
            "       [ 2.697428  , -3.0264225 ],\n",
            "       [-1.1456877 ,  0.9722283 ],\n",
            "       [ 2.3518403 , -2.7000148 ],\n",
            "       [ 0.55887896, -0.8299275 ],\n",
            "       [ 2.416704  , -2.797828  ]], dtype=float32), array([[ 1.9304969 , -2.3058693 ],\n",
            "       [ 1.7882141 , -2.1518638 ],\n",
            "       [ 2.6646235 , -3.0139844 ],\n",
            "       [ 1.8763039 , -2.2309592 ],\n",
            "       [ 2.2233388 , -2.5748277 ],\n",
            "       [ 1.4843277 , -1.8481712 ],\n",
            "       [ 2.8116415 , -3.139974  ],\n",
            "       [-0.68344426,  0.44162288],\n",
            "       [ 1.461541  , -1.8176236 ],\n",
            "       [ 2.3515217 , -2.7356722 ],\n",
            "       [ 1.9904892 , -2.3788602 ],\n",
            "       [ 2.098049  , -2.4738135 ],\n",
            "       [ 2.9509299 , -3.2422986 ],\n",
            "       [ 1.8635803 , -2.2049706 ],\n",
            "       [ 2.401419  , -2.7458522 ],\n",
            "       [ 2.3115542 , -2.652744  ],\n",
            "       [-0.17972974, -0.06517046],\n",
            "       [ 2.1442552 , -2.5129194 ],\n",
            "       [ 1.2053632 , -1.5589167 ],\n",
            "       [ 2.2534308 , -2.6349175 ],\n",
            "       [ 1.5619568 , -1.8845538 ],\n",
            "       [ 1.1823778 , -1.506404  ],\n",
            "       [ 1.1100708 , -1.4410722 ],\n",
            "       [ 1.9048545 , -2.2748778 ],\n",
            "       [ 2.1711247 , -2.5420976 ],\n",
            "       [ 1.3458421 , -1.7299737 ],\n",
            "       [ 1.0325978 , -1.3389803 ],\n",
            "       [ 2.1343105 , -2.4886599 ],\n",
            "       [ 2.1075773 , -2.4837983 ],\n",
            "       [ 2.0014856 , -2.371333  ],\n",
            "       [ 1.7308798 , -2.094915  ],\n",
            "       [ 3.1070156 , -3.3716009 ]], dtype=float32), array([[-2.1288214 ,  2.1012893 ],\n",
            "       [-1.378433  ,  1.234224  ],\n",
            "       [ 0.0137999 , -0.28358075],\n",
            "       [ 0.3271122 , -0.6299058 ],\n",
            "       [ 2.0191634 , -2.3815377 ],\n",
            "       [ 0.91951525, -1.2421452 ],\n",
            "       [ 0.8283584 , -1.1390275 ],\n",
            "       [ 2.6710746 , -3.0102963 ],\n",
            "       [ 1.0453509 , -1.3648812 ],\n",
            "       [ 2.3700352 , -2.716777  ],\n",
            "       [ 2.5746245 , -2.941943  ],\n",
            "       [ 2.4977415 , -2.8469443 ],\n",
            "       [ 1.4776545 , -1.8183852 ],\n",
            "       [ 2.60416   , -2.9622896 ],\n",
            "       [ 0.81649494, -1.1143798 ],\n",
            "       [ 2.2476707 , -2.6360853 ],\n",
            "       [ 1.446447  , -1.7975365 ],\n",
            "       [ 1.4416872 , -1.7910928 ],\n",
            "       [ 1.1529173 , -1.4751748 ],\n",
            "       [ 2.0837533 , -2.4434245 ],\n",
            "       [ 1.9235479 , -2.265658  ],\n",
            "       [ 2.680279  , -3.033427  ],\n",
            "       [ 2.1199338 , -2.462239  ],\n",
            "       [ 2.2633345 , -2.640872  ],\n",
            "       [ 2.5109525 , -2.8813446 ],\n",
            "       [ 2.2530856 , -2.6301687 ],\n",
            "       [-0.23760973, -0.01492421],\n",
            "       [ 1.3844223 , -1.762661  ],\n",
            "       [ 2.0832365 , -2.4418204 ],\n",
            "       [ 2.4704318 , -2.8436651 ],\n",
            "       [ 2.42706   , -2.7833924 ],\n",
            "       [ 2.6030085 , -2.9722707 ]], dtype=float32), array([[ 2.3726842 , -2.7287967 ],\n",
            "       [ 1.3564636 , -1.6851077 ],\n",
            "       [ 2.3434029 , -2.701331  ],\n",
            "       [ 1.7423831 , -2.083007  ],\n",
            "       [ 0.37702513, -0.6775794 ],\n",
            "       [ 2.371635  , -2.7255223 ],\n",
            "       [-0.9038557 ,  0.7279243 ],\n",
            "       [ 0.8096293 , -1.1166061 ],\n",
            "       [ 2.8981931 , -3.2321274 ],\n",
            "       [ 2.2716978 , -2.6212485 ],\n",
            "       [ 0.05458312, -0.3807705 ],\n",
            "       [ 0.9451452 , -1.2761313 ],\n",
            "       [-1.0186688 ,  0.84152365],\n",
            "       [ 2.152747  , -2.5203295 ],\n",
            "       [-0.5571787 ,  0.3378996 ],\n",
            "       [ 1.6919453 , -2.0744505 ],\n",
            "       [-1.0131007 ,  0.8422593 ],\n",
            "       [ 2.2344792 , -2.6085865 ],\n",
            "       [ 2.8908024 , -3.2007701 ],\n",
            "       [ 1.2349764 , -1.5590876 ],\n",
            "       [ 2.722343  , -3.0862615 ],\n",
            "       [ 0.4675477 , -0.77560365],\n",
            "       [ 2.2309058 , -2.6049864 ],\n",
            "       [-0.13658394, -0.15179175],\n",
            "       [ 2.3384893 , -2.7034419 ],\n",
            "       [ 2.716226  , -3.0537655 ],\n",
            "       [ 1.3682787 , -1.7054794 ],\n",
            "       [ 2.5943727 , -2.954981  ],\n",
            "       [-2.7571075 ,  2.8577192 ],\n",
            "       [ 2.5647047 , -2.917324  ],\n",
            "       [ 1.0899264 , -1.4124627 ],\n",
            "       [ 0.68773323, -0.9891943 ]], dtype=float32), array([[-1.2062532 ,  1.0524353 ],\n",
            "       [ 0.10204609, -0.39690033],\n",
            "       [ 0.8472317 , -1.1814598 ],\n",
            "       [ 2.143795  , -2.4959092 ],\n",
            "       [ 2.388077  , -2.7671955 ],\n",
            "       [ 1.2807528 , -1.6397117 ],\n",
            "       [ 2.7323215 , -3.0796242 ],\n",
            "       [ 1.4779128 , -1.8463217 ],\n",
            "       [ 1.8328558 , -2.1742573 ],\n",
            "       [ 1.6904699 , -2.0484002 ],\n",
            "       [ 2.3760695 , -2.7541015 ],\n",
            "       [ 2.671418  , -3.026561  ],\n",
            "       [ 1.7972635 , -2.1737025 ],\n",
            "       [ 1.7664784 , -2.1385105 ],\n",
            "       [ 1.6816207 , -2.0267997 ],\n",
            "       [ 2.6344638 , -2.9821725 ],\n",
            "       [ 2.3474977 , -2.7063763 ],\n",
            "       [ 1.94187   , -2.3187907 ],\n",
            "       [ 2.4334753 , -2.7862685 ],\n",
            "       [ 1.9007    , -2.1984377 ],\n",
            "       [ 2.1998131 , -2.54889   ],\n",
            "       [ 0.47511023, -0.82688844],\n",
            "       [ 0.6455126 , -0.979062  ],\n",
            "       [-2.3444307 ,  2.3580382 ],\n",
            "       [ 1.3705833 , -1.6988224 ],\n",
            "       [ 1.897671  , -2.2755864 ],\n",
            "       [ 1.7831234 , -2.1125162 ],\n",
            "       [-1.4321364 ,  1.3166804 ],\n",
            "       [ 1.256438  , -1.5954516 ],\n",
            "       [ 2.4716    , -2.835953  ],\n",
            "       [ 2.91798   , -3.237406  ],\n",
            "       [ 2.6922696 , -3.0384476 ]], dtype=float32), array([[ 2.6811604 , -3.0226126 ],\n",
            "       [ 1.8867885 , -2.238257  ],\n",
            "       [ 2.155523  , -2.5321643 ],\n",
            "       [ 0.70149916, -1.0136274 ],\n",
            "       [ 3.0291343 , -3.3273916 ],\n",
            "       [ 2.2888052 , -2.6450586 ],\n",
            "       [-0.91415185,  0.7075473 ],\n",
            "       [ 1.9584099 , -2.34184   ],\n",
            "       [-0.7875631 ,  0.5805837 ],\n",
            "       [ 2.2854874 , -2.6340945 ],\n",
            "       [ 0.93480957, -1.2530615 ],\n",
            "       [-0.19692062, -0.0713485 ],\n",
            "       [ 1.6089199 , -1.9538347 ],\n",
            "       [ 1.9670185 , -2.3130677 ],\n",
            "       [ 2.3050797 , -2.669524  ],\n",
            "       [ 2.0682764 , -2.41414   ],\n",
            "       [ 1.6955675 , -2.0494483 ],\n",
            "       [ 1.5025438 , -1.8349386 ],\n",
            "       [ 0.8472617 , -1.1244886 ],\n",
            "       [ 0.9530299 , -1.2864525 ],\n",
            "       [ 1.9285804 , -2.2961285 ],\n",
            "       [-0.06809533, -0.18779023],\n",
            "       [ 2.407376  , -2.782435  ],\n",
            "       [ 1.661703  , -2.0307267 ],\n",
            "       [ 0.0782819 , -0.34720385],\n",
            "       [ 1.2546035 , -1.552971  ],\n",
            "       [ 0.06270044, -0.33943865],\n",
            "       [ 0.4854629 , -0.7850418 ],\n",
            "       [-0.63252544,  0.38498768],\n",
            "       [ 2.1699092 , -2.5460327 ],\n",
            "       [ 3.1743262 , -3.4220467 ],\n",
            "       [ 1.102261  , -1.4419581 ]], dtype=float32), array([[ 1.9762452 , -2.3360827 ],\n",
            "       [ 2.2569728 , -2.6110437 ],\n",
            "       [ 1.4212383 , -1.8000687 ],\n",
            "       [ 1.4139307 , -1.784288  ],\n",
            "       [ 2.4004297 , -2.7566528 ],\n",
            "       [-1.769679  ,  1.693839  ],\n",
            "       [ 2.2312753 , -2.6020262 ],\n",
            "       [ 1.918372  , -2.2825353 ],\n",
            "       [ 2.1993852 , -2.552434  ],\n",
            "       [ 1.1338146 , -1.4707762 ],\n",
            "       [ 2.198486  , -2.5769844 ],\n",
            "       [ 2.0992687 , -2.4710503 ],\n",
            "       [ 1.9107757 , -2.268154  ],\n",
            "       [-0.7940146 ,  0.59342426],\n",
            "       [ 2.9677703 , -3.2772248 ],\n",
            "       [ 1.3531716 , -1.6997452 ],\n",
            "       [ 2.980337  , -3.2874858 ],\n",
            "       [ 2.467076  , -2.8506882 ],\n",
            "       [ 0.9096913 , -1.2211608 ],\n",
            "       [-0.00456701, -0.29291818],\n",
            "       [ 2.8056557 , -3.141803  ],\n",
            "       [ 2.1464937 , -2.5292919 ],\n",
            "       [ 2.1105063 , -2.4662743 ],\n",
            "       [ 1.9859818 , -2.3373697 ],\n",
            "       [ 1.1636468 , -1.5127207 ],\n",
            "       [ 2.8181727 , -3.1372187 ],\n",
            "       [ 2.4004116 , -2.7575269 ],\n",
            "       [ 2.0822084 , -2.4412928 ],\n",
            "       [ 2.2953522 , -2.6607854 ],\n",
            "       [ 1.4804184 , -1.827783  ],\n",
            "       [ 2.2347739 , -2.5852506 ],\n",
            "       [ 2.2142098 , -2.596146  ]], dtype=float32), array([[-0.07349066, -0.18754284],\n",
            "       [ 1.8439645 , -2.214237  ],\n",
            "       [ 0.93749714, -1.2767166 ],\n",
            "       [ 2.2323554 , -2.6073735 ],\n",
            "       [ 1.2497824 , -1.5865107 ],\n",
            "       [ 1.552927  , -1.9087328 ],\n",
            "       [-0.12334643, -0.13201992],\n",
            "       [ 2.4368002 , -2.8152106 ],\n",
            "       [-0.370536  ,  0.11419435],\n",
            "       [ 0.81068856, -1.1372306 ],\n",
            "       [ 0.00710376, -0.27026576],\n",
            "       [ 0.75628746, -1.0976812 ],\n",
            "       [ 2.4203146 , -2.793205  ],\n",
            "       [ 1.1203806 , -1.4606445 ],\n",
            "       [ 2.275006  , -2.6524894 ],\n",
            "       [ 1.6733408 , -2.0006335 ],\n",
            "       [ 1.9267682 , -2.286002  ],\n",
            "       [ 2.2538755 , -2.6152585 ],\n",
            "       [ 0.6507352 , -0.90930116],\n",
            "       [ 1.7109903 , -2.071747  ],\n",
            "       [ 2.86219   , -3.1819623 ],\n",
            "       [ 1.4152026 , -1.7728704 ],\n",
            "       [ 2.4338393 , -2.7807906 ],\n",
            "       [ 0.48973134, -0.76587653],\n",
            "       [ 2.8988514 , -3.212561  ],\n",
            "       [ 0.3064088 , -0.59034806],\n",
            "       [ 0.4739981 , -0.76542807],\n",
            "       [ 1.759886  , -2.0998218 ],\n",
            "       [ 2.0496354 , -2.3911097 ],\n",
            "       [ 2.0900648 , -2.452329  ],\n",
            "       [ 2.241403  , -2.6157815 ],\n",
            "       [ 1.3131319 , -1.6510733 ]], dtype=float32), array([[ 1.131819  , -1.4696975 ],\n",
            "       [ 2.4469209 , -2.810572  ],\n",
            "       [ 2.0496142 , -2.4192743 ],\n",
            "       [ 0.20157339, -0.46666417],\n",
            "       [ 1.6199965 , -1.9666344 ],\n",
            "       [ 1.9162054 , -2.2929344 ],\n",
            "       [ 2.568982  , -2.939792  ],\n",
            "       [ 2.8545594 , -3.1811025 ],\n",
            "       [ 0.00867142, -0.30430654],\n",
            "       [ 0.00788065, -0.2932466 ],\n",
            "       [-1.0908769 ,  0.92792976],\n",
            "       [ 1.7987336 , -2.1233695 ],\n",
            "       [ 2.453851  , -2.8211577 ],\n",
            "       [ 2.5751073 , -2.931472  ],\n",
            "       [ 1.3866394 , -1.7264136 ],\n",
            "       [-0.07789684, -0.20424138],\n",
            "       [ 1.4318343 , -1.7537478 ],\n",
            "       [ 0.16926004, -0.45830902],\n",
            "       [ 0.31877896, -0.6218215 ],\n",
            "       [ 1.1350814 , -1.4788028 ],\n",
            "       [ 1.1990651 , -1.5299748 ],\n",
            "       [ 2.848997  , -3.1808863 ],\n",
            "       [ 1.8852364 , -2.2622602 ],\n",
            "       [ 2.9419708 , -3.2589948 ],\n",
            "       [ 2.6368597 , -2.9985604 ],\n",
            "       [ 0.4843261 , -0.7642631 ],\n",
            "       [ 2.8794258 , -3.2020109 ],\n",
            "       [ 1.9767245 , -2.328635  ],\n",
            "       [ 2.354275  , -2.703997  ],\n",
            "       [-0.35048583,  0.09425277],\n",
            "       [ 2.0115697 , -2.3781693 ],\n",
            "       [ 0.76943487, -1.1074723 ]], dtype=float32), array([[ 1.6637075 , -2.0184221 ],\n",
            "       [ 0.83703077, -1.1648086 ],\n",
            "       [ 2.2219    , -2.592296  ],\n",
            "       [ 0.13444813, -0.42188212],\n",
            "       [ 1.8731428 , -2.2436743 ],\n",
            "       [ 1.8581681 , -2.228214  ],\n",
            "       [ 2.086314  , -2.4267662 ],\n",
            "       [ 0.57593924, -0.8672192 ],\n",
            "       [ 2.01941   , -2.373373  ],\n",
            "       [ 1.357565  , -1.7378746 ],\n",
            "       [ 0.7018056 , -1.0233079 ],\n",
            "       [ 1.5085131 , -1.8656405 ],\n",
            "       [ 1.7099985 , -2.0786273 ],\n",
            "       [ 0.17558251, -0.45826718],\n",
            "       [ 2.3034918 , -2.6846673 ],\n",
            "       [ 2.1589782 , -2.5319068 ],\n",
            "       [-0.03643335, -0.2534481 ],\n",
            "       [-0.13117887, -0.13434403],\n",
            "       [ 1.5882808 , -1.9168593 ],\n",
            "       [ 2.0687387 , -2.4071615 ],\n",
            "       [ 1.0768739 , -1.4608692 ],\n",
            "       [ 1.1610732 , -1.4602058 ],\n",
            "       [-1.9520864 ,  1.8736248 ],\n",
            "       [ 0.48501518, -0.79105264],\n",
            "       [ 2.937867  , -3.2436821 ],\n",
            "       [ 2.2777088 , -2.6538396 ],\n",
            "       [ 0.86125183, -1.159578  ],\n",
            "       [ 2.2735345 , -2.6385486 ],\n",
            "       [ 2.154124  , -2.5274923 ],\n",
            "       [ 0.06579336, -0.332199  ],\n",
            "       [ 2.1234238 , -2.4732108 ],\n",
            "       [ 2.1507573 , -2.5009875 ]], dtype=float32), array([[-1.4164534 ,  1.2653601 ],\n",
            "       [ 0.95063895, -1.2835802 ],\n",
            "       [ 1.94157   , -2.2869823 ],\n",
            "       [ 0.16927208, -0.43730757],\n",
            "       [ 1.1771649 , -1.5151638 ],\n",
            "       [ 1.7634662 , -2.124922  ],\n",
            "       [ 0.5554991 , -0.85485303],\n",
            "       [ 1.6112367 , -1.9728748 ],\n",
            "       [ 1.5973722 , -1.932879  ],\n",
            "       [-1.4147424 ,  1.2864658 ],\n",
            "       [-0.43427816,  0.18495633],\n",
            "       [ 2.4125068 , -2.7859638 ],\n",
            "       [ 2.685047  , -3.0414598 ],\n",
            "       [ 2.3726404 , -2.7415411 ],\n",
            "       [ 1.2107323 , -1.5380911 ],\n",
            "       [ 1.894338  , -2.255636  ],\n",
            "       [ 1.6950419 , -2.0652304 ],\n",
            "       [ 0.00833117, -0.269124  ],\n",
            "       [ 0.21078072, -0.50314164],\n",
            "       [ 2.2810202 , -2.6444485 ],\n",
            "       [ 2.4890244 , -2.838579  ],\n",
            "       [ 1.4403412 , -1.7987076 ],\n",
            "       [ 0.72773397, -1.0416104 ],\n",
            "       [-1.2867001 ,  1.1464105 ],\n",
            "       [ 1.4677688 , -1.7975103 ],\n",
            "       [ 2.6298459 , -2.9754236 ],\n",
            "       [ 2.7305253 , -3.0688212 ],\n",
            "       [ 1.9426436 , -2.2749991 ],\n",
            "       [ 1.5539511 , -1.9247321 ],\n",
            "       [ 2.8459857 , -3.1704345 ],\n",
            "       [ 1.9535099 , -2.3362062 ],\n",
            "       [-0.7043346 ,  0.49009666]], dtype=float32), array([[ 2.014918  , -2.3832693 ],\n",
            "       [ 0.50157666, -0.8220029 ],\n",
            "       [ 0.39643502, -0.67923653],\n",
            "       [ 0.84519947, -1.1436275 ],\n",
            "       [-1.1202189 ,  0.9752718 ],\n",
            "       [ 0.3645192 , -0.658865  ],\n",
            "       [ 2.1394722 , -2.5006278 ],\n",
            "       [ 1.706304  , -2.0628731 ],\n",
            "       [ 2.2114236 , -2.5870109 ],\n",
            "       [ 2.1871789 , -2.5583477 ],\n",
            "       [-0.6119223 ,  0.39993864],\n",
            "       [ 1.768684  , -2.1553123 ],\n",
            "       [ 1.6764096 , -2.021038  ],\n",
            "       [ 2.26841   , -2.633403  ],\n",
            "       [ 2.0718315 , -2.4385843 ],\n",
            "       [ 1.0592464 , -1.3969148 ],\n",
            "       [ 2.2576807 , -2.6088915 ],\n",
            "       [ 2.7872999 , -3.1459095 ],\n",
            "       [ 1.5191787 , -1.8454632 ],\n",
            "       [-0.49804422,  0.24653925],\n",
            "       [ 2.6408436 , -3.003249  ],\n",
            "       [ 0.6510527 , -0.96130884],\n",
            "       [ 2.8856554 , -3.1763527 ],\n",
            "       [ 1.5454041 , -1.8979731 ],\n",
            "       [-0.12974225, -0.12160426],\n",
            "       [ 2.847871  , -3.169612  ],\n",
            "       [ 2.032007  , -2.4136612 ],\n",
            "       [ 1.4916254 , -1.8426225 ],\n",
            "       [-1.7426243 ,  1.6630069 ],\n",
            "       [ 1.5481495 , -1.9186707 ],\n",
            "       [ 2.1669388 , -2.4883869 ],\n",
            "       [-0.15860231, -0.14480413]], dtype=float32), array([[ 1.1986619 , -1.5221303 ],\n",
            "       [ 1.7429749 , -2.0985038 ],\n",
            "       [ 2.545551  , -2.9187567 ],\n",
            "       [ 2.176968  , -2.5314467 ],\n",
            "       [ 2.3388479 , -2.7270393 ],\n",
            "       [ 2.40199   , -2.7540958 ],\n",
            "       [-0.4916675 ,  0.21796031],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 1.420005  , -1.7589713 ],\n",
            "       [ 1.0983686 , -1.4274595 ],\n",
            "       [ 1.258021  , -1.5691329 ],\n",
            "       [ 0.5968807 , -0.8904648 ],\n",
            "       [ 1.5199231 , -1.8922659 ],\n",
            "       [ 2.4326375 , -2.7974675 ],\n",
            "       [ 1.530672  , -1.9063972 ],\n",
            "       [-0.14264525, -0.12510131],\n",
            "       [ 1.3917094 , -1.7123202 ],\n",
            "       [ 2.7383149 , -3.0675552 ],\n",
            "       [ 1.2227724 , -1.5655345 ],\n",
            "       [ 0.89279234, -1.2523133 ],\n",
            "       [ 2.407468  , -2.7819078 ],\n",
            "       [ 2.7365954 , -3.0783007 ],\n",
            "       [ 2.254629  , -2.6121666 ],\n",
            "       [ 1.4865283 , -1.8297335 ],\n",
            "       [-0.14343856, -0.11840357],\n",
            "       [-0.681298  ,  0.47611293],\n",
            "       [ 2.333385  , -2.7140071 ],\n",
            "       [ 2.508566  , -2.8927271 ],\n",
            "       [ 2.248885  , -2.5986667 ],\n",
            "       [-0.93454885,  0.7615663 ],\n",
            "       [ 2.377624  , -2.7514336 ],\n",
            "       [ 1.8074876 , -2.1503122 ]], dtype=float32), array([[ 2.32695   , -2.664852  ],\n",
            "       [ 1.1108922 , -1.444877  ],\n",
            "       [ 3.0467265 , -3.3285403 ],\n",
            "       [ 2.0939124 , -2.4723413 ],\n",
            "       [ 1.4906621 , -1.8557217 ],\n",
            "       [ 1.9926783 , -2.3547575 ],\n",
            "       [ 0.8952489 , -1.2092448 ],\n",
            "       [ 2.4603395 , -2.8242028 ],\n",
            "       [ 1.6148123 , -1.9752797 ],\n",
            "       [-2.577329  ,  2.6214306 ],\n",
            "       [ 1.6960838 , -2.058785  ],\n",
            "       [ 1.1764396 , -1.5220124 ],\n",
            "       [ 0.92735595, -1.2587563 ],\n",
            "       [ 1.3372322 , -1.710335  ],\n",
            "       [ 1.713643  , -2.109789  ],\n",
            "       [ 2.674092  , -3.0046117 ],\n",
            "       [ 2.1327126 , -2.4916992 ],\n",
            "       [-1.3850452 ,  1.2305449 ],\n",
            "       [ 0.6552551 , -1.0221058 ],\n",
            "       [ 0.37589657, -0.66195095],\n",
            "       [ 1.9633126 , -2.3450994 ],\n",
            "       [-2.1911905 ,  2.2028306 ],\n",
            "       [ 2.2121513 , -2.5805037 ],\n",
            "       [ 2.3496106 , -2.7204869 ],\n",
            "       [ 2.002269  , -2.3653667 ],\n",
            "       [ 2.260164  , -2.6395512 ],\n",
            "       [-0.43130642,  0.19958515],\n",
            "       [ 0.9996717 , -1.3023013 ],\n",
            "       [ 1.1230999 , -1.4661665 ],\n",
            "       [ 2.1646683 , -2.526673  ],\n",
            "       [ 2.0673516 , -2.4399493 ],\n",
            "       [ 2.5621884 , -2.9214146 ]], dtype=float32), array([[ 0.70040596, -1.0069393 ],\n",
            "       [ 0.09153648, -0.36706683],\n",
            "       [ 0.00565397, -0.308698  ],\n",
            "       [ 2.394545  , -2.7526453 ],\n",
            "       [ 0.387507  , -0.6671358 ],\n",
            "       [ 2.723118  , -3.0683167 ],\n",
            "       [-0.6636246 ,  0.4204546 ],\n",
            "       [ 1.4949915 , -1.8478798 ],\n",
            "       [-0.04434888, -0.23692003],\n",
            "       [ 0.9497785 , -1.278991  ],\n",
            "       [ 0.7157606 , -1.0514251 ],\n",
            "       [ 0.8476531 , -1.1536837 ],\n",
            "       [ 1.8514569 , -2.229532  ],\n",
            "       [ 2.6994703 , -3.029084  ],\n",
            "       [ 2.575378  , -2.939963  ],\n",
            "       [ 1.6140437 , -1.9596479 ],\n",
            "       [ 1.2063363 , -1.5328511 ],\n",
            "       [ 2.4448397 , -2.8160183 ],\n",
            "       [ 2.6979048 , -3.0522642 ],\n",
            "       [-1.1032528 ,  1.0232872 ],\n",
            "       [ 1.7572029 , -2.121333  ],\n",
            "       [ 2.4464345 , -2.7978456 ],\n",
            "       [ 1.6448792 , -2.000912  ],\n",
            "       [ 2.5658245 , -2.8943324 ],\n",
            "       [ 2.833711  , -3.1707017 ],\n",
            "       [ 2.7282968 , -3.0526874 ],\n",
            "       [ 1.8011993 , -2.1491246 ],\n",
            "       [-1.549633  ,  1.4613279 ],\n",
            "       [ 1.7323538 , -2.0920792 ],\n",
            "       [ 2.3167284 , -2.7004106 ],\n",
            "       [ 1.9413533 , -2.3154464 ],\n",
            "       [-1.2833444 ,  1.1059328 ]], dtype=float32), array([[ 1.0366904 , -1.3686768 ],\n",
            "       [ 2.9552686 , -3.264829  ],\n",
            "       [ 2.4375236 , -2.8009145 ],\n",
            "       [ 0.4280282 , -0.7344152 ],\n",
            "       [ 1.728377  , -2.0803258 ],\n",
            "       [ 1.8888034 , -2.2552512 ],\n",
            "       [ 2.2554412 , -2.6181557 ],\n",
            "       [ 2.8589885 , -3.1788485 ],\n",
            "       [ 1.5639273 , -1.9069189 ],\n",
            "       [ 1.8591712 , -2.208325  ],\n",
            "       [ 2.5050414 , -2.8769512 ],\n",
            "       [ 1.8451343 , -2.199383  ],\n",
            "       [ 1.7120413 , -2.052398  ],\n",
            "       [-2.1125531 ,  2.105817  ],\n",
            "       [ 0.4819505 , -0.79061425],\n",
            "       [ 2.5133402 , -2.8690917 ],\n",
            "       [ 2.1381218 , -2.4873533 ],\n",
            "       [ 0.76320165, -1.0563781 ],\n",
            "       [ 2.0716922 , -2.4460337 ],\n",
            "       [ 0.7295191 , -1.006893  ],\n",
            "       [-1.9739867 ,  1.9284114 ],\n",
            "       [-1.3622866 ,  1.252235  ],\n",
            "       [-1.2149552 ,  1.0643516 ],\n",
            "       [ 1.9926482 , -2.3503516 ],\n",
            "       [ 1.4603676 , -1.7975516 ],\n",
            "       [ 2.2418702 , -2.6110902 ],\n",
            "       [-0.8361192 ,  0.6650962 ],\n",
            "       [ 1.526805  , -1.8867843 ],\n",
            "       [ 0.738347  , -1.0710297 ],\n",
            "       [ 2.1742454 , -2.5404165 ],\n",
            "       [ 0.571398  , -0.9048524 ],\n",
            "       [ 2.236056  , -2.5759146 ]], dtype=float32), array([[ 2.2849638 , -2.6524794 ],\n",
            "       [ 1.0882883 , -1.3895738 ],\n",
            "       [ 2.175865  , -2.4935932 ],\n",
            "       [ 2.3836277 , -2.75092   ],\n",
            "       [ 1.4659346 , -1.8227092 ],\n",
            "       [ 1.0330862 , -1.3618947 ],\n",
            "       [ 1.294655  , -1.6338649 ],\n",
            "       [ 2.3404317 , -2.6881607 ],\n",
            "       [ 2.4860203 , -2.8647854 ],\n",
            "       [ 1.3329884 , -1.6928158 ],\n",
            "       [ 1.4836768 , -1.8417978 ],\n",
            "       [ 2.1672661 , -2.520652  ],\n",
            "       [ 2.1400058 , -2.5012753 ],\n",
            "       [-0.6484932 ,  0.44795   ],\n",
            "       [ 1.3113445 , -1.6518539 ],\n",
            "       [ 2.0121224 , -2.3786108 ],\n",
            "       [ 2.4295905 , -2.781126  ],\n",
            "       [ 2.9484897 , -3.2512243 ],\n",
            "       [ 2.79591   , -3.1354053 ],\n",
            "       [ 2.490908  , -2.861124  ],\n",
            "       [ 2.1855903 , -2.5557358 ],\n",
            "       [ 2.226721  , -2.5841582 ],\n",
            "       [ 2.4972775 , -2.862413  ],\n",
            "       [ 0.29140052, -0.546054  ],\n",
            "       [ 1.9496088 , -2.3151858 ],\n",
            "       [ 1.7394185 , -2.0808072 ],\n",
            "       [ 0.1217024 , -0.40065092],\n",
            "       [-0.36624274,  0.11323792],\n",
            "       [ 2.5871408 , -2.9561515 ],\n",
            "       [ 1.9139334 , -2.2615068 ],\n",
            "       [ 0.81606   , -1.1090717 ],\n",
            "       [-1.3452761 ,  1.1729635 ]], dtype=float32), array([[ 2.028659  , -2.3890495 ],\n",
            "       [ 0.02241587, -0.30615348],\n",
            "       [ 2.8611107 , -3.1779315 ],\n",
            "       [-0.7918951 ,  0.61133313],\n",
            "       [ 1.0214031 , -1.3340586 ],\n",
            "       [-0.6922972 ,  0.48136017],\n",
            "       [-0.4945907 ,  0.23107503],\n",
            "       [ 1.0172389 , -1.3608966 ],\n",
            "       [ 1.7841607 , -2.1744807 ],\n",
            "       [ 2.900949  , -3.2294772 ],\n",
            "       [ 1.7952381 , -2.156895  ],\n",
            "       [ 2.34484   , -2.6973178 ],\n",
            "       [ 2.966181  , -3.267619  ],\n",
            "       [ 2.2866437 , -2.6215305 ],\n",
            "       [ 1.9984887 , -2.3997    ],\n",
            "       [ 1.6892126 , -2.0242639 ],\n",
            "       [ 0.07484531, -0.34128883],\n",
            "       [ 0.6982802 , -1.0050901 ],\n",
            "       [ 1.0389022 , -1.3468034 ],\n",
            "       [ 2.3954127 , -2.7267973 ],\n",
            "       [ 2.6428897 , -3.0043013 ],\n",
            "       [ 1.9821366 , -2.3110535 ],\n",
            "       [ 1.775644  , -2.147643  ],\n",
            "       [ 2.5123484 , -2.9018238 ],\n",
            "       [ 2.4115295 , -2.790371  ],\n",
            "       [-0.18886064, -0.05701806],\n",
            "       [ 0.20330445, -0.5157316 ],\n",
            "       [ 2.445163  , -2.8030698 ],\n",
            "       [ 0.35869464, -0.7028624 ],\n",
            "       [ 2.5689836 , -2.8994803 ],\n",
            "       [ 1.2383418 , -1.5759903 ],\n",
            "       [-2.1329768 ,  2.1062815 ]], dtype=float32), array([[ 0.20536248, -0.49720123],\n",
            "       [ 1.9429283 , -2.3148987 ],\n",
            "       [ 1.7892729 , -2.1328204 ],\n",
            "       [ 0.942387  , -1.2551507 ],\n",
            "       [ 1.1591021 , -1.5398246 ],\n",
            "       [ 1.0781654 , -1.4172543 ],\n",
            "       [ 0.33541673, -0.622333  ],\n",
            "       [ 1.6502752 , -1.963932  ],\n",
            "       [ 2.6891158 , -3.0317526 ],\n",
            "       [ 0.02457391, -0.32802805],\n",
            "       [ 2.654587  , -3.0184104 ],\n",
            "       [ 2.826916  , -3.163586  ],\n",
            "       [ 2.8112109 , -3.1506171 ],\n",
            "       [ 2.2691016 , -2.6295493 ],\n",
            "       [ 0.38674006, -0.67744607],\n",
            "       [ 0.2646016 , -0.58117986],\n",
            "       [ 1.0729104 , -1.4284858 ],\n",
            "       [ 1.6775205 , -2.027749  ],\n",
            "       [ 1.1597911 , -1.4884906 ],\n",
            "       [-0.9309268 ,  0.751266  ],\n",
            "       [ 2.0718782 , -2.4681408 ],\n",
            "       [ 2.3788965 , -2.7452152 ],\n",
            "       [ 2.2630975 , -2.6413057 ],\n",
            "       [ 1.8417562 , -2.191017  ],\n",
            "       [ 1.9490436 , -2.3204296 ],\n",
            "       [ 1.4382756 , -1.7929889 ],\n",
            "       [-2.4804897 ,  2.5237403 ],\n",
            "       [ 2.1587198 , -2.5461576 ],\n",
            "       [ 0.6688649 , -0.9647143 ],\n",
            "       [ 2.1867268 , -2.5500119 ],\n",
            "       [ 2.5499372 , -2.9106472 ],\n",
            "       [ 1.4088054 , -1.7582165 ]], dtype=float32), array([[ 1.0177526 , -1.3615388 ],\n",
            "       [ 1.7633128 , -2.1165702 ],\n",
            "       [ 2.5813816 , -2.9362063 ],\n",
            "       [ 2.433326  , -2.7813323 ],\n",
            "       [ 2.5806415 , -2.9302237 ],\n",
            "       [ 2.8241484 , -3.1554825 ],\n",
            "       [ 2.1960957 , -2.5642617 ],\n",
            "       [-0.00788931, -0.25845972],\n",
            "       [ 2.4187882 , -2.786604  ],\n",
            "       [-0.5077394 ,  0.26436394],\n",
            "       [ 0.669417  , -0.96088016],\n",
            "       [ 0.67187876, -0.9843738 ],\n",
            "       [ 1.4895697 , -1.835302  ],\n",
            "       [ 1.7233623 , -2.0752192 ],\n",
            "       [ 3.1461337 , -3.394078  ],\n",
            "       [ 2.3278515 , -2.6852295 ],\n",
            "       [-0.45714444,  0.20283459],\n",
            "       [ 2.5100236 , -2.8746243 ],\n",
            "       [ 1.9894515 , -2.3612885 ],\n",
            "       [ 1.188209  , -1.5223078 ],\n",
            "       [ 2.9618697 , -3.2650497 ],\n",
            "       [ 2.0185187 , -2.3899562 ],\n",
            "       [ 1.7952434 , -2.1649573 ],\n",
            "       [ 2.1711552 , -2.5272624 ],\n",
            "       [ 2.2723954 , -2.6401947 ],\n",
            "       [ 1.67195   , -2.0355315 ],\n",
            "       [ 0.7792145 , -1.096421  ],\n",
            "       [ 0.42275748, -0.70870304],\n",
            "       [ 2.1194909 , -2.4926493 ],\n",
            "       [ 2.2769258 , -2.6351368 ],\n",
            "       [ 2.1976388 , -2.5816908 ],\n",
            "       [ 1.9683751 , -2.3401706 ]], dtype=float32), array([[-1.9452966 ,  1.886912  ],\n",
            "       [-1.0133706 ,  0.81932366],\n",
            "       [ 2.6999178 , -3.0617375 ],\n",
            "       [ 2.947725  , -3.247594  ],\n",
            "       [ 2.1535792 , -2.5318973 ],\n",
            "       [ 2.4059176 , -2.7851474 ],\n",
            "       [ 2.6552942 , -3.0206814 ],\n",
            "       [ 1.7804028 , -2.1427176 ],\n",
            "       [ 2.1916466 , -2.5633402 ],\n",
            "       [ 1.7685393 , -2.1333277 ],\n",
            "       [ 0.3551885 , -0.662842  ],\n",
            "       [ 2.4011235 , -2.7673502 ],\n",
            "       [ 0.08209746, -0.35630822],\n",
            "       [ 3.1233664 , -3.3813086 ],\n",
            "       [ 0.36648282, -0.6710472 ],\n",
            "       [ 1.6191324 , -1.9767449 ],\n",
            "       [ 2.6405442 , -2.9830961 ],\n",
            "       [ 2.6744108 , -3.029013  ],\n",
            "       [ 2.0288284 , -2.3829005 ],\n",
            "       [ 0.80624545, -1.1022949 ],\n",
            "       [ 1.324304  , -1.6509718 ],\n",
            "       [-0.605481  ,  0.38006976],\n",
            "       [ 0.83116925, -1.1449888 ],\n",
            "       [ 2.2566311 , -2.649418  ],\n",
            "       [ 2.2216375 , -2.5860853 ],\n",
            "       [ 1.749823  , -2.1325634 ],\n",
            "       [ 0.4900824 , -0.7641966 ],\n",
            "       [ 2.0785117 , -2.3683343 ],\n",
            "       [ 3.090185  , -3.3635569 ],\n",
            "       [ 2.1078265 , -2.4979148 ],\n",
            "       [ 2.3973377 , -2.741358  ],\n",
            "       [ 0.81258744, -1.1290482 ]], dtype=float32), array([[-1.5615476 ,  1.4064727 ],\n",
            "       [ 2.4828713 , -2.8458762 ],\n",
            "       [ 2.123545  , -2.499477  ],\n",
            "       [ 2.4242666 , -2.8002856 ],\n",
            "       [ 1.174002  , -1.5132643 ],\n",
            "       [ 2.3106782 , -2.6584742 ],\n",
            "       [ 2.3271446 , -2.68796   ],\n",
            "       [-0.7029166 ,  0.49029383],\n",
            "       [ 0.8028167 , -1.1187803 ],\n",
            "       [ 2.0550423 , -2.419702  ],\n",
            "       [-0.7067179 ,  0.467151  ],\n",
            "       [ 0.25427666, -0.57435256],\n",
            "       [ 1.8328499 , -2.1764781 ],\n",
            "       [ 2.6117988 , -2.9773798 ],\n",
            "       [ 0.94942594, -1.2925143 ],\n",
            "       [ 3.0772922 , -3.34786   ],\n",
            "       [ 0.491416  , -0.7983561 ],\n",
            "       [ 2.412421  , -2.7674377 ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 2.626763  , -2.965103  ],\n",
            "       [ 1.544924  , -1.8816514 ],\n",
            "       [ 1.7715786 , -2.1358476 ],\n",
            "       [-2.129929  ,  2.102564  ],\n",
            "       [ 2.4824536 , -2.8525696 ],\n",
            "       [ 1.813342  , -2.1487017 ],\n",
            "       [ 1.9360586 , -2.3005686 ],\n",
            "       [ 2.4129615 , -2.7881205 ],\n",
            "       [ 1.0624202 , -1.4045712 ],\n",
            "       [ 2.8821356 , -3.2122602 ],\n",
            "       [ 0.7285203 , -1.0538697 ],\n",
            "       [ 1.4355661 , -1.7697519 ],\n",
            "       [ 1.8704698 , -2.224224  ]], dtype=float32), array([[ 1.0023845 , -1.3163267 ],\n",
            "       [ 0.06258359, -0.37591895],\n",
            "       [ 0.0502929 , -0.34424046],\n",
            "       [-1.680917  ,  1.5937897 ],\n",
            "       [-2.5067866 ,  2.5389845 ],\n",
            "       [ 2.0385644 , -2.398501  ],\n",
            "       [ 2.6661975 , -3.0207765 ],\n",
            "       [ 1.9046429 , -2.2860482 ],\n",
            "       [ 2.6244385 , -2.9713662 ],\n",
            "       [ 2.7019858 , -3.0419948 ],\n",
            "       [-2.0278637 ,  1.9804925 ],\n",
            "       [ 1.8138586 , -2.2176435 ],\n",
            "       [ 0.73361254, -1.0599462 ],\n",
            "       [ 1.0765157 , -1.4115609 ],\n",
            "       [ 1.3285073 , -1.6550936 ],\n",
            "       [ 0.4138855 , -0.69860315],\n",
            "       [ 1.7465016 , -2.1053772 ],\n",
            "       [ 0.63304514, -0.9848441 ],\n",
            "       [ 1.9883326 , -2.372915  ],\n",
            "       [-1.1425015 ,  0.96345425],\n",
            "       [ 1.9829147 , -2.3356454 ],\n",
            "       [-1.0168856 ,  0.83517617],\n",
            "       [ 1.7664466 , -2.1151285 ],\n",
            "       [ 2.7577357 , -3.1006513 ],\n",
            "       [ 0.08592819, -0.38107392],\n",
            "       [ 2.5885978 , -2.9488428 ],\n",
            "       [ 1.3821744 , -1.7383779 ],\n",
            "       [-0.51085466,  0.35341996],\n",
            "       [ 2.8726459 , -3.2076795 ],\n",
            "       [ 2.7091978 , -3.0544174 ],\n",
            "       [ 2.702369  , -3.0465515 ],\n",
            "       [ 1.844829  , -2.1909919 ]], dtype=float32), array([[-1.6243558 ,  1.500382  ],\n",
            "       [ 0.25262803, -0.5242601 ],\n",
            "       [-1.9201237 ,  1.8717201 ],\n",
            "       [ 0.17474149, -0.4349007 ],\n",
            "       [-0.45748672,  0.22309117],\n",
            "       [ 2.086163  , -2.4377682 ],\n",
            "       [ 1.4696755 , -1.8110164 ],\n",
            "       [ 1.5604687 , -1.9038948 ],\n",
            "       [ 2.720547  , -3.0589688 ],\n",
            "       [ 0.70340204, -1.0242261 ],\n",
            "       [ 2.2632365 , -2.6347783 ],\n",
            "       [ 0.93920535, -1.2612902 ],\n",
            "       [ 2.730065  , -3.06041   ],\n",
            "       [ 2.1437654 , -2.490609  ],\n",
            "       [ 2.5712152 , -2.925218  ],\n",
            "       [ 2.1120458 , -2.4773195 ],\n",
            "       [ 0.5927193 , -0.9381244 ],\n",
            "       [ 1.7754132 , -2.147401  ],\n",
            "       [ 2.5361826 , -2.8751175 ],\n",
            "       [ 1.8973247 , -2.2606103 ],\n",
            "       [ 2.2758296 , -2.64347   ],\n",
            "       [-0.14490713, -0.12320135],\n",
            "       [ 2.2899945 , -2.6537259 ],\n",
            "       [ 1.704364  , -2.0243356 ],\n",
            "       [ 2.7706492 , -3.0927794 ],\n",
            "       [ 2.6897757 , -3.0388107 ],\n",
            "       [ 1.7943804 , -2.1333296 ],\n",
            "       [ 2.2436488 , -2.606788  ],\n",
            "       [-0.24082185, -0.00615931],\n",
            "       [ 1.4447122 , -1.7818848 ],\n",
            "       [ 0.92402995, -1.2700616 ],\n",
            "       [ 2.464327  , -2.8380916 ]], dtype=float32), array([[-0.31083664,  0.05218883],\n",
            "       [ 1.5929401 , -1.9655443 ],\n",
            "       [ 2.490039  , -2.8339303 ],\n",
            "       [ 2.598929  , -2.9528842 ],\n",
            "       [-3.044647  ,  3.2490494 ],\n",
            "       [ 2.2699344 , -2.625378  ],\n",
            "       [ 2.1280844 , -2.5117652 ],\n",
            "       [ 1.8919898 , -2.2473345 ],\n",
            "       [-1.6216143 ,  1.5208173 ],\n",
            "       [ 1.6009116 , -1.9705865 ],\n",
            "       [ 2.1645133 , -2.5347912 ],\n",
            "       [-1.7377582 ,  1.6755173 ],\n",
            "       [ 2.4418874 , -2.8019745 ],\n",
            "       [ 2.5275626 , -2.9011772 ],\n",
            "       [ 2.181515  , -2.5343125 ],\n",
            "       [-0.44741526,  0.21449262],\n",
            "       [ 1.4521759 , -1.8219539 ],\n",
            "       [ 1.848337  , -2.1618023 ],\n",
            "       [ 2.4779737 , -2.8140602 ],\n",
            "       [ 2.7566946 , -3.1075716 ],\n",
            "       [ 1.6990212 , -2.0604131 ],\n",
            "       [ 1.9480416 , -2.315798  ],\n",
            "       [ 2.3871439 , -2.7625463 ],\n",
            "       [ 2.1073432 , -2.4682953 ],\n",
            "       [ 1.2283472 , -1.5882983 ],\n",
            "       [ 2.681544  , -3.0161529 ],\n",
            "       [ 0.99662346, -1.3496939 ],\n",
            "       [ 1.6789582 , -2.0425742 ],\n",
            "       [ 0.8730941 , -1.2291385 ],\n",
            "       [ 1.2335578 , -1.5766641 ],\n",
            "       [-0.13496314, -0.12506263],\n",
            "       [-1.0195498 ,  0.8522592 ]], dtype=float32), array([[ 2.8024845 , -3.123918  ],\n",
            "       [-3.0402346 ,  3.221593  ],\n",
            "       [ 1.1641542 , -1.5068724 ],\n",
            "       [ 2.361134  , -2.7362719 ],\n",
            "       [ 0.9146318 , -1.2359121 ],\n",
            "       [-1.9248216 ,  1.888455  ],\n",
            "       [ 2.2311442 , -2.6079776 ],\n",
            "       [ 2.5956523 , -2.9357598 ],\n",
            "       [ 2.7129688 , -3.0600078 ],\n",
            "       [ 0.23385946, -0.46454832],\n",
            "       [ 1.9028122 , -2.2544096 ],\n",
            "       [ 1.6680158 , -2.0334203 ],\n",
            "       [ 1.9241089 , -2.3215196 ],\n",
            "       [ 2.4851983 , -2.8549674 ],\n",
            "       [ 2.6446178 , -3.000022  ],\n",
            "       [ 1.3460077 , -1.7157629 ],\n",
            "       [ 0.67660236, -0.99681747],\n",
            "       [-0.25069833, -0.01744913],\n",
            "       [ 2.2789257 , -2.6568336 ],\n",
            "       [ 2.366595  , -2.7421777 ],\n",
            "       [ 2.774728  , -3.108745  ],\n",
            "       [ 1.6855645 , -2.0415533 ],\n",
            "       [ 1.7239461 , -2.0958278 ],\n",
            "       [ 0.40805912, -0.68422544],\n",
            "       [ 2.4436808 , -2.7847974 ],\n",
            "       [ 0.27623686, -0.57038164],\n",
            "       [ 1.3423547 , -1.6931725 ],\n",
            "       [ 1.1985646 , -1.5541687 ],\n",
            "       [ 1.6983298 , -2.0614452 ],\n",
            "       [-2.922488  ,  3.0392907 ],\n",
            "       [ 0.91292983, -1.2044667 ],\n",
            "       [-1.0366544 ,  0.8659853 ]], dtype=float32), array([[ 2.521569  , -2.8774564 ],\n",
            "       [-0.56328773,  0.32663235],\n",
            "       [ 0.64466596, -0.9358015 ],\n",
            "       [ 1.3163891 , -1.6673795 ],\n",
            "       [ 2.713772  , -3.0453606 ],\n",
            "       [ 0.33254495, -0.6238544 ],\n",
            "       [ 3.047961  , -3.3325827 ],\n",
            "       [ 1.589542  , -1.9680799 ],\n",
            "       [ 0.1920412 , -0.47177547],\n",
            "       [ 2.997134  , -3.2971644 ],\n",
            "       [ 0.25136897, -0.5722494 ],\n",
            "       [ 1.8961118 , -2.2506945 ],\n",
            "       [ 2.804704  , -3.139321  ],\n",
            "       [-0.31330654,  0.07506802],\n",
            "       [ 0.6945069 , -1.0153068 ],\n",
            "       [ 1.5085489 , -1.8426545 ],\n",
            "       [ 2.5179164 , -2.881389  ],\n",
            "       [ 2.5694814 , -2.9361353 ],\n",
            "       [ 0.5215109 , -0.8547672 ],\n",
            "       [ 1.7304903 , -2.0779338 ],\n",
            "       [ 1.563848  , -1.9095328 ],\n",
            "       [ 1.0435005 , -1.3829356 ],\n",
            "       [ 1.9051322 , -2.2572482 ],\n",
            "       [ 2.530098  , -2.8934581 ],\n",
            "       [-1.0101043 ,  0.8176697 ],\n",
            "       [ 1.5994066 , -1.952011  ],\n",
            "       [ 2.1485713 , -2.5118036 ],\n",
            "       [ 1.5512925 , -1.9016532 ],\n",
            "       [-0.36074877,  0.13922422],\n",
            "       [-0.82501894,  0.64930916],\n",
            "       [ 0.6855257 , -0.99681616],\n",
            "       [ 1.3081229 , -1.6621469 ]], dtype=float32), array([[ 5.8198529e-01, -8.7534630e-01],\n",
            "       [ 2.6260345e+00, -2.9875395e+00],\n",
            "       [ 1.8870370e-01, -4.9716869e-01],\n",
            "       [ 2.3410008e+00, -2.6911638e+00],\n",
            "       [ 2.7486508e+00, -3.1023600e+00],\n",
            "       [-2.3043944e-01, -5.5571254e-02],\n",
            "       [ 2.2907650e+00, -2.6576433e+00],\n",
            "       [ 2.0799901e+00, -2.4428272e+00],\n",
            "       [ 1.9846088e+00, -2.3538680e+00],\n",
            "       [ 2.4830940e+00, -2.8300576e+00],\n",
            "       [ 1.6868172e+00, -2.0253413e+00],\n",
            "       [ 3.8018823e-01, -7.1280342e-01],\n",
            "       [ 1.4566103e+00, -1.7949822e+00],\n",
            "       [ 3.0484855e+00, -3.3305819e+00],\n",
            "       [ 1.4064406e+00, -1.7415296e+00],\n",
            "       [ 2.1547387e+00, -2.5162606e+00],\n",
            "       [ 9.2370594e-01, -1.2803022e+00],\n",
            "       [ 1.8735501e+00, -2.2478683e+00],\n",
            "       [ 1.8914758e+00, -2.2602673e+00],\n",
            "       [ 2.1996968e+00, -2.5543654e+00],\n",
            "       [ 2.3244150e+00, -2.6792743e+00],\n",
            "       [ 9.7009695e-01, -1.2966865e+00],\n",
            "       [ 2.1308002e+00, -2.4959953e+00],\n",
            "       [ 1.2372528e+00, -1.5980058e+00],\n",
            "       [ 1.5346605e-03, -3.1011635e-01],\n",
            "       [ 1.9623147e+00, -2.3416879e+00],\n",
            "       [ 2.3003243e-01, -5.1865447e-01],\n",
            "       [ 5.0095922e-01, -8.1843245e-01],\n",
            "       [ 1.7480999e+00, -2.1034353e+00],\n",
            "       [ 1.3783709e+00, -1.7251693e+00],\n",
            "       [ 2.6297467e+00, -2.9921873e+00],\n",
            "       [-2.8978759e-01,  1.8505020e-02]], dtype=float32), array([[ 2.580168  , -2.9337463 ],\n",
            "       [ 1.1180483 , -1.4189389 ],\n",
            "       [ 0.8409452 , -1.1598984 ],\n",
            "       [-2.0228229 ,  2.0110657 ],\n",
            "       [ 1.500147  , -1.8369683 ],\n",
            "       [ 1.1568136 , -1.4803305 ],\n",
            "       [-0.21865134, -0.03244104],\n",
            "       [ 1.9624473 , -2.343827  ],\n",
            "       [ 0.93799025, -1.3233579 ],\n",
            "       [ 2.6887274 , -3.0424893 ],\n",
            "       [ 2.4060857 , -2.771894  ],\n",
            "       [-0.20728488, -0.03842248],\n",
            "       [ 2.280153  , -2.6386569 ],\n",
            "       [ 1.2518038 , -1.5866257 ],\n",
            "       [ 2.5090156 , -2.8756049 ],\n",
            "       [ 2.121556  , -2.4686959 ],\n",
            "       [ 1.44783   , -1.7983755 ],\n",
            "       [ 2.4784405 , -2.8364863 ],\n",
            "       [ 1.726309  , -2.0912738 ],\n",
            "       [-2.1830707 ,  2.1935647 ],\n",
            "       [ 2.235304  , -2.5911338 ],\n",
            "       [ 0.35051718, -0.62060153],\n",
            "       [ 2.253252  , -2.6144154 ],\n",
            "       [ 0.9367221 , -1.2897012 ],\n",
            "       [ 0.9780703 , -1.3071471 ],\n",
            "       [ 2.2180464 , -2.5633116 ],\n",
            "       [ 2.8849456 , -3.2036092 ],\n",
            "       [ 1.2799363 , -1.577257  ],\n",
            "       [ 2.551215  , -2.907682  ],\n",
            "       [ 1.7653096 , -2.1089575 ],\n",
            "       [ 2.4591148 , -2.8173363 ],\n",
            "       [ 2.183849  , -2.5438383 ]], dtype=float32), array([[-0.3210681 ,  0.053005  ],\n",
            "       [-2.1081817 ,  2.1034904 ],\n",
            "       [ 2.0173328 , -2.3927872 ],\n",
            "       [ 1.0946532 , -1.4352032 ],\n",
            "       [-0.32443398,  0.04308712],\n",
            "       [ 0.6141602 , -0.9198004 ],\n",
            "       [ 2.4079268 , -2.7717168 ],\n",
            "       [-1.9529252 ,  1.9139217 ],\n",
            "       [ 2.1999424 , -2.5762222 ],\n",
            "       [ 2.2581823 , -2.6278107 ],\n",
            "       [ 1.5254651 , -1.8985579 ],\n",
            "       [ 2.6365345 , -2.9931238 ],\n",
            "       [ 2.155019  , -2.5146172 ],\n",
            "       [ 2.2806106 , -2.645448  ],\n",
            "       [ 0.04969161, -0.34156385],\n",
            "       [ 1.1710422 , -1.4902383 ],\n",
            "       [-2.975927  ,  3.1361117 ],\n",
            "       [ 2.4147851 , -2.7857783 ],\n",
            "       [ 0.98040134, -1.332993  ],\n",
            "       [ 1.4778712 , -1.8301936 ],\n",
            "       [ 2.164368  , -2.5018153 ],\n",
            "       [ 2.1654782 , -2.523102  ],\n",
            "       [ 2.135167  , -2.4971163 ],\n",
            "       [ 0.7827325 , -1.0981394 ],\n",
            "       [ 1.9533795 , -2.3212485 ],\n",
            "       [ 0.888387  , -1.232586  ],\n",
            "       [ 1.8618629 , -2.228662  ],\n",
            "       [ 2.4748576 , -2.8184829 ],\n",
            "       [ 2.0181613 , -2.3730538 ],\n",
            "       [ 2.5098355 , -2.8562572 ],\n",
            "       [ 1.6464607 , -1.9715332 ],\n",
            "       [ 1.8697764 , -2.215267  ]], dtype=float32), array([[ 1.400705  , -1.7270166 ],\n",
            "       [ 1.8105584 , -2.1563623 ],\n",
            "       [ 1.7476852 , -2.116013  ],\n",
            "       [ 1.6934412 , -2.0425935 ],\n",
            "       [ 2.8426926 , -3.1677263 ],\n",
            "       [ 1.5050287 , -1.853396  ],\n",
            "       [ 3.1603427 , -3.3911083 ],\n",
            "       [ 1.5067426 , -1.8437527 ],\n",
            "       [ 1.3007766 , -1.6318953 ],\n",
            "       [ 1.8181671 , -2.1915596 ],\n",
            "       [-0.74875367,  0.53919065],\n",
            "       [ 2.2263439 , -2.6023943 ],\n",
            "       [ 1.7226774 , -2.0744245 ],\n",
            "       [ 1.7707542 , -2.1323013 ],\n",
            "       [ 2.9893696 , -3.2922575 ],\n",
            "       [ 0.28131437, -0.58617437],\n",
            "       [ 2.0528471 , -2.413674  ],\n",
            "       [ 3.0206573 , -3.3080854 ],\n",
            "       [ 1.0655062 , -1.381506  ],\n",
            "       [ 2.263839  , -2.6324635 ],\n",
            "       [ 1.7680292 , -2.1356866 ],\n",
            "       [ 2.6329327 , -2.9791358 ],\n",
            "       [ 1.2339338 , -1.5768209 ],\n",
            "       [ 1.6874694 , -2.0411518 ],\n",
            "       [ 0.39294663, -0.71166074],\n",
            "       [ 1.7261926 , -2.0647907 ],\n",
            "       [ 2.7713735 , -3.1116054 ],\n",
            "       [-0.91615826,  0.7156153 ],\n",
            "       [ 0.2467679 , -0.5359379 ],\n",
            "       [ 2.9245021 , -3.2162845 ],\n",
            "       [ 2.4034698 , -2.778425  ],\n",
            "       [ 2.0518157 , -2.4395382 ]], dtype=float32), array([[-1.0710179 ,  0.88865036],\n",
            "       [ 1.0603307 , -1.3966824 ],\n",
            "       [ 2.3771496 , -2.750541  ],\n",
            "       [ 2.076431  , -2.4253004 ],\n",
            "       [ 1.6138974 , -1.9342836 ],\n",
            "       [ 2.9144356 , -3.2354364 ],\n",
            "       [ 1.0038823 , -1.3312836 ],\n",
            "       [ 2.4484968 , -2.8218458 ],\n",
            "       [-1.4556192 ,  1.3069257 ],\n",
            "       [ 1.2403427 , -1.5919393 ],\n",
            "       [ 1.7669406 , -2.143554  ],\n",
            "       [ 1.7786118 , -2.1436622 ],\n",
            "       [ 2.5333838 , -2.9075868 ],\n",
            "       [-0.5045612 ,  0.27357292],\n",
            "       [ 0.480136  , -0.7939179 ],\n",
            "       [ 0.8148543 , -1.1352831 ],\n",
            "       [ 2.7269628 , -3.082661  ],\n",
            "       [-1.9254749 ,  1.8648715 ],\n",
            "       [ 1.3078123 , -1.652785  ],\n",
            "       [ 2.285237  , -2.66726   ],\n",
            "       [ 2.974743  , -3.281089  ],\n",
            "       [ 1.0407805 , -1.3632592 ],\n",
            "       [ 2.4534826 , -2.7956173 ],\n",
            "       [ 2.423735  , -2.7903094 ],\n",
            "       [ 1.8720795 , -2.2427905 ],\n",
            "       [ 2.3927896 , -2.753249  ],\n",
            "       [ 1.2945672 , -1.6372056 ],\n",
            "       [ 2.4974685 , -2.8582687 ],\n",
            "       [ 2.72592   , -3.0534394 ],\n",
            "       [ 1.2434698 , -1.5870441 ],\n",
            "       [ 2.5228088 , -2.8627565 ],\n",
            "       [ 0.9543302 , -1.2563499 ]], dtype=float32), array([[ 1.7858768 , -2.131665  ],\n",
            "       [ 1.9879541 , -2.376354  ],\n",
            "       [ 1.361365  , -1.7081245 ],\n",
            "       [ 2.8205855 , -3.1272402 ],\n",
            "       [ 2.210842  , -2.567701  ],\n",
            "       [ 2.793306  , -3.1038222 ],\n",
            "       [ 0.65041983, -0.9711218 ],\n",
            "       [-0.26283804, -0.01508049],\n",
            "       [ 0.83621997, -1.1566929 ],\n",
            "       [ 2.4940033 , -2.862552  ],\n",
            "       [ 1.11597   , -1.4250883 ],\n",
            "       [ 2.3100207 , -2.6621106 ],\n",
            "       [ 2.5869038 , -2.9255707 ],\n",
            "       [ 2.3071375 , -2.6823833 ],\n",
            "       [ 0.6666061 , -0.9798144 ],\n",
            "       [ 2.661338  , -3.0120215 ],\n",
            "       [-1.2201812 ,  1.0511363 ],\n",
            "       [ 1.1332315 , -1.4727662 ],\n",
            "       [ 2.1123626 , -2.490034  ],\n",
            "       [-2.1246405 ,  2.1284387 ],\n",
            "       [ 1.0683401 , -1.3762625 ],\n",
            "       [ 2.014361  , -2.3713996 ],\n",
            "       [ 2.158194  , -2.5299637 ],\n",
            "       [ 1.6594472 , -2.007835  ]], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94 94\n"
          ]
        }
      ],
      "source": [
        "print(len(predictions),len(true_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "[0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "print((true_labels[0][0]))\n",
        "print((true_labels[93]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.24871208 -0.5706789 ]\n",
            "[[ 0.24871208 -0.5706789 ]\n",
            " [ 0.9866019  -1.3104534 ]\n",
            " [ 2.6334898  -2.9709299 ]\n",
            " [ 1.1350842  -1.4524695 ]\n",
            " [ 1.9563595  -2.3189394 ]\n",
            " [ 3.08615    -3.36703   ]\n",
            " [ 0.0901994  -0.39536664]\n",
            " [ 3.0230162  -3.316258  ]\n",
            " [ 2.1108963  -2.4529583 ]\n",
            " [ 0.00368916 -0.28003964]\n",
            " [ 2.827805   -3.1599944 ]\n",
            " [ 2.5646427  -2.9203513 ]\n",
            " [ 1.5777411  -1.9322644 ]\n",
            " [ 2.0924344  -2.45437   ]\n",
            " [-0.3094897   0.05432946]\n",
            " [-0.4735841   0.21962158]\n",
            " [ 2.986885   -3.2851648 ]\n",
            " [ 0.74665934 -1.0782636 ]\n",
            " [ 2.8025713  -3.150106  ]\n",
            " [ 2.8188126  -3.1432073 ]\n",
            " [ 0.33537692 -0.6387907 ]\n",
            " [ 2.4267008  -2.8125076 ]\n",
            " [ 0.5340896  -0.8449312 ]\n",
            " [ 1.6906191  -2.0481403 ]\n",
            " [ 2.4781735  -2.836065  ]\n",
            " [ 1.4660608  -1.8114294 ]\n",
            " [-0.12761389 -0.14030115]\n",
            " [ 2.169318   -2.550057  ]\n",
            " [ 1.8786501  -2.2302272 ]\n",
            " [ 2.0285375  -2.4051163 ]\n",
            " [ 0.59976137 -0.9301604 ]\n",
            " [ 2.5813186  -2.9546692 ]]\n"
          ]
        }
      ],
      "source": [
        "print((predictions[0][0]))\n",
        "print((predictions[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0]\n",
            "<class 'numpy.ndarray'>\n",
            "[array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0], dtype=int64), array([0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1], dtype=int64), array([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0], dtype=int64), array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64), array([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int64), array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0], dtype=int64), array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
            "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1], dtype=int64), array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
            "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
            "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
            "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
            "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0], dtype=int64), array([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
            "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int64), array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
            "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
            "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
            "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64), array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
            "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0], dtype=int64), array([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
            "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int64), array([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int64), array([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
            "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64), array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64), array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64), array([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64), array([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
            "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=int64), array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1], dtype=int64), array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 1], dtype=int64)]\n"
          ]
        }
      ],
      "source": [
        "#for item in true_labels:\n",
        "    #true_labels.extend(item.split())\n",
        "\n",
        "print(true_labels[0])\n",
        "print(type(true_labels[0]))\n",
        "print(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(true_labels)):\n",
        "    true_labels[i] = true_labels[i].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = test_labels.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(type(true_labels[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_list(_2d_list):\n",
        "    flat_list = []\n",
        "    # Iterate through the outer list\n",
        "    for element in _2d_list:\n",
        "        if type(element) is list:\n",
        "            # If the element is of type list, iterate through the sublist\n",
        "            for item in element:\n",
        "                flat_list.append(item)\n",
        "        else:\n",
        "            flat_list.append(element)\n",
        "    return flat_list\n",
        "\n",
        "nested_list = true_labels\n",
        "true_labels = flatten_list(nested_list)\n",
        "print(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n"
          ]
        }
      ],
      "source": [
        "n = len(test_labels)\n",
        "print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n"
          ]
        }
      ],
      "source": [
        "n_pred =  len(true_labels)\n",
        "print(n_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(type(test_labels), type(true_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'> <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "print(type(test_labels[0]), type(true_labels[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000 3000\n"
          ]
        }
      ],
      "source": [
        "print(len(test_labels),len(true_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(true_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(test_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(156, 1758, 543, 543)\n",
            "precision :  0.22317596566523606 \n",
            "Recall :  0.22317596566523606\n",
            "f1 Score :  0.22317596566523606\n"
          ]
        }
      ],
      "source": [
        "class Metrics:\n",
        "    true_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_positves = 0 \n",
        "    false_negatives = 0\n",
        "    precision = 0 \n",
        "    recall = 0\n",
        "\n",
        "    def confusion_matrix(self):\n",
        "        for i in range(n):\n",
        "            if test_labels[i]==1 and true_labels[i]==1:\n",
        "                self.true_positives +=1\n",
        "            elif test_labels[i]==0 and true_labels[i]==0:\n",
        "                self.true_negatives += 1 \n",
        "            elif test_labels[i]==0 and true_labels[i]==1:\n",
        "                self.false_positves += 1 \n",
        "            else:\n",
        "                self.false_negatives += 1 \n",
        "        return self.true_positives, self.true_negatives, self.false_positves, self.false_negatives\n",
        "    \n",
        "    def precision_recall(self):\n",
        "        self.precision = self.true_positives/(self.true_positives+self.false_positves)\n",
        "        self.recall = self.true_positives/(self.true_positives+self.false_negatives)\n",
        "        print(\"precision : \",self.precision, \"\\nRecall : \",self.recall)\n",
        "    \n",
        "    def f1_score(self):\n",
        "        f1 = 2*(self.precision*self.recall)/(self.precision+self.recall)\n",
        "        print('f1 Score : ', f1)\n",
        "\n",
        "model = Metrics()\n",
        "print(model.confusion_matrix())\n",
        "model.precision_recall()\n",
        "model.f1_score()\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ahhhhhhhh.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "755f7636b7779f2e0198c42c8a2f48b6bb82eb2cff7cbc251f2f7266fc339e21"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('env_pytorch': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
